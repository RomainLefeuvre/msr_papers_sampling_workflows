"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Title Page i","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","1","1","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025599","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Title Page iii","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","3","3","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025733","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Copyright Page","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","4","4","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025793","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Table of Contents","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","5","17","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025645","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the General, Program, and Junior PC Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","18","21","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025537","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Data and Tool Showcase Track Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","22","22","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025787","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Industry Track Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","23","23","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025710","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Mining Challenge Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","24","25","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025696","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Registered Reports Track Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","26","27","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025588","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Tutorials Track Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","28","28","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025711","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Message from the Vision and Reflection Track Co-Chairs","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","29","29","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025569","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Organizing Committee","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","30","31","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025600","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Program Committees","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","32","40","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025582","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Keynote","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","41","41","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025719","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Vision and Reflection Track Abstracts","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","42","42","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025797","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Tutorials","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","43","45","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025742","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Learning from Mistakes: Understanding Ad-hoc Logs through Analyzing Accidental Commits","Y. -H. Chou; Y. Min; A. Y. Wang; J. A. Jones","University of California, Irvine, Irvine, United States; Amazon, Toronto, Toronto, Canada; ETH Zürich, Zürich, Switzerland; University of California, Irvine, Irvine, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","1","13","Developers often insert temporary “print” or “log” instructions into their code to help them better understand runtime behavior, usually when the code is not behaving as they expected. Despite the fact that such monitoring instructions, or “ad-hoc logs,” are so commonly used by developers, there is almost no existing literature that studies developers’ practices in how they use them. This paucity of knowledge of the use of these ephemeral logs may be largely due to the fact that they typically only exist in the developers’ local environments and are removed before they commit their code to their revision control system. In this work, we overcame this challenge by observing that developers occasionally mistakenly forget to remove such instructions before committing, and then they remove them shortly later. Additionally, we further studied such developer logging practices by watching and analyzing live-streamed coding videos. Through these empirical approaches, we presented where, how, and why developers use ad-hoc logs to better understand their code and its execution. We collected 27 GB of accidental commits that removed 548,880 ad-hoc logs in JavaScript from GitHub Archive repositories to provide the first large-scale dataset and empirical studies on ad-hoc logging practices. Our results revealed several illuminating findings, including a particular propensity for developers to use ad-hoc logs in asynchronous and callback functions. Our findings provided both empirical evidence and a valuable dataset for researchers and tool developers seeking to enhance ad-hoc logging practices, and potentially deepen our understanding of developers’ practices towards understanding of software’s runtime behaviors.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025683","Empirical Software Engineering;Ad-hoc Logs;Mining Software Repository","Codes;Runtime;Market research;Software;Libraries;Encoding;Data mining;Monitoring;Videos;Software development management","","","","62","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"On the calibration of Just-in-time Defect Prediction","X. Shahini; J. Bartel; K. Pohl","paluno-the Ruhr Institute for Software Technology University of Duisburg Essen, Essen, Germany; paluno-the Ruhr Institute for Software Technology University of Duisburg Essen, Essen, Germany; paluno-the Ruhr Institute for Software Technology University of Duisburg Essen, Essen, Germany",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","14","26","Just-in-time defect prediction (JIT DP) leverages machine learning to identify defect-prone code commits, enabling quality assurance (QA) teams to allocate resources more efficiently by focusing on commits that are most likely to contain defects. Although JIT defect prediction techniques have introduced notable improvements in terms of predictive accuracy, they are still susceptible to misclassification errors such as false positives and false negatives. To preserve the practical utility of JIT defect prediction tools, it becomes essential to estimate the reliability of the predictions, i.e., computing confidence scores. Such scores can help practitioners identify predictions that are most likely to be correct. A simple approach to computing confidence scores is to extract, alongside each prediction, the corresponding prediction probabilities and use them as indicators of confidence. However, for these probabilities to reliably serve as confidence scores, the predictive model must be well-calibrated. This means that the prediction probabilities must accurately represent the true likelihood of each prediction being correct. Miscalibration, common in modern machine learning models, distorts probability scores such that the model’s prediction probabilities do not align with the actual probability of those predictions being correct. Despite its importance, model calibration has been largely overlooked in JIT defect prediction. In this study, we evaluate the calibration of several state-of-theart JIT defect prediction techniques to determine whether and to what extent they exhibit poor calibration. Furthermore, we assess whether post-calibration methods can improve the calibration of existing JIT defect prediction models. Our experimental analysis reveals that all evaluated JIT DP models exhibit some level of miscalibration, with Expected Calibration Error (ECE) ranging from 2% to 35%. Furthermore, post-calibration methods do not consistently improve the calibration of these JIT DP models. Index Terms-Just-in-time defect prediction, machine learning, model calibration, prediction probabilities, prediction reliability.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025774","Just-in-time defect prediction;machine learning;model calibration;prediction probabilities;prediction reliability","Training;Quality assurance;Accuracy;Machine learning;Predictive models;Software;Nickel;Calibration;Software reliability;Resource management","","","","41","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"An Empirical Study on Leveraging Images in Automated Bug Report Reproduction","D. Wang; Z. Zhang; S. Feng; W. G. J. Halfond; T. Yu","University of Connecticut, USA; University of Southern California, USA; Monash University, Australia; University of Southern California, USA; University of Connecticut, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","27","38","Automated bug reproduction is a challenging task, with existing tools typically relying on textual steps-to-reproduce, videos, or crash logs in bug reports as input. However, images provided in bug reports have been overlooked. To address this gap, this paper presents an empirical study investigating the necessity of including images as part of the input in automated bug reproduction. We examined the characteristics and patterns of images in bug reports, focusing on (1) the distribution and types of images (e.g., UI screenshots), (2) documentation patterns associated with images (e.g., accompanying text, annotations), and (3) the functional roles they served, particularly their contribution to reproducing bugs. Furthermore, we analyzed the impact of images on the performance of existing tools, identifying the reasons behind their influence and the ways in which they can be leveraged to improve bug reproduction. Our findings reveal several key insights that demonstrate the importance of images in supporting automated bug reproduction. Specifically, we identified six distinct functional roles that images serve in bug reports, each exhibiting unique patterns and specific contributions to the bug reproduction process. This study offers new insights into tool advancement and suggests promising directions for future research.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00019","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025660","Android;Bug report;Empirical study","Accuracy;Annotations;Computer bugs;Focusing;Documentation;Software;Data mining;Videos","","","","42","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"It’s About Time: An Empirical Study of Date and Time Bugs in Open-Source Python Software","S. Tiwari; S. Chen; A. Joukov; P. Vandervelde; A. Li; R. Padhye","Carnegie Mellon University, Pittsburgh, PA, USA; University of California, San Diego, San Diego, CA, USA; Stony Brook University, Stony Brook, NY, USA; University of California, Santa Barbara, Santa Barbara, CA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","39","51","Accurately performing date and time calculations in software is non-trivial due to the inherent complexity and variability of temporal concepts such as time zones, daylight saving time (DST) adjustments, leap years and leap seconds, clock drifts, and different calendar systems. Although the challenges are frequently discussed in the grey literature, there has not been any systematic study of date/time issues that have manifested in real software systems. To bridge this gap, we qualitatively study 151 bugs and their associated fixes from open-source Python projects on GitHub to understand: (a) the conceptual categories of date/time computations in which bugs occur, (b) the programmatic operations involved in the buggy computations, and (c) the underlying root causes of these errors. We also analyze metrics such as bug severity and detectability as well as fix size and complexity. Our study produces several interesting findings and actionable insights, such as (1) time-zone-related mistakes are the largest contributing factor to date/time bugs; (2) a majority of the studied bugs involved incorrect construction of date/time values; (3) the root causes of date/time bugs often involve misconceptions about library API behavior, such as default conventions or nuances about edge-case behavior; (4) most bugs occur within a single function and can be patched easily, requiring only a few lines of simple code changes. Our findings indicate that static analysis tools can potentially find common classes of high-impact bugs and that such bugs can potentially be fixed automatically. Based on our insights, we also make concrete recommendations to software developers to harden their software against date/time bugs via automated testing strategies.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025657","date;time;time zone;DST;empirical study;software bugs","Systematics;Computer bugs;Static analysis;Software systems;Software;Libraries;Complexity theory;Testing;Software development management;Python","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Enhancing Just-In-Time Defect Prediction Models with Developer-Centric Features","E. Guglielmi; A. D’Aguanno; R. Oliveto; S. Scalabrino","DEVISER @ University of Molise, Italy; DEVISER @ University of Molise, Italy; DEVISER @ University of Molise, Italy; DEVISER @ University of Molise, Italy",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","52","62","Ensuring high software quality in development cycles with frequent updates is critical, especially in Agile and CI/CD environments. Just-In-Time Software Defect Prediction (JIT-SDP) has emerged as a promising solution for finding bugs early, as it enables immediate identification of changes prone to defects. JIT-SPD models based on Machine Learning focus primarily on project- and change-specific features, such as number of lines added and number of files modified in the change. Recent research has started to investigate developer-related features for defect prediction. However, these studies overlook information about developers’ work habits and cross-project activities. In this paper, we try to fill this gap by introducing a set of developer-centric features for JIT-SDP, which span through temporal aspects (when do developers usually make commits?), change-related aspects (how do developers usually make commits?), and project-related aspects (how are the contributions distributed among different repositories?). We conducted an empirical evaluation to understand if such features allow to improve ML-based JIT-SPD models and evaluated the importance of developer-centric features on the performance of the model. Our results show that integrating developer-centric features improves model performance. We observed a +15.48% precision and +10.47% recall in a within-project evaluation and +14.59% precision and even +85.83% recall in cross-project evaluation.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025715","Just-in-Time Software Defect Prediction;Developer Centric;Mining software repositories","Computer bugs;Software quality;Machine learning;Predictive models;Data mining","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Revisiting Defects4J for Fault Localization in Diverse Development Scenarios","M. N. Rafi; A. R. Chen; T. -H. P. Chen; S. Wang","Software Performance, Analysis, and Reliability (SPEAR) Lab, Concordia University, Montréal, Québec, Canada; University of Alberta, Edmonton, Canada; Software Performance, Analysis, and Reliability (SPEAR) Lab, Concordia University, Montréal, Québec, Canada; Central University of Finance and Economics, Beijing, China",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","63","75","Defects4J stands out as a leading benchmark dataset for software testing research, providing a controlled environment to study real bugs from prominent open-source systems. While Defects4J provides a clean and valuable dataset, we aim to explore how fault localization techniques perform under less-controlled development scenarios. In this paper, we revisited Defects4J to study developers’ changes to fault-triggering tests after the bugs were reported/fixed. We aim to introduce a new evaluation scenario within Defects4J, focusing on the implications of regression tests and test changes added after the bug was fixed. We analyze when these tests were modified relative to bug report creation and examine spectrum-based fault localization (SBFL) performance in less-controlled settings. Our findings show that 1) 55% of the fault-triggering tests were added to replicate the bug or test for regression; 2) 22% of the tests were changed after the bug reports, incorporating information related to the bug; 3) developers often update tests with new assertions or changes to match source code updates; and 4) SBFL performance differs significantly in less-controlled settings (down by at most 90% for Mean First Rank). Our study points out the diverse development scenarios in the studied bugs, highlighting new settings for future SBFL evaluations and bug benchmarks.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025619","Fault localization;Defects4J;Empirical study","Location awareness;Software testing;Source coding;Computer bugs;Focusing;Debugging;Benchmark testing;Maintenance engineering;Software;Software development management","","","","70","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Mining Bug Repositories for Multi-Fault Programs","D. Callaghan; B. Fischer","Stellenbosch University, Stellenbosch, South Africa; Stellenbosch University, Stellenbosch, South Africa",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","76","80","Datasets such as Defects4J and BugsInPy that contain bugs from real-world software projects are necessary for a realistic evaluation of automated debugging tools. However, these datasets largely identify only a single bug in each entry, while real-world software projects (including those used in Defects4J and BugsInPy) typically contain multiple bugs at the same time. We lift this limitation and describe an automated approach to identify multiple existing bugs in the individual dataset entries. We use test case transplantation and fault location translation to expose and locate the bugs, respectively. We identified 9.2 faults on average in each of the 311 versions of the 5 projects in Defects4J, and 18.6 faults in 501 versions of the 17 projects in BugsInPy. We thus provide datasets of true multi-fault versions within real-world software projects, which maintain the properties, format and usability of the original datasets.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025646","bug dataset;real faults;testing and debugging","Location awareness;Translation;Computer bugs;Fault location;Maintenance engineering;Software;Reproducibility of results;Extensibility;Data mining;Usability","","1","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"HaPy-Bug – Human Annotated Python Bug Resolution Dataset","P. Przymus; M. Fejzer; J. Narębski; R. Woźniak; Ł. Halada; A. Kazecki; M. Molchanov; K. Stencel","Nicolaus Copernicus University, Toruń, Poland; Nicolaus Copernicus University, Toruń, Poland; Nicolaus Copernicus University, Toruń, Poland; Nicolaus Copernicus University, Toruń, Poland; University of Wrocław, Wrocław, Poland; Nicolaus Copernicus University, Toruń, Poland; University of Warsaw, Warsaw, Poland; Kyiv Polytechnic Institute, Kyiv, Ukraine",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","81","85","We present HaPy-Bug, a curated dataset of 793 Python source code commits associated with bug fixes, with each line of code annotated by three domain experts. The annotations offer insights into the purpose of modified files, changes at the line level, and reviewers’ confidence levels. We analyze HaPy-Bug to examine the distribution of file purposes, types of modifications, and tangled changes. Additionally, we explore its potential applications in bug tracking, the analysis of bug-fixing practices, and the development of repository analysis tools. HaPy-Bug serves as a valuable resource for advancing research in software maintenance and security.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025740","CVE;Software quality","Software maintenance;Codes;Annotations;Source coding;Computer bugs;Software quality;Security;Tuning;Python;Software development management","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"SPRINT: An Assistant for Issue Report Management","A. Adnan; A. Saha; O. Chaparro","University of Dhaka, Dhaka, Bangladesh; William & Mary, Williamsburg, Virginia, USA; William & Mary, Williamsburg, Virginia, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","86","90","Managing issue reports is essential for the evolution and maintenance of software systems. However, manual issue management tasks such as triaging, prioritizing, localizing, and resolving issues are highly resource-intensive for projects with large codebases and users. To address this challenge, we present SPRINT, a GitHub application that utilizes state-of-the-art deep learning techniques to streamline issue management tasks. SPRINT assists developers by: (i) identifying existing issues similar to newly reported ones, (ii) predicting issue severity, and (iii) suggesting code files that likely require modification to solve the issues. We evaluated SPRINT using existing datasets and methodologies, measuring its predictive performance, and conducted a user study with five professional developers to assess its usability and usefulness. The results show that SPRINT is accurate, usable, and useful, providing evidence of its effectiveness in assisting developers in managing issue reports. SPRINT is an open-source tool available at github.com/sea-lab-wm/sprint_issue_report_assistant_tool.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025725","","Deep learning;Codes;Accuracy;Manuals;Software systems;Maintenance;Data mining;Usability;Software development management","","2","","46","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Wolves in the Repository: A Software Engineering Analysis of the XZ Utils Supply Chain Attack","P. Przymus; T. Durieux","Nicolaus Copernicus University in Toruń, Poland; TU Delft & Endor Labs, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","91","102","The digital economy runs on Open Source Software (OSS), with an estimated 90% of modern applications containing open-source components. While this widespread adoption has revolutionized software development, it has also created critical security vulnerabilities, particularly in essential but underresourced projects. This paper examines a sophisticated attack on the XZ Utils project (CVE-2024-3094), where attackers exploited not just code, but the entire open-source development process to inject a backdoor into a fundamental Linux compression library. Our analysis reveals a new breed of supply chain attack that manipulates software engineering practices themselves - from community management to CI/CD configurations - to establish legitimacy and maintain long-term control. Through a comprehensive examination of GitHub events and development artifacts, we reconstruct the attack timeline, analyze the evolution of attacker tactics. Our findings demonstrate how attackers leveraged seemingly beneficial contributions to project infrastructure and maintenance to bypass traditional security measures. This work extends beyond traditional security analysis by examining how software engineering practices themselves can be weaponized, offering insights for protecting the open-source ecosystem.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025592","security;project management","Adaptation models;Reviews;Biological system modeling;Weapons;Ecosystems;Supply chains;Security;Open source software;Software engineering;Software development management","","","","21","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Software Composition Analysis and Supply Chain Security in Apache Projects: an Empirical Study","S. Nocera; S. Vegas; G. Scanniello; N. Juristo","University of Salerno, Fisciano, Italy; Universidad Politécnica de Madrid, Madrid, Spain; University of Salerno, Fisciano, Italy; Universidad Politécnica de Madrid, Madrid, Spain",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","103","115","A software supply chain consists of anything needed to develop and deliver a software project, including (third-party) components. Software Composition Analysis (SCA) allows for managing the security of software supply chains by identifying such components and their (security) vulnerabilities. The main goal of the empirical study presented in this paper is to investigate the effects of adopting/using over time an SCA tool like OWASP Dependency-Check (OWASP DC) in the context of the security of the software supply chain. To this end, following a cohort design, we analyzed the vulnerabilities affecting the components of the open-source (OS) Java Maven projects owned by the Apache Software Foundation (ASF) and publicly hosted on GitHub. These projects could adopt (or not) OWASP DC. The results indicate that the adoption of OWASP DC appears to be causing a significant reduction in the overall number/score of vulnerabilities, including those with a high Common Vulnerability Scoring System (CVSS) severity level. The use of OWASP DC also increased the vulnerabilities with a low severity level. Our results seem to encourage practitioners to adopt SCA to improve the security of their software supply chains.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025577","Cohort Study;Empirical Study;Software Composition Analysis;Software Supply Chain Security;Software Vulnerabilities","Java;Supply chains;Software;Security;Data mining;Software development management","","","","65","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Good practice versus reality: A landscape analysis of Research Software metadata adoption in European Open Science Clusters","A. E. Hounsri; D. Garijo","Ontology Engineering Group, Universidad Politécnica de Madrid, Madrid, Spain; Ontology Engineering Group, Universidad Politécnica de Madrid, Madrid, Spain",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","116","128","Research Software has become a key asset to support the results described in academic publications, enabling effective data analysis and reproducibility. In order to ensure adherence of Research Software to the Findable, Accessible, Interoperable, and Reusable (FAIR) principles, the scientific community has proposed metadata guidelines and best practices. However, it is unclear how these practices have been adopted so far. This paper examines how different scientific communities describe Research Software with metadata to support FAIR, how do they adopt existing good practices regarding citation, documentation or versioning, and what is the current adoption of archival services for long-term preservation. We carry out our analysis in the software registries of five science clusters (in domains ranging from Physics to Environmental Sciences), together with a multi-domain collaborative software registry. Our results highlight the main gaps in metadata adoption in the different communities, opening an opportunity for future contributions to aid researchers in adopting good FAIR and Open Science practices.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00028","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025739","Research Software;Metadata;FAIR software;FAIR principles;Guidelines.","Data analysis;Europe;Documentation;Metadata;Software;Reproducibility of results;Distance measurement;Data mining;Physics;Guidelines","","","","37","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"From Industrial Practices to Academia: Uncovering the Gap in Vulnerability Research and Practice","Z. Liu; X. Hu; J. Zhou; X. Xia","Zhejiang University, China; Zhejiang University, China; Queen’s University, Canada; Zhejiang University, China",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","129","141","The rising number of vulnerabilities has attracted significant attention from academia and industry. While the Common Vulnerabilities and Exposures (CVE) database is an industry-standard resource for organizing and researching vulnerabilities, it lacks comprehensive analysis, often requiring researchers to conduct additional investigations. This gap in detailed vulnerability information can hinder effective vulnerability management and research. To address this problem, we conduct the first empirical investigation to discover the disparities in vulnerability aspects between academia and industry. We collect a comprehensive dataset comprising ${5 0, 2 5 4}$ security bulletins and blogs from 36 CVE Numbering Authorities (CNAs). We extract and summarize the specific characteristics of vulnerabilities from these web pages and identify 15 key aspects for describing vulnerabilities. Our analysis reveals that the detailed information provided by different CNAs varies significantly. The industrial practice primarily emphasizes post-disclosure aspects of vulnerabilities, such as Impact (82.1%) and Measures (i.e., Solution and Mitigation), while largely overlooking Attacker Type (almost none), Attack Scenario (0.3%), and details on Steps to Reproduce (0.2%) and Vulnerability Validation & Exploitation (almost none). We also systematically review 31 academic papers on vulnerabilities to identify the primary aspects of academic research. Our findings indicate the lack of research on Attack Scenario and Attack Method in academia. Academic research on vulnerabilities primarily focuses on Fix/Patch Release (13 out of 31), with significant attention to patch generation, porting, search, and vulnerability repair. By offering insights to industry and academia, we aim to stimulate the advancement of vulnerability research. In the future, the aspect Attack scenario of vulnerabilities holds the potential for breakthrough advancements, benefiting both industry and academia.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025642","Vulnerability;Aspects;Industry;Academia","Industries;Databases;Prevention and mitigation;Blogs;Web pages;Maintenance engineering;Software;Security;Data mining;Systematic literature review","","","","62","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Patch Me If You Can—Securing the Linux Kernel","G. Kudrjavets","Amazon Web Services, Seattle, WA, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","142","143","In February 2024, the Linux kernel became a CNA (CVE numbering authority). The number of CVEs issued for the kernel increased by an order of magnitude. This increase places additional patching demands on kernel vendors and software companies maintaining custom Linux kernels. The industry needs the software analytics research community’s help to understand the patch velocity, develop the prediction models, and estimate the effort required to patch the kernel.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025677","linux;kernel;cve","Industries;Analytical models;Linux;Companies;Predictive models;Software;Data mining;Kernel","","","","14","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"OSS License Identification at Scale: A Comprehensive Dataset Using World of Code","M. Jahanshahi; D. Reid; A. McDaniel; A. Mockus","Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","144","148","The proliferation of open source software (OSS) and different types of reuse has made it incredibly difficult to perform an essential legal and compliance task of accurate license identification within the software supply chain. This study presents a reusable and comprehensive dataset of OSS licenses, created using the World of Code (WoC) infrastructure. By scanning all files containing “license” in their file paths, and applying the approximate matching via winnowing algorithm to identify the most similar license from the SPDX and Open Source list, we found and identified 5.5 million distinct license blobs in OSS projects. The dataset includes a detailed project-to-license (P2L) map with commit timestamps, enabling dynamic analysis of license adoption and changes over time. To verify the accuracy of the dataset we use stratified sampling and manual review, achieving a final accuracy of 92.08%, with precision of 87.14%, recall of 95.45%, and an F1 score of 91.11%. This dataset is intended to support a range of research and practical tasks, including the detection of license noncompliance, the investigations of license changes, study of licensing trends, and the development of compliance tools. The dataset is open, providing a valuable resource for developers, researchers, and legal professionals in the OSS community.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00032","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025699","Software Licenses;Open Source Software;Open Source Licenses;World of Code","Codes;Accuracy;Law;Reviews;Supply chains;Software algorithms;Manuals;Licenses;Market research;Open source software","","","","15","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"SCRUBD: Smart Contracts Reentrancy and Unhandled Exceptions Vulnerability Dataset","C. S. Yashavant; M. Chavda; S. Kumar; A. Karkare; A. Karmakar","Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur, Kanpur, India",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","149","153","Smart Contracts (SCs) handle transactions in the Ethereum blockchain worth millions of United States dollars, making them a lucrative target for attackers seeking to exploit vulnerabilities and steal funds. The Ethereum community has developed a rich set of tools to detect vulnerabilities in SCs, including reentrancy (RE) and unhandled exceptions (UX). A dataset of SCs labeled with vulnerabilities is needed to evaluate the tools’ efficacy. Existing SC datasets with labeled vulnerabilities have limitations, such as covering only a limited range of vulnerability scenarios and containing incorrect labels. As a result, there is a lack of a standardized dataset to compare the performances of these tools. Our dataset, SCRUBD, aims to fill this gap. SCRUBD is a dataset of real-world SCs and synthesized SCs labeled with RE and UX vulnerabilities. The real-world SC dataset is labeled through crowdsourcing, followed by manual inspection by an experienced SC programmer, and covers both RE and UX vulnerabilities. On the other hand, the synthesized dataset is carefully crafted to cover various RE scenarios only. Using SCRUBD, we compared the performance of six popular vulnerability detection tools. Based on our study, we found that Slither outperforms other tools on a crowdsourced dataset in detecting RE vulnerabilities, while Sailfish outperforms other tools on a manually synthesized dataset for detecting RE. For UX vulnerabilities, Slither outperforms all other tools.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025708","Smart Contract Vulnerabilities;Reentrancy;Unhandled Exceptions;Dataset","Hands;Crowdsourcing;Smart contracts;Manuals;Inspection;Software;Blockchains;Data mining","","","","35","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"ICVul: A Well-labeled C/C++ Vulnerability Dataset with Comprehensive Metadata and VCCs","C. Lu; T. Li; T. Dehaene; B. Lagaisse","DistriNet Group-T, KU Leuven, Leuven, Belgium; DistriNet Group-T, KU Leuven, Leuven, Belgium; DistriNet Group-T, KU Leuven, Leuven, Belgium; DistriNet Group-T, KU Leuven, Leuven, Belgium",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","154","158","Machine learning-based software vulnerability detection requires high-quality datasets, which is essential for training effective models. To address challenges related to data label quality, diversity, and comprehensiveness, we constructed ICVul, a dataset emphasizing data quality and enriched with comprehensive metadata, including Vulnerability-Contributing Commits (VCCs). We began by filtering Common Vulnerabilities and Exposures from the NVD, retaining only those linked to GitHub fix commits. Then we extracted functions and files along with relevant metadata from these commits and used the SZZ algorithm to trace VCCs. To further enhance label reliability, we developed the ESC (Eliminate Suspicious Commit) technique, ensuring credible data labels. The dataset is stored in a relationallike database for improved usability and data integrity. Both ICVul and its construction framework are publicly accessible on GitHub, supporting research in related field.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025773","Common Vulnerabilities and Exposures;Software Vulnerability Datasets;Mining Software Repositories;C/C++ Code","Training;Data integrity;Software algorithms;Metadata;Software;Software reliability;Data mining;Labeling;Usability;Software development management","","","","16","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"A Dataset of Contributor Activities in the NumFocus Open-Source Community","Y. Hourri; A. Decan; T. Mens","Software Engineering Lab, University of Mons, Belgium; Software Engineering Lab, University of Mons, Belgium; Software Engineering Lab, University of Mons, Belgium",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","159","163","Large open-source software (OSS) communities are composed of multiple interrelated projects, hosting numerous repositories involving thousands of interacting contributors. Socio-technical studies about a community’s collaboration dynamics can benefit from historical data logs of the detailed activities performed by the projects’ contributors.This paper provides an automated mapping of raw public events in GitHub repositories to structured activities that more accurately capture the intent of contributors. It also contributes a large dataset containing three years of activities of the 180K+ contributors of NUMFOCUS, a large OSS community supporting scientific research and data science. The dataset covers 58 projects, including 2.2M+ activities across 2,851 GitHub repositories. This dataset allows advanced studies of the NUMFOCUS community collaboration dynamics, and the activity mapping process enables the possibility to create and use similar datasets for other OSS communities.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025690","open source;software community;collaborative development;contributor activities;repository mining","Collaboration;Data science;Data mining;Open source software;Software development management","","","","16","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Wild SBOMs: a Large-scale Dataset of Software Bills of Materials from Public Code","L. Soeiro; T. Robert; S. Zacchiroli","LTCI, Télécom Paris, Institut Polytechnique de Paris, France; LTCI, Télécom Paris, Institut Polytechnique de Paris, France; LTCI, Télécom Paris, Institut Polytechnique de Paris, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","164","168","Developers gain productivity by reusing readily available Free and Open Source Software (FOSS) components. Such practices also bring some difficulties, such as managing licensing, components and related security. One approach to handle those difficulties is to use Software Bill of Materials (SBOMs). While there have been studies on the readiness of practitioners to embrace SBOMs and on the SBOM tools ecosystem, a large scale study on SBOM practices based on SBOM files produced in the wild is still lacking. A starting point for such a study is a large dataset of SBOM files found in the wild. We introduce such a dataset, consisting of over 78 thousand unique SBOM files, deduplicated from those found in over 94 million repositories. We include metadata that contains the standard and format used, quality score generated by the tool sbomqs, number of revisions, filenames and provenance information. Finally, we give suggestions and examples of research that could bring new insights on assessing and improving SBOM real practices.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025611","SBOM dataset;SBOM standards;SBOM usage in the wild;SBOM scores","Productivity;Codes;Bills of materials;Ecosystems;Metadata;Software measurement;Security;Data mining;Standards;Open source software","","","","44","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"MaLAware: Automating the Comprehension of Malicious Software Behaviours using Large Language Models (LLMs)","B. Saha; N. Rani; S. K. Shukla","Department of Computer Science & Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Computer Science & Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Computer Science & Engineering, Indian Institute of Technology Kanpur, Kanpur, India",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","169","173","Current malware (malicious software) analysis tools focus on detection and family classification but fail to provide clear and actionable narrative insights into the malignant activity of the malware. Therefore, there is a need for a tool that translates raw malware data into human-readable descriptions. Developing such a tool accelerates incident response, reduces malware analysts’ cognitive load, and enables individuals having limited technical expertise to understand malicious software behaviour. With this objective, we present MaLAware, which automatically summarizes the full spectrum of malicious activity of malware executables. MaLAware processes Cuckoo Sandbox-generated reports using large language models (LLMs) to correlate malignant activities and generate concise summaries explaining malware behaviour. We evaluate the tool’s performance on five opensource LLMs. The evaluation uses the human-written malware behaviour description dataset as ground truth. The model’s performance is measured using 11 extensive performance metrics, which boosts the confidence of MaLAware’s effectiveness. The current version of the tool, i.e., MaLAware, supports Qwen2.5-7B, Llama2-7B, Llama3.1-8B, Mistral-7B, and Falcon-7B, along with the quantization feature for resource-constrained environments. MaLAware lays a foundation for future research in malware behavior explanation, and its extensive evaluation demonstrates LLMs’ ability to narrate malware behavior in an actionable and comprehensive manner.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025594","LLM;Malware Analysis;Malicious Behavior Explanation;Large Language Model;Natural Language Processing (NLP) in Cybersecurity;LLM for cybersecurity;Malware Explainer;Cybersecurity","Analytical models;Accuracy;Translation;Quantization (signal);Large language models;Malware;Natural language processing;Computer security;Cancer;Resilience","","","","25","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Combining Large Language Models with Static Analyzers for Code Review Generation","I. Jaoua; O. B. Sghaier; H. Sahraoui","Université de Montréal, Montreal, Canada; Université de Montréal, Montreal, Canada; Université de Montréal, Montreal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","174","186","Code review is a crucial but often complex, subjective, and time-consuming activity in software development. Over the past decades, significant efforts have been made to automate this process. Early approaches focused on knowledge-based systems (KBS) that apply rule-based mechanisms to detect code issues, providing precise feedback but struggling with complex, context-dependent cases. More recent work has shifted toward fine-tuning pre-trained language models for code review, enabling broader issue coverage but often at the expense of precision. In this paper, we propose a hybrid approach that combines the strengths of KBS and learning-based systems (LBS) to generate high-quality, comprehensive code reviews. Our method integrates knowledge at three distinct stages of the language model pipeline: during data preparation (DataAugmented Training, DAT), at inference (Retrieval-Augmented Generation, RAG), and after inference (Naive Concatenation of Outputs, NCO). We empirically evaluate our combination strategies against standalone KBS and LBS fine-tuned on a realworld dataset. Our results show that these hybrid strategies enhance the relevance, completeness, and overall quality of review comments, effectively bridging the gap between rule-based tools and deep learning models.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025622","Code Review;Knowledge-Based Systems;Language Models;Retrieval-Augmented Generation","Training;Codes;Automation;Reviews;Large language models;Retrieval augmented generation;Knowledge based systems;Pipelines;Static analysis;Hybrid power systems","","","","62","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Harnessing Large Language Models for Curated Code Reviews","O. B. Sghaier; M. Weyssow; H. Sahraoui","Université de Montréal, Montréal, Canada; Singapore Management University, Singapore; Université de Montréal, Montréal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","187","198","In code review, generating structured and relevant comments is crucial for identifying code issues and facilitating accurate code changes that ensure an efficient code review process. Well-crafted comments not only streamline the code review itself but are also essential for subsequent tasks like code refinement, where the code is modified to satisfy the input review comment. Although various AI-based approaches aimed to automate comment generation, their effectiveness remains limited by the quality of the training data. Existing code review datasets are often noisy and unrefined, posing limitations to the learning potential of AI models and hindering the automation process. To address these challenges, we propose a curation pipeline designed to enhance the quality of the largest publicly available code review dataset. We begin by establishing an evaluation framework, incorporating specific criteria and categories to empirically study the initial quality of the dataset. Using a large language model (LLM)-driven approach, we then apply our curation pipeline to refine the dataset. A comparative analysis of the newly curated dataset, based on the same evaluation framework, demonstrates substantial improvements in the clarity and conciseness of the comments. Additionally, we assess the impact of the curated dataset on automating downstream tasks, specifically comment generation and code refinement. Our findings show that the curated dataset leads to enhanced model performance in generating more accurate comments. Curated comments are also more useful as they lead to more accurate code refinement.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025570","Code review;large language models;software maintenance;empirical software engineering","Training;Software maintenance;Codes;Accuracy;Reviews;Large language models;Pipelines;Training data;Predictive models;Software engineering","","","","42","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"SMATCH-M-LLM: Semantic Similarity in Metamodel Matching With Large Language Models","N. Ahmed; H. C. Kwok; M. Hamdaqa; W. K. G. Assunção","Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, Canada; Department of Industrial and Systems Engineering, Hong Kong Polytechnic University, Hong Kong, China; Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, Canada; Department of Computer Science, North Carolina State University, Raleigh, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","199","210","Metamodel matching plays a crucial role in defining transformation rules in model-driven engineering by identifying correspondences between different metamodels, forming the foundation for effective transformations. Current techniques face significant challenges due to syntactical and structural heterogeneity. To address this, matching techniques often employ semantic similarity to identify correspondences. Traditional semantic matchers, however, rely on ontology matching tools or lexical databases, which often struggle when metamodels use different terminologies or hierarchical structures. Inspired by the contextual understanding capabilities of Large Language Models (LLMs), this paper explores the capability of GPT-4 potentials as a semantic matcher and alternative to existing methods for metamodel matching. However, metamodels can be large, which can overwhelm LLMs if provided in a single prompt, leading to reduced accuracy. Therefore, we propose prompting LLMs with fragments of the source and target metamodels, identifying correspondences through an iterative process. The fragments to be provided in the prompt are identified based on an initial mapping derived from their elements’ definitions. Through experiments with 10 metamodels, our results show that our LLMbased approach improves the accuracy of metamodel matching, achieving an average F-measure of $\approx 91 \%$, outperforming both the baseline and hybrid approaches, which have a maximum average F-measure of $\approx \mathbf{2 9 \%}$ and $\approx \mathbf{7 4 \%}$, respectively. Moreover, our approach surpasses single-prompt LLM-based matching, which has an average $\mathbf{F}$-measure of $\mathbf{8 0 \%}$, by approximately $\mathbf{1 1 \%}$.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025595","Model-driven Engineering;Metamodel Matching;Domain-Specific Languages;Model Migration","Accuracy;Costs;Terminology;Databases;Large language models;Semantics;Ontologies;Model driven engineering;Software;Iterative methods","","","","43","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"How Effective are LLMs for Data Science Coding? A Controlled Experiment","N. Nascimento; E. Guimaraes; S. S. Chintakunta; S. A. Boominathan","EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","211","222","The adoption of Large Language Models (LLMs) for code generation in data science offers substantial potential for enhancing tasks such as data manipulation, statistical analysis, and visualization. However, the effectiveness of these models in the data science domain remains underexplored. This paper presents a controlled experiment that empirically assesses the performance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4 Turbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs (Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges sourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM) approach, we evaluated each model’s effectiveness across task types (Analytical, Algorithm, Visualization) and varying difficulty levels. Our statistical testing confirms that all models achieved success rates significantly above $50 \%$, demonstrating performance beyond chance. ChatGPT and Claude significantly exceeded the $60 \%$ threshold, but no model reached $70 \%$, indicating limitations in achieving higher accuracy. ChatGPT maintained consistent performance across difficulty levels, whereas Claude’s success varied with task complexity. Hypothesis testing indicates that task type does not significantly impact success rate overall. For analytical tasks, efficiency analysis shows no significant differences in execution times, though ChatGPT tended to be slower and less predictable despite high success rates. For visualization tasks, while similarity quality among LLMs is comparable, ChatGPT consistently delivered the most accurate outputs. This study provides a structured, empirical evaluation of LLMs in data science, delivering insights that support informed model selection tailored to specific task demands. Our findings establish a framework for future AI assessments, emphasizing the value of rigorous evaluation beyond basic accuracy measures.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025766","data science;large language model;coding generation;empirical study;hypothesis testing","Visualization;Accuracy;Statistical analysis;Large language models;Data visualization;Data science;Chatbots;Encoding;Data models;Testing","","","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Do LLMs Provide Links to Code Similar to What They Generate? A Study with Gemini and Bing CoPilot","D. Bifolco; P. Cassieri; G. Scanniello; M. D. Penta; F. Zampetti","University of Sannio, Benevento, Italy; University of Salerno, Fisciano, Italy; University of Salerno, Fisciano, Italy; University of Sannio, Benevento, Italy; University of Sannio, Benevento, Italy",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","223","235","Large Language Models (LLMs) are currently used for various software development tasks, including generating code snippets to solve specific problems. Unlike reuse from the Web, LLMs are limited in providing provenance information about the generated code, which may have important trustworthiness and legal consequences. While LLM-based assistants may provide external links that are “related” to the generated code, we do not know how relevant such links are. This paper presents the findings of an empirical study assessing the extent to which 243 and 194 code snippets, across six programming languages, generated by Bing CoPilot and Google Gemini, likely originate from the links provided by these two LLM-based assistants. The study leverages automated code similarity assessments with thorough manual analysis. The study’s findings indicate that the LLM-based assistants provide a mix of relevant and irrelevant links having a different nature. Specifically, although 66% of the links from Bing CoPilot and 28% from Google Gemini are relevant, LLMs-based assistants still suffer from serious “provenance debt”.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025675","Large Language Models;Code Provenance;Empirical Study;Licensing;Trustworthiness","Training;Computer languages;Codes;Law;Large language models;Roads;Manuals;Software;Internet;Software development management","","","","72","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Too Noisy To Learn: Enhancing Data Quality for Code Review Comment Generation","C. Liu; H. Y. Lin; P. Thongtanunam",The University of Melbourne; The University of Melbourne; The University of Melbourne,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","236","248","Code review is an important practice in software development, yet it is time-consuming and requires substantial effort. While open-source datasets have been used to train neural models for automating code review tasks, including review comment generation, these datasets contain a significant amount of noisy comments (e.g., vague or non-actionable feedback) that persist despite cleaning methods using heuristics and machine learning approaches. Such remaining noise may lead models to generate low-quality review comments, yet removing them requires a complex semantic understanding of both code changes and natural language comments. In this paper, we investigate the impact of such noise on review comment generation and propose a novel approach using large language models (LLMs) to further clean these datasets. Based on an empirical study on a large-scale code review dataset, our LLM-based approach achieves $66-85 \%$ precision in detecting valid comments. Using the predicted valid comments to fine-tune the state-of-the-art code review models (cleaned models) can generate review comments that are $13.0 \%-12.4 \%$ more similar to valid human-written comments than the original models. We also find that the cleaned models can generate more informative and relevant comments than the original models. Our findings underscore the critical impact of dataset quality on the performance of review comment generation. We advocate for further research into cleaning training data to enhance the practical utility and quality of automated code review.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025607","Automated Code Review;Review Comment Generation;Dataset Quality","Training;Codes;Reviews;Data integrity;Large language models;Noise;Training data;Predictive models;Cleaning;Noise measurement","","","","54","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks","K. S. Khant; H. Y. Lin; P. Thongtanunam",The University of Melbourne; The University of Melbourne; The University of Melbourne,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","249","254","Learning-based techniques, especially advanced pretrained models for code have demonstrated capabilities in code understanding and generation, solving diverse software engineering (SE) tasks. Despite the promising results, current training approaches may not fully optimize model performance, as they typically involve learning from randomly shuffled training data. Recent work shows that Curriculum Learning (CL) can improve performance on code-related tasks through incremental learning based on the difficulty of synthetic code. Yet, the effectiveness of CL with conventional difficulty measures in SE tasks remains largely unexplored. In this study, we explore two conventional code metrics: code length and cyclomatic complexity to determine the difficulty levels. We investigate how the pre-trained code model (CodeT5) learns under CL, through the tasks of code clone detection and code summarization. Our empirical study on the CodeXGLUE benchmark showed contrasting results to prior studies, where the model exhibited signs of catastrophic forgetting and shortcut learning. Surprisingly, model performance saturates after only the first quartile of training, potentially indicating a limit in the model’s representation capacity and/or the task’s inherent difficulty. Future work should further explore various CL strategies with different code models across a wider range of SE tasks for a more holistic understanding.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025707","Code Understanding;Curriculum Learning","Training;Measurement;Codes;Incremental learning;Current measurement;Training data;Software;Data models;Data mining;Software engineering","","","","28","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"RepoChat: An LLM-Powered Chatbot for GitHub Repository Question-Answering","S. Abedu; L. Menneron; S. Khatoonabadi; E. Shihab","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; CESI Graduate School of Engineering, Saint-Nazaire, France; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","255","259","Software repositories contain a wealth of data about the software development process, such as source code, documentation, issue tracking, and commit histories. However, accessing and extracting meaningful insights from these data is timeconsuming and requires technical expertise, posing challenges for software practitioners, especially non-technical stakeholders like project managers. Existing solutions, such as software engineering chatbots leveraging LLMs, have demonstrated significant limitations in retrieving relevant data to answer user questions. In this paper, we introduce RepoChat, a web-based tool designed to answer repository-related questions by synergizing LLMs with knowledge graphs. RepoChat operates in two steps: (1) the Data Ingestion step, where it collects and constructs a knowledge graph from repository metadata, such as commits, issues, files and users; and (2) the Interaction step, where it takes the users natural language question, translates it into graph queries using an LLM, executes these queries against the knowledge graph, and generates a user-friendly response to the question using the query results as context. We evaluate RepoChat by conducting a user study in which participants asked a series of repository-related questions representing common developer intents. RepoChat achieved an accuracy of $90 \%$, correctly answering 36 out of 40 questions, demonstrating its effectiveness in accurately retrieving relevant information to answer user’s questions. RepoChat is available at https://repochattool.streamlit.app/, and its source code is accessible on Zenodo [1].","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025648","Mining Software Repositories;Software Engineering Chatbots;Software Development Assistants","Translation;Source coding;Knowledge graphs;Metadata;Chatbots;Software;Data mining;Stakeholders;Software development management;Software engineering","","","","26","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Analyzing Dependency Clusters and Security Risks in the Maven Central Repository","G. Lake; M. F. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, USA; Department of Computer Science, Idaho State University, Pocatello, ID, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","260","264","We present a cluster analysis of the Maven Central Repository’s dependency structure to identify and assess vulnerability risks using the Goblin framework. Through analysis of over 15 million artifacts using the Leiden community detection algorithm, we identified approximately 67 thousand distinct clusters with a high modularity score. Our risk assessment framework combines CVE metrics, freshness scores, and inter-cluster connectivity patterns to evaluate cluster risk levels and potential vulnerability propagation paths. The analysis reveals that while individual clusters typically show low to moderate risk scores, the repository’s highly connected structure creates critical paths for vulnerability propagation through hub clusters, some containing over 1.5 million nodes. We provide recommendations for dependency risk monitoring, including tracking of bridge nodes and prioritizing high-connectivity clusters. Our systematic approach provides a framework to identify systemic dependency risks across the repository through targeted inspections at critical points in the dependency network.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00046","Idaho State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025718","Maven Central;Dependency Analysis;Community Detection;Software Ecosystem;Vulnerability Analysis;Risk Assessment;Leiden Algorithm;Bridge Nodes;Principal Component Analysis","Bridges;Target tracking;Systematics;Software algorithms;Software;Risk management;Security;Detection algorithms;Monitoring;Principal component analysis","","","","36","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Chasing the Clock: How Fast Are Vulnerabilities Fixed in the Maven Ecosystem?","M. F. Rabbi; A. I. Champa; R. Paul; M. F. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","265","269","This study investigates the software vulnerability resolution time in the Maven ecosystem, focusing on the influence of CVE severity, library popularity as measured by the number of dependents, and version release frequency. The results suggest that critical vulnerabilities are addressed slightly faster compared to lower-severity ones. Library popularity shows a positive impact on resolution times, while frequent version updates are associated with faster vulnerability fixes. These statistically significant findings are based on a thorough evaluation of over 14 million versions from 658,078 libraries using the dependency graph database of Goblin framework. These results emphasize the need for proactive maintenance strategies to improve vulnerability management in open-source ecosystems.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00047","Idaho State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025666","Goblin;dependency;vulnerability;vulnerability fixing;library popularity;library release frequency","Time-frequency analysis;Databases;Statistical analysis;Ecosystems;Focusing;Libraries;Software;Maintenance;Frequency measurement;Software measurement","","","","34","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Decoding Dependency Risks: A Quantitative Study of Vulnerabilities in the Maven Ecosystem","C. Nachuma; M. M. Hossan; A. K. Turzo; M. F. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","270","274","This study investigates vulnerabilities within the Maven ecosystem by analyzing a comprehensive dataset of $14,459,139$ releases. Our analysis reveals the most critical weaknesses that pose significant threats to developers and their projects as they look to streamline their development tasks through code reuse. We show risky weaknesses, those unique to Maven, and emphasize those becoming increasingly dangerous over time. Furthermore, we reveal how vulnerabilities subtly propagate, impacting $31.39 \%$ of the 635,003 latest releases through direct dependencies and $62.89 \%$ through transitive dependencies. Our findings suggest that improper handling of input and mismanagement of resources pose the most risk. Additionally, Insufficient session-ID length in J2EE configuration and no throttling while allocating resources uniquely threaten the Maven ecosystem. We also find that weaknesses related to improper authentication and managing sensitive data without encryption have quickly gained prominence in recent years. These findings emphasize the need for proactive strategies to mitigate security risks in the Maven ecosystem.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025612","dependency vulnerability;maven central;software ecosystem;open source software","Java;Codes;Ecosystems;Focusing;Stability analysis;Encryption;Decoding;Security;Data mining;Open source software","","","","41","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Faster Releases, Fewer Risks: A Study on Maven Artifact Vulnerabilities and Lifecycle Management","M. S. Shafin; M. F. Rabbi; S. M. Mahedy Hasan; M. F. Zibran","Department of Computer Science, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","275","279","In modern software ecosystems, dependency management plays a critical role in ensuring secure and maintainable applications. However, understanding the relationship between release practices and their impact on vulnerabilities and update cycles remains a challenge. In this study, we analyze the release histories of $\mathbf{1 0, 0 0 0}$ Maven artifacts, covering over $\mathbf{2 0 3, 0 0 0}$ releases and 1.7 million dependencies. We evaluate how release speed affects software security and lifecycle. Our results show an inverse relationship between release speed and dependency outdatedness. Artifacts with more frequent releases maintain significantly shorter outdated times. We also find that faster release cycles are linked to fewer CVEs in dependency chains, indicating a strong negative correlation. These findings emphasize the importance of accelerated release strategies in reducing security risks and ensuring timely updates. Our research provides valuable insights for software developers, maintainers, and ecosystem managers.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00049","Idaho State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025608","Artifact;Release;Speed;Freshness;Outdated Time;CVE;Pearson’s correlation","Correlation coefficient;Correlation;Statistical analysis;Ecosystems;Continuous integration;Software;Security;History;Data mining","","","","39","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Insights into Dependency Maintenance Trends in the Maven Ecosystem","B. Chowdhury; M. F. Rabbi; S. M. Mahedy Hasan; M. F. Zibran","Department of Computer Science, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","280","284","As modern software development increasingly relies on reusable libraries and components, managing dependencies has become critical for ensuring software stability and security. However, challenges such as outdated dependencies, missed releases, and the complexity of interdependent libraries can significantly impact project maintenance. In this paper, we present a quantitative analysis of the Neo 4 j dataset using the Goblin framework to uncover patterns of freshness in projects with different numbers of dependencies. Our analysis reveals that releases with fewer dependencies have a higher number of missed releases. Additionally, our study shows that the dependencies in the latest releases have positive freshness scores, indicating better software management efficacy. These results can encourage better management practices and contribute to the overall health of software ecosystems.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00050","Idaho State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025745","Dependency management;freshness patterns;Maven;software stability;missed releases","Surveys;Ecosystems;Market research;Software;Libraries;Stability analysis;Maintenance;Complexity theory;Interviews;Software development management","","","","38","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Insights into Vulnerability Trends in Maven Artifacts: Recurrence, Popularity, and User Behavior","C. Bodily; E. Hill; A. Kramer; L. Kerby; M. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","285","289","Vulnerabilities in open-source software, particularly in ecosystems like Maven Central, propagate risks across projects. This paper examines vulnerability trends in Maven artifacts, focusing on recurrence patterns, user behavior after disclosures, and the link between popularity and exposure. Analyzing 24 vulnerable artifacts and $2,900+$ releases, we find recurring risks in previously vulnerable artifacts, significant intravs. extra-organizational differences in user behavior, and minimal correlation between popularity and vulnerability exposure. These results underscore the need for proactive security, effective disclosures, and better dependency management to strengthen ecosystem resilience.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025616","Artifact Popularity;Vulnerability Recurrence;User Behavior","Correlation;Shape;Scalability;Ecosystems;Refining;Market research;Sampling methods;Security;Open source software;Resilience","","","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Understanding Software Vulnerabilities in the Maven Ecosystem: Patterns, Timelines, and Risks","M. F. Rabbi; R. Paul; A. I. Champa; M. F. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States; Department of Computer Science, Idaho State University, Pocatello, ID, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","290","294","Vulnerabilities in software libraries and reusable components cause major security challenges, particularly in dependency-heavy ecosystems such as Maven. This paper presents a large-scale analysis of vulnerabilities in the Maven ecosystem using the Goblin framework. Our analysis focuses on the aspects and implications of vulnerability types, documentation delays, and resolution timelines. We identify 77,393 vulnerable releases with 226 unique CWEs. On average, vulnerabilities take nearly half a decade to be documented and 4.4 years to be resolved, with some remaining unresolved for even over a decade. The delays in documenting and fixing vulnerabilities incur security risks for the library users emphasizing the need for more careful and efficient vulnerability management in the Maven ecosystem.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00052","Idaho State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025783","security;vulnerability;Maven ecosystem","Access control;Software libraries;Prevention and mitigation;Ecosystems;Documentation;Software;Delays;Data mining","","","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Dependency Update Adoption Patterns in the Maven Software Ecosystem","B. Berretta; A. Thomas; H. Guarnera","Department of Mathematical and Computational Sciences, The College of Wooster, USA; Department of Mathematical and Computational Sciences, The College of Wooster, USA; Department of Mathematical and Computational Sciences, The College of Wooster, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","295","299","Regular dependency updates protect dependent software components from upstream bugs, security vulnerabilities, and poor code quality. Measures of dependency updates across software ecosystems involve two key dimensions: the time span during which a release is being newly adopted (adoption lifespan) and the extent of adoption across the ecosystem (adoption reach). We examine correlations between adoption patterns in the Maven software ecosystem and two factors: the magnitude of code modifications (extent of modifications affecting the meaning or behavior of the code, henceforth called “semantic change”) in an upstream dependency and the relative maintenance rate of upstream packages. Using the Goblin Weaver framework, we find adoption latency in the Maven ecosystem follows a log-normal distribution while adoption reach exhibits an exponential decay distribution.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025632","dependency management;maven ecosystem;semantic versioning;software updates;adoption patterns","Codes;Source coding;Semantics;Ecosystems;Static analysis;Software;Time measurement;Maintenance;Security;Software measurement","","","","20","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Analyzing Vulnerability Overestimation in the Maven Ecosystem","T. Draoui; F. Jebari; C. B. Slimen; M. Uppal; M. W. Mkaouer","University of Michigan-Flint, Flint, Michigan, USA; University of Michigan-Flint, Flint, Michigan, USA; University of Michigan-Flint, Flint, Michigan, USA; University of Michigan-Flint, Flint, Michigan, USA; University of Michigan-Flint, Flint, Michigan, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","300","303","The widespread use of third-party dependencies in software development has heightened concerns about security vulnerabilities, especially those introduced via transitive dependencies. Current vulnerability assessment tools often overestimate the attack surface by including bloated dependencies-unused components within dependency trees-leading to inflated risk evaluations. This paper investigates the role of bloated dependencies in vulnerability overestimation, focusing on Maven-based projects. Utilizing a dataset from Maven Central Dependency Graph, enriched with Weaver metrics, we identify patterns of dependency bloat and quantify its impact on risk assessments. Our findings demonstrate how excluding bloated dependencies from evaluations can provide a more accurate and actionable view of a project’s security risks. The study also discusses the limitations of existing tools, offering insights into refining vulnerability assessment methodologies for modern software ecosystems. Our artifacts are available at: https://github.com/smilevo/MavenVulnerability CCS Concepts • Software Engineering $\rightarrow$ Open source software; Vulnerability management","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025768","vulnerability assessment in maven central repository;bloated dependencies;mining software repositories","Measurement;Ecosystems;Refining;Focusing;Security;Data mining;Risk management;Open source software;Software engineering;Software development management","","","","10","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Dependency Dilemmas: A Comparative Study of Independent and Dependent Artifacts in Maven Central Ecosystem","M. H. Shanto; M. Asaduzzaman; M. Mondal; S. Chowdhury","Computer Science and Engineering Discipline, Khulna University, Bangladesh; School of Computer Science, University of Windsor, Canada; Computer Science and Engineering Discipline, Khulna University, Bangladesh; Department of Computer Science, University of Manitoba, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","304","308","Maven Central ecosystem forms the backbone of Java dependency management, hosting artifacts that vary significantly in their adoption, security, and ecosystem roles. Artifact reuse is fundamental in software development, and ecosystems like Maven facilitate this process. However, prior studies predominantly analyzed popular artifacts with numerous dependencies, leaving those without incoming dependencies (i.e., independent artifacts) unexplored. In this study, we analyzed 658,078 artifacts, of which 635,003 had at least one release. Among these, 93,101 artifacts (15.4%) were identified as independent (in-degree = 0), while the rest were classified as dependent. We looked at the impact of individual artifacts using PageRank and outdegree centrality and discovered that independent artifacts were very important to the ecosystem. Further analysis using 18 different metrics revealed several advantages and comparability of independent artifacts with dependent artifacts: comparable popularity ($\mathbf{2 5. 5 8}$ vs. 7.30), fewer vulnerabilities ($\mathbf{6 0}$ CVEs vs. 179 CVEs), and zero propagated vulnerabilities. These findings suggest that independent artifacts might be a beneficial choice for dependencies but have some maintenance issues. Therefore, developers should carefully incorporate independent artifacts into their projects, and artifact maintainers should prioritize this group of artifacts to mitigate the risk of transitive vulnerability propagation and improve software sustainability.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025581","Maven;dependencies;release;vulnerability;popularity","Surveys;Measurement;Time-frequency analysis;Java;Ecosystems;Software;Maintenance;Security;Sustainable development;Software development management","","","","16","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Cascading Effects: Analyzing Project Failure Impact in the Maven Central Ecosystem","M. Shehata; S. Makhkamjonoov; M. Syed; E. Parra","Dept. of Math, Computer Science, and Data Science, Belmont University, Nashville, TN, USA; Dept. of Math, Computer Science, and Data Science, Belmont University, Nashville, TN, USA; Dept. of Math, Computer Science, and Data Science, Belmont University, Nashville, TN, USA; Dept. of Math, Computer Science, and Data Science, Belmont University, Nashville, TN, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","309","313","This study examines failure propagation within the Maven Central ecosystem, a critical software dependency repository, through a comprehensive analysis of dependency networks using the Goblin framework. Our dual-sampling methodology, investigating both top dependencies and random libraries, revealed two distinct failure propagation patterns that pose significant risks to ecosystem stability. Core infrastructure failures, particularly evident in cases like the AWS SDK family, can create immediate and widespread disruption. These libraries have many direct dependents - averaging 20,402 projects that would break immediately if the library fails. Furthermore, these core libraries themselves have extensive dependencies, with the AWS SDK family depending on 377 other libraries itself. The impact of failures spreads deeply through the ecosystem, with dependency chains reaching an average of 90.80 levels. Our analysis of peripheral projects reveals their significant cascading effects, with higher average dependency depths of 54.25 levels and chain lengths extending to 116.74 levels, as exemplified by cases like org.apache.camel:camel-swagger-java, which demonstrated a maximum chain length of 647 levels. Our findings highlight specific vulnerabilities in dependency network structures, showing that ecosystem resilience requires both protecting core infrastructure and managing dependency complexity.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025804","Software Dependencies;Maven Central;Ecosystem Analysis;Failure Propagation;Dependency Networks;Software Maintenance;Infrastructure Resilience;Graph Analysis","Software maintenance;Ecosystems;Power system protection;Focusing;Libraries;Stability analysis;Complexity theory;Protection;Power system faults;Resilience","","","","15","CCBY","13 Jun 2025","","","IEEE","IEEE Conferences"
"Do Developers Depend on Deprecated Library Versions? A Mining Study of Log4j","H. Yoshioka; S. Lertbanjongngam; M. Inaba; Y. Fan; T. Nakano; K. Shimari; R. G. Kula; K. Matsumoto","Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Information Science and Technology, Osaka University; Graduate School of Science and Technology, Nara Institute of Science and Technology",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","314","318","Log4j has become a widely adopted logging library for Java programs due to its long history and high reliability. Its widespread use is notable not only because of its maturity but also due to the complexity and depth of its features, which have made it an essential tool for many developers. However, Log4j 1.x, which reached its end of support (deprecated), poses significant security risks and has numerous deprecated features that can be exploited by attackers. Despite this, some clients may still rely on this library. We aim to understand whether clients are still using Log4j 1.x despite its official support ending. We utilized the Mining Software Repositories 2025 challenge dataset, which provides a large and representative sample of open-source software projects. We analyzed over 10,000 log entries from the Mining Software Repositories 2025 challenge dataset using the Goblin framework to identify trends in usage rates for both Log4j 1.x and Log4j-core 2.x. Specifically, our study addressed two key issues: (1) We examined the usage rates and trends for these two libraries, highlighting any notable differences or patterns in their adoption. (2) We demonstrate that projects initiated after a deprecated library has reached the end of its support lifecycle can still maintain significant popularity. These findings highlight how deprecated are still popular, with the next step being to understand the reasoning behind these adoptions.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025729","Log4j;Security Vulnerabilities;Library Migration","Java;Market research;Libraries;Cognition;Complexity theory;Data mining;Security;Reliability;History;Open source software","","","","12","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Mining for Lags in Updating Critical Security Threats: A Case Study of Log4j Library","H. Tanaka; K. Yamasaki; M. Hirose; T. Nakano; Y. Fan; K. Shimari; R. G. Kula; K. Matsumoto","Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Science and Technology, Nara Institute of Science and Technology; Graduate School of Information Science and Technology, Osaka University; Graduate School of Science and Technology, Nara Institute of Science and Technology",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","319","323","The Log4j-Core vulnerability, known as Log4Shell, exposed significant challenges to dependency management in software ecosystems. When a critical vulnerability is disclosed, it is imperative that dependent packages quickly adopt patched versions to mitigate risks. However, delays in applying these updates can leave client systems exposed to exploitation. Previous research has primarily focused on NPM, but there is a need for similar analysis in other ecosystems, such as Maven. Leveraging the 2025 mining challenge dataset of Java dependencies, we identify factors influencing update lags and categorize them based on version classification (major, minor, patch release cycles). Results show that lags exist, but projects with higher release cycle rates tend to address severe security issues more swiftly. In addition, over half of vulnerability fixes are implemented through patch updates, highlighting the critical role of incremental changes in maintaining software security. Our findings confirm that these lags also appear in the Maven ecosystem, even when migrating away from severe threats.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025604","Log4j;CVEs;Log4Shell;dependency;critical vulnerability;release frequency","Java;Ecosystems;Software;Libraries;Delays;Security;Data mining","","","","14","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"On the Evolution of Unused Dependencies in Java Project Releases: An Empirical Study","N. Suwanachote; Y. Shakizada; Y. Kashiwa; B. Lin; H. Iida","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Hangzhou Dianzi University, China; Nara Institute of Science and Technology, Japan",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","324","328","Modern software development heavily relies on third-party dependencies to reduce workload and improve developer productivity. Given the vast number of dependencies available and the ease of including them in projects, some introduced dependencies are never used, leading to bloated software, longer build times, and increased network bandwidth usage. While several previous studies have examined the prevalence of unused dependencies and their impact on security, it remains unclear how these dependencies are introduced and removed in software projects. This study aims to answer this question through an empirical study involving 3,020 release versions of 417 Java projects. Our analysis shows that unused packages are common in most projects ($52 \%$ of projects), but few releases (9%) introduce new unused dependencies. Among those resolved unused dependencies, $59 \%$ of them were removed and $41 \%$ were used in later versions. Our findings highlight that not all unused dependencies should be removed in practice.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025630","Dependencies;Packages;Empirical Study","Productivity;Java;Bandwidth;Software;Security;Data mining;Software development management","","","","19","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Out of Sight, Still at Risk: The Lifecycle of Transitive Vulnerabilities in Maven","P. Przymus; M. Fejzer; J. Narębski; K. Rykaczewski; K. Stencel","Nicolaus Copernicus University in Toruń, Toruń, Poland; Nicolaus Copernicus University in Toruń, Toruń, Poland; Nicolaus Copernicus University in Toruń, Toruń, Poland; Nicolaus Copernicus University in Toruń, Toruń, Poland; University of Warsaw, Toruń, Poland",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","329","333","The modern software development landscape heavily relies on transitive dependencies. They enable seamless integration of third-party libraries. However, they also introduce security challenges. Transitive vulnerabilities that arise from indirect dependencies expose projects to risks associated with Common Vulnerabilities and Exposures (CVEs). It happens even when direct dependencies remain secure. This paper examines the lifecycle of transitive vulnerabilities in the Maven ecosystem. We employ survival analysis to measure the time projects remain exposed after a CVE is introduced. Using a large dataset of Maven projects, we identify factors that influence the resolution of these vulnerabilities. Our findings offer practical advice on improving dependency management.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025601","CVE;Mining software repositories;Software quality","Ecosystems;Software quality;Time measurement;Libraries;Delays;Security;Data mining;Software development management","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Popularity and Innovation in Maven Central","N. Ede; J. Dietrich; U. Zülicke","Victoria University of Wellington, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","334","338","Maven Central is a large popular repository of Java components that has evolved over the last 20 years. The distribution of dependencies indicates that the repository is dominated by a relatively small number of components other components depend on. The question is whether those elites are static, or change over time, and how this relates to innovation in the Maven ecosystem. We study those questions using several metrics. We find that elites are dynamic, and that the rate of innovation is slowing as the repository ages but remains healthy.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025753","software ecosystems;software evolution;innovation;open source software;software repositories;maven;secos","Measurement;Technological innovation;Java;Ecosystems;Software;Data mining","","","","43","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Software Bills of Materials in Maven Central","Y. Gamage; N. G. Fernandez; M. Monperrus; B. Baudry",Université de Montréal; Université de Montréal; KTH Royal Institute of Technology; Université de Montréal,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","339","343","Software Bills of Materials (SBOMs) are essential to ensure the transparency and integrity of the software supply chain. There is a growing body of work that investigates the accuracy of SBOM generation tools and the challenges for producing complete SBOMs. Yet, there is little knowledge about how developers distribute SBOMs. In this work, we mine SBOMs from Maven Central to assess the extent to which developers publish SBOMs along with the artifacts. We develop our work on top of the Goblin framework, which consists of a Maven Central dependency graph and a Weaver that allows augmenting the dependency graph with additional data. For this study, we select a sample of 10% of release nodes from the Maven Central dependency graph and collected 14,071 SBOMs from 7,290 package releases. We then augment the Maven Central dependency graph with the collected SBOMs. We present our methodology to mine SBOMs, as well as novel insights about SBOM publication. Our dataset is the first set of SBOMs collected from a package registry. We make it available as a standalone dataset, which can be used for future research about SBOMs and package distribution.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025737","software bills of materials;maven central;dependency graph;package registry;programmerhumor","Accuracy;Bills of materials;Supply chains;Production;Documentation;Software;Data mining;Stress;Faces","","","","17","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"The Ripple Effect of Vulnerabilities in Maven Central: Prevalence, Propagation, and Mitigation Challenges","E. U. Haq; S. Wang; R. S. Allison","Lassonde School of Engineering, York University, Toronto, Canada; Lassonde School of Engineering, York University, Toronto, Canada; Lassonde School of Engineering, York University, Toronto, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","344","348","The widespread use of package managers like Maven has accelerated software development but has also introduced significant security risks due to vulnerabilities in dependencies. In this study, we analyze the prevalence and impact of vulnerabilities within the Maven Central ecosystem, using Common Vulnerabilities and Exposures (CVE) data from OSV.dev and a subsample enriched with aggregated CVE data (CVE_AGGREGATED), which captures both direct and transitive vulnerabilities. In our subsample of around 4 million releases, we found that while only about $1 \%$ of releases have direct vulnerabilities, approximately $46.8 \%$ are affected by transitive vulnerabilities. This highlights how a small number of vulnerable yet influential artifacts can impact a vast portion of the ecosystem. Moreover, our analysis shows that vulnerabilities propagate rapidly through dependency networks and that more central artifacts (those with a high number of dependents) are not necessarily less vulnerable. We also observed that the time taken to patch vulnerabilities, including those of high or critical severity, often spans several years. Additionally, we found that dependents of artifacts tend to prefer presumably non-vulnerable versions; however, some continue to use vulnerable versions, indicating challenges in adopting patched releases. These findings highlight the critical need for improved dependency management practices and timely vulnerability remediation to enhance the security of software ecosystems.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025606","Software Ecosystems;Software Dependencies;Vulnerability Propagation;Vulnerability Patch Time","Prevention and mitigation;Ecosystems;Pipelines;Documentation;Software;Security;Data mining;Software development management;Resilience","","","","11","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Tracing Vulnerabilities in Maven: A Study of CVE lifecycles and Dependency Networks","C. Yang-Smith; A. Abdellatif","University of Calgary, Calgary, Canada; University of Calgary, Calgary, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","349","353","Software ecosystems rely on centralized package registries, such as Maven, to enable code reuse and collaboration. However, the interconnected nature of these ecosystems amplifies the risks posed by security vulnerabilities in direct and transitive dependencies. While numerous studies have examined vulnerabilities in Maven and other ecosystems, there remains a gap in understanding the behavior of vulnerabilities across parent and dependent packages, and the response times of maintainers in addressing vulnerabilities. This study analyzes the lifecycle of 3,362 CVEs in Maven to uncover patterns in vulnerability mitigation and identify factors influencing at-risk packages. We conducted a comprehensive study integrating temporal analyses of CVE lifecycles, correlation analyses of GitHub repository metrics, and assessments of library maintainers’ response times to patch vulnerabilities, utilizing a package dependency graph for Maven. A key finding reveals a trend in “Publish-Before-Patch” scenarios: maintainers prioritize patching severe vulnerabilities more quickly after public disclosure, reducing response time by 48.3% from low (151 days) to critical severity (78 days). Additionally, project characteristics, such as contributor absence factor and issue activity, strongly correlate with the presence of CVEs. Leveraging tools such as the Goblin Ecosystem, OSV.dev, and OpenDigger, our findings provide insights into the practices and challenges of managing security risks in Maven.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025716","Software Ecosystems;Maven;Software Vulnerabilities","Measurement;Prevention and mitigation;Ecosystems;Collaboration;Market research;Software;Libraries;Time factors;Security;Software development management","","1","","35","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Understanding Abandonment and Slowdown Dynamics in the Maven Ecosystem","K. A. Hasan; J. Yasmin; H. Hao; Y. Tian; S. Hassan; S. H. H. Ding","School of Computing, Queen’s University, Kingston, ON, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; University of Toronto, Toronto, ON, Canada; McGill University, Montreal, Quebec, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","354","358","The sustainability of libraries is critical for modern software development, yet many libraries face abandonment, posing significant risks to dependent projects. This study explores the prevalence and patterns of library abandonment in the Maven ecosystem. We investigate abandonment trends over the past decade, revealing that approximately one in four libraries fail to survive beyond their creation year. We also analyze the release activities of libraries, focusing on their lifespan and release speed, and analyze the evolution of these metrics within the lifespan of libraries. We find that while slow release speed and relatively long periods of inactivity are often precursors to abandonment, some abandoned libraries exhibit bursts of high frequent release activity late in their life cycle. Our findings contribute to a new understanding of library abandonment dynamics and offer insights for practitioners to identify and mitigate risks in software ecosystems.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025680","","Measurement;Ecosystems;Focusing;Market research;Libraries;Software;Data mining;Sustainable development;Faces;Software development management","","","","19","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Characterizing Packages for Vulnerability Prediction","S. Owolabi; F. Rosati; A. Abdellatif; L. D. Carli","University of Calgary, Alberta, Canada; University of Calgary, Alberta, Canada; University of Calgary, Alberta, Canada; University of Calgary, Alberta, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","359","363","Modern software development relies heavily on the use of external libraries and packages as software reuse provides benefits, such as reduced time to market and lower development cost. However, these libraries often come with their own set of direct and indirect dependencies which could introduce vulnerabilities, compromising the security of end users. Prior work shows that developers may remain unaware of these vulnerabilities until a security incident that exploits them occurs, leading to potential consequences for data privacy. Therefore, it is essential for developers to have the ability, before committing time to a project, to understand whether the external libraries and packages they intend to use may induce vulnerabilities, and how that might happen. In our work, we use the dataset made available by the Goblin framework to identify and evaluate salient features for predicting the vulnerability profile of software packages. We use these features to build classifiers for predicting whether or not a dependency-related vulnerability will occur within 3, 6, or 12 months. Our approach proves to be effective, achieving F1-scores of 0.74, 0.79 and 0.86 in the 3, 6, and 12 month contexts respectively. Providing timely vulnerability information could help developers identify potential security weaknesses before deploying a package to production, thereby minimizing the risk of security incidents.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025792","Dependency Analysis;Vulnerability Prediction;Software Security;Machine Learning;CVE Analysis;Goblin Framework;Neo4J;Maven Central","Data privacy;Costs;Software packages;Time to market;Production;Machine learning;Libraries;Security;Software reusability;Software development management","","","","39","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Understanding the Popularity of Packages in Maven Ecosystem","S. J. Sakib; M. Asaduzzaman; C. Bright; C. Morgan","School of Computer Science, University of Windsor, Windsor, ON, Canada; School of Computer Science, University of Windsor, Windsor, ON, Canada; School of Computer Science, University of Windsor, Windsor, ON, Canada; School of Computer Science, University of Windsor, Windsor, ON, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","364","368","The widespread availability of open-source software packages in ecosystems like Maven has significantly improved developer productivity by promoting the reuse of pre-existing packages. However, the vast number of available packages often poses challenges in selecting suitable packages. This study investigates the role of popularity metrics in evaluating Maven packages by analyzing 103,315 packages, each at least two years old. Metrics were collected from the Maven Neo4j dataset and GitHub repositories to examine their relationships and importance in determining package popularity. Our analysis reveals strong interdependencies among community-driven GitHub metrics, such as stars, forks, pull requests, and contributors, which highlight their role in defining package popularity. Conversely, Maven-specific metrics, including dependencies and vulnerabilities, showed weak correlations with GitHub-based popularity indicators. Our analysis identified license status, commits count, presence of README files, and usages as the most significant predictors of package popularity, while vulnerabilities had limited statistical impact. These findings underscore the complementary nature of technical and community-driven metrics in assessing package popularity and provide actionable insights for developers and researchers to better evaluate and select open-source software packages.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025736","Popularity Metrics;Software Packages;Maven;GitHub","Measurement;Productivity;Software packages;Ecosystems;Stars;Documentation;Licenses;Market research;Open source software;Software development management","","","","12","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Navigating and Exploring Software Dependency Graphs Using Goblin","D. Jaime; J. E. Haddad; P. Poizat","Sorbonne Université, CNRS, LIP6, Université Paris Nanterre, Paris, France; Université Paris Dauphine - PSL, CNRS, LAMSADE, Paris, France; Sorbonne Université, CNRS, LIP6, Université Paris Nanterre, Paris, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","369","371","Using package managers is a simple and common method for reusing code through project dependencies. However, these, direct, dependencies can themselves rely on additional packages, resulting in indirect dependencies. It may then become complex to get a grasp of the whole set of dependencies of a project. Beyond studying individual projects, a deep understanding of software ecosystems is also a critical prerequisite for achieving sustained success in software development. This paper presents the 2025 edition of the MSR conference mining challenge. This year’s mining challenge focuses on dependencies and dependency ecosystem analysis using the Goblin framework that has been presented at the previous edition of the MSR conference. Goblin is composed of a Neo4j Maven Central dependency graph and a tool called Weaver for on-demand metric weaving into dependency graphs. As a whole, Goblin is a customizable framework for ecosystem and dependency analysis.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025627","software ecosystem;dependency graph;dataset;mining software repositories;maven central","Measurement;Codes;Navigation;Ecosystems;Software;Weaving;Data mining;Software development management","","20","","5","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"50 Years of Programming Language Evolution through the Software Heritage looking glass","A. Desmazières; R. D. Cosmo; V. Lorentz","Sorbonne University, France; Inria and University Paris Cité, France; Inria Foundation, Inria, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","372","383","Programming languages have evolved rapidly over the past five decades, reflecting broader shifts in software development practices and technological advances. Early on, entities like the U.S. Department of Defense recognized the challenges posed by diverse programming languages, leading to initiatives such as the Ada programming language. Since then, indexes like Tiobe, RedMonk, and Open Hub have attempted to track language popularity, though their metrics provide only a snapshot view, and most of them do not make available their data. We show that Software Heritage, the largest public archive of source code, makes it now possible, and easy, to address this question in a comprehensive, transparent and reproducible manner through its unified dataset, which includes over 20 billion source files and 4 billion commits. As a result of our study, we have created a dataset and pipeline that allows to analyze five decades of programming language trends, by measuring the programming activity as seen in the Software Heritage archive, confirming trends in language adoption, shifts in popularity, and significant transitions linked to technological changes. The comparison with the existing indexes shows rather good alignment for the first positions in the rankings, but differences emerge down the line, as programmer activity, and language popularity are not necessary aligned. To facilitate further research on programming language evolution, we publish the whole software pipeline as Open Source, and make available the full dataset, that will be updated bi-annually.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025697","","Computer languages;Source coding;Pipelines;Glass;Programming;Market research;Software;Indexes;Software measurement;Software development management","","","","18","CCBY","13 Jun 2025","","","IEEE","IEEE Conferences"
"It Works (only) on My Machine: A Study on Reproducibility Smells in Ansible Scripts","G. Sobhani; I. Haque; T. Sharma","Faculty of Computer Science, Dalhousie University, Halifax, Canada; Faculty of Computer Science, Dalhousie University, Halifax, Canada; Faculty of Computer Science, Dalhousie University, Halifax, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","384","395","Infrastructure as Code (IaC) automates the creation, configuration, management, and monitoring of computing infrastructure through code. One of the key principles that IaC promises is repeatability and reproducibility. However, certain programming practices in IaC platforms, especially those that allow imperative configuration, such as Ansible, hinder reproducibility in IaC scripts. This study, first, identifies such programming practices that we refer to as reproducibility smells by conducting a comprehensive multi-vocal literature review and propose a first-ever validated catalog of reproducibility smells for IaC scripts. We implement a tool viz. Reduse to identify reproducibility smells in Ansible scripts. Furthermore, we conduct an empirical study to reveal the proliferation of reproducibility smells in open-source projects and explore correlation and fine-grained co-occurrence relationships among them. We observe that broken dependency chain smell occurs the most in approximately $71 \%$ tasks that we analyzed. Our analysis uncovers significant positive correlations between specific reproducibility smells, implying that repositories with one such smell tend to exhibit others. Moreover, the co-occurrence analysis reveals smell pairs that show a high tendency of co-occurrence at the task granularity. With the developed tool Reduse, DevOps engineers can identify and rectify reproducibility issues before becoming part of the production system. Software engineering researchers can use the smells catalog proposed first in this study and can utilize Reduse in empirical studies exploring various facets of reproducibility.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025635","Infrastructure as Code;Ansible;Reproducibility;Reproducibility smells","Production systems;Correlation;DevOps;Programming;Reproducibility of results;Software;Data mining;Monitoring;Systematic literature review;Software engineering","","","","73","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Are the Majority of Public Computational Notebooks Pathologically Non-Executable?","T. Nguyen; W. Gill; M. A. Gulzar","Virginia Tech, Blacksburg, USA; Virginia Tech, Blacksburg, USA; Virginia Tech, Blacksburg, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","396","407","Computational notebooks are the de facto platform for exploratory data science, offering an interactive programming environment where users can create, modify, and execute code cells in any sequence. However, this flexibility often introduces code quality issues, with prior studies showing that approximately $76 \%$ of public notebooks are non-executable, raising significant concerns about reusability. We argue that the traditional notion of executability—requiring a notebook to run fully and without error—is overly rigid, misclassifying many notebooks and overestimating their non-executability. This paper investigates pathological executability issues in public notebooks under varying notions and degrees of executability. Notebooks, by construction, are incrementally and interactively executed, where each cell execution advances logic toward the notebook’s goal. Even partially improving executability can improve code comprehension and offer a pathway for dynamic analyses. With this insight, we first categorize notebooks into potentially restorable and pathological non-executable notebooks and then measure how removing misconfiguration and superficial execution issues in notebooks can improve their executability (i.e., additional cells executed without error). For instance, we use a Large Language Model (LLM) to generate synthetic input data to restore non-executable notebooks with “FileNotFound” errors. In a dataset of 42,546 popular public notebooks, containing 34,659 non-executable notebooks, only $21.3 \%$ are truly pathologically non-executable. For restorable notebooks, LLM-based methods fully restore $5.4 \%$ of previously nonexecutable notebooks. Among the partially restored, it improves the notebooks’ executability by $\mathbf{4 0. 5 \%}$ and $\mathbf{2 8 \%}$ by installing the correct modules and generating synthetic data. These findings challenge prior assumptions, suggesting that notebooks have higher executability than previously reported, many of which offer valuable partial execution, and that their executability should be evaluated within the interactive notebook paradigm rather than through traditional software executability standards.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00070","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025746","Computational notebooks;non-executability;restoration;mining software repositories","Pathology;Codes;Measurement uncertainty;Data science;Software;Data mining;Logic;Standards;Synthetic data;Programming environments","","","","54","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Understanding Test Deletion in Java Applications","S. Bhatta; F. Kendemah; A. K. Jha","North Dakota State University, Fargo, USA; North Dakota State University, Fargo, USA; North Dakota State University, Fargo, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","408","420","Obsolete and redundant tests increase regression testing costs. Therefore, developers should remove them from test suites; however, identifying these tests is non-trivial. Automated techniques for identifying obsolete and redundant tests could help developers reduce regression testing costs. Nonetheless, we have limited empirical evidence of how and why developers delete tests. Therefore, in this work, we first create DelTest, a dataset of 24,431 manually confirmed deleted tests, by analyzing 449,592 commits from seven open-source Java projects. We then perform an empirical study on DelTest to understand test deletion. Our findings show that test deletion frequency and the number of deleted tests vary significantly across projects, suggesting that test deletion is more likely driven by project-specific needs than the broader development cycle. Developers delete only one or two tests in most commits, suggesting test deletion is mostly small and incremental. In DelTest, 83.2% of tests are deleted along with the corresponding test classes, while $16.8 \%$ are deleted individually. We find that $91.4 \%$ of deleted tests in six projects are obsolete tests (i.e., production code is deleted), $7 \%$ are redundant tests (i.e., passing tests), and $1.6 \%$ are failing tests. The deletion of $20 \%$ of redundant tests reduces code coverage or mutation scores. We also evaluate test suite reduction (TSR) approaches on DelTEST and find that a TSR approach identifies up to 54% of the redundant tests. Our findings can help improve automated techniques for identifying obsolete and redundant tests.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025602","Test deletion;test suite evolution;test suite reduction;test suite maintenance;regression testing","Java;Codes;Costs;Production;Software;Maintenance;Data mining;Testing;Software development management","","","","61","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"A Public Benchmark of REST APIs","A. Decrop; S. Eraso; X. Devroey; G. Perrouin","NADI, University of Namur, Namur, Belgium; University of Valle, Cali, Valle del Cauca, Colombia; NADI, University of Namur, Namur, Belgium; NADI, University of Namur, Namur, Belgium",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","421","433","In software engineering, benchmarks are widely used to evaluate and compare the performance, functionality, and reliability of analysis tools. Despite the prevalence of benchmarks in areas such as databases, machine learning, and programming languages, there is a notable absence of publicly available benchmarks for REST APIs, a cornerstone of modern web-based systems. While existing research papers occasionally employ similar REST APIs in their evaluations, opportunistic API selection hampers comparison. Moreover, these studies often rely on API documentation and structural characteristics. Without a reliable benchmark, API data used in evaluations may be outdated or inaccurate, compromising reliability and reproducibility. Hence, this paper addresses a gap in the literature by providing a comprehensive and Public REST API Benchmark (PRAB), to be utilized by researchers in their evaluations. The benchmark contains documentation and structural characteristics of 60 publicly available REST APIs. First, we conduct a systematic mapping study to discover the available and public REST APIs that are utilized in the academic literature. Then, by analyzing the resulting APIs, we report their structural characteristics (e.g., routes, query parameters, HTTP methods, authentication). Finally, we provide their documentation (i.e., OpenAPI Specification, Postman Collection) in a publicly available GitHub repository, to help with future evaluations of REST API studies.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025751","REST API;Benchmark;Documentation;OpenAPI Specification;Testing;Systematic mapping study","Systematics;Documentation;Benchmark testing;Reliability engineering;Software;Reproducibility of results;HTTP;Software reliability;Software engineering;Software development management","","","","105","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"What Do Contribution Guidelines Say About Software Testing?","B. Falcucci; F. Gomide; A. Hora","Department of Computer Science, UFMG, Belo Horizonte, Brazil; Department of Computer Science, UFMG, Belo Horizonte, Brazil; Department of Computer Science, UFMG, Belo Horizonte, Brazil",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","434","438","Software testing plays a crucial role in the contribution process of open-source projects. For example, contributions introducing new features are expected to include tests, and contributions with tests are more likely to be accepted. Although most real-world projects require contributors to write tests, the specific testing practices communicated to contributors remain unclear. In this paper, we present an empirical study to understand better how software testing is approached in contribution guidelines. We analyze the guidelines of 200 Python and JavaScript open-source software projects. We find that $78 \%$ of the projects include some form of test documentation for contributors. Test documentation is located in multiple sources, including CONTRIBUTING files ($\mathbf{5 8 \%}$), external documentation ($\mathbf{2 4 \%}$), and README files ($\mathbf{8 \%}$). Furthermore, test documentation commonly explains how to run tests ($83.5 \%$), but less often provides guidance on how to write tests $(37 \%)$. It frequently covers unit tests $(71 \%)$, but rarely addresses integration ($\mathbf{2 0. 5 \%}$) and end-to-end tests ($\mathbf{1 5. 5 \%}$). Other key testing aspects are also less frequently discussed: test coverage ($\mathbf{2 5. 5 \%}$) and mocking ($\mathbf{9. 5 \%}$). We conclude by discussing implications and future research.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00073","EMI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025800","Software Testing;Contribution Guidelines;Empirical Studies;GitHub","Software testing;Documentation;Data mining;Open source software;Guidelines;Software development management;Python","","","","21","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Measuring InnerSource Value","C. de Silva; D. I. Cortázar","FINOS Innersource SIG Lead Citibank, London, United Kingdom; Bitergia, Madrid, Spain",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","439","440","InnerSource practices, inspired by open source methodologies, offer significant value to organizations by fostering software reuse, improving collaboration, and eliminating inefficiencies [1]. However, quantifying this value is essential to justify investments and sustain InnerSource initiatives. This paper presents a framework to measure the impact of InnerSource projects in the financial industry defining four key areas and their corresponding data gathering strategies. It focuses on metrics for cost savings through reuse, enhanced time-to-market, reduced maintenance expenses, and improved engineering health. By leveraging automated tools, surveys, and analytical models, organizations can assess the financial benefits of InnerSource contributions while fostering transparency and collaboration among teams [2]. This approach provides actionable insights to drive strategic decisions and optimize software development processes.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025738","financial industry;innersource;value","Surveys;Collaboration;Organizations;Maintenance;Software measurement;Data mining;Software reusability;Financial industry;Software development management;Investment","","","","4","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"CoUpJava: A Dataset of Code Upgrade Histories in Open-Source Java Repositories","K. Jiang; B. Jin; P. Nie","University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","441","445","Modern programming languages are constantly evolving, introducing new language features and APIs to enhance software development practices. Software developers often face the tedious task of upgrading their codebase to new programming language versions. Recently, large language models (LLMs) have demonstrated potential in automating various code generation and editing tasks, suggesting their applicability in automating code upgrade. However, there exists no benchmark for evaluating the code upgrade ability of LLMs, as distilling code changes related to programming language evolution from real-world software repositories’ commit histories is a complex challenge. In this work, we introduce CoUpJava, the first large-scale dataset for code upgrade, focusing on the code changes related to the evolution of Java. CoUpJava comprises 10,697 code upgrade samples, distilled from the commit histories of 1,379 open-source Java repositories and covering Java versions 7–23. The dataset is divided into two subsets: CoUpJava-FINE, which captures fine-grained method-level refactorings towards new language features; and CoUpJava-COARSE, which includes coarse-grained repository-level changes encompassing new language features, standard library APIs, and build configurations. Our proposed dataset provides high-quality samples by filtering irrelevant and noisy changes and verifying the compilability of upgraded code. Moreover, CoUpJava reveals diversity in code upgrade scenarios, ranging from small, fine-grained refactorings to large-scale repository modifications.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00075","Natural Sciences and Engineering Research Council of Canada; University of Waterloo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025747","Code upgrade;software evolution;Java;dataset;benchmark","Java;Computer languages;Codes;Benchmark testing;Software;Libraries;History;Noise measurement;Standards;Software development management","","","","32","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"EvoChain: A Framework for Tracking and Visualizing Smart Contract Evolution","I. Qasse; M. Hamdaqa; B. Þ. Jónsson","Department of Computer Science, Reykjavik University, Reykjavik, Iceland; Department of Computer Science, Reykjavik University, Reykjavik, Iceland; Department of Computer Science, Reykjavik University, Reykjavik, Iceland",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","446","450","Tracking the evolution of smart contracts is challenging due to their immutable nature and complex upgrade mechanisms. We introduce EvoChain, a comprehensive framework and dataset designed to track and visualize smart contract evolution. Building upon data from our previous empirical study, EvoChain models contract relationships using a Neo4j graph database and provides an interactive web interface for exploration. The framework consists of a data layer, an API layer, and a user interface layer. EvoChain allows stakeholders to analyze contract histories, upgrade paths, and associated vulnerabilities by leveraging these components. Our dataset encompasses approximately 1.3 million upgradeable proxies and nearly 15,000 historical versions, enhancing transparency and trust in blockchain ecosystems by providing an accessible platform for understanding smart contract evolution.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025638","Proxy Contracts;Smart Contracts;Immutability;Software Maintenance;Versions","Software maintenance;Databases;Smart contracts;Ecosystems;Data visualization;Data models;Blockchains;Stakeholders;Security;Predictive analytics","","","","23","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"CoDocBench: A Dataset for Code-Documentation Alignment in Software Maintenance","K. Pai; P. Devanbu; T. Ahmed","University of California, Davis, USA; University of California, Davis, USA; University of California, Davis, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","451","455","One of the central tasks in software maintenance is being able to understand and develop code changes. Thus, given a natural language description of the desired new operation of a function, an agent (human or AI) might be asked to generate the set of edits to that function to implement the desired new operation; likewise, given a set of edits to a function, an agent might be asked to generate a changed description, of that function’s new workings. Thus, there is an incentive to train a neural model for change-related tasks. Motivated by this, we offer a new, “natural”, large dataset of coupled changes to code and documentation mined from actual high-quality GitHub projects, where each sample represents a single commit where the code and the associated docstring were changed together. We present the methodology for gathering the dataset, and some sample, challenging (but realistic) tasks where our dataset provides opportunities for both learning and evaluation. We find that current models (specifically Llama-3.1 405B, Mixtral $8 \times 22 \mathrm{~B}$) do find these maintenance-related tasks challenging.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00077","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025763","llms;code generation;docstring generation","Software maintenance;Codes;Source coding;Natural languages;Documentation;Data mining;Artificial intelligence;Software development management","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"RefExpo: Unveiling Software Project Structures through Advanced Dependency Graph Extraction","V. Haratian; P. Derakhshanfar; V. Kovalenko; E. Tüzün","Bilkent University, Ankara, Turkey; JetBrains Research, Amsterdam, The Netherlands; JetBrains Research, Amsterdam, The Netherlands; Bilkent University, Ankara, Turkey",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","456","460","The dependency graph (DG) of a software project offers valuable insights for identifying its key components and, hence has been leveraged in numerous studies. Nevertheless, there is a lack of reusable tools for DG extraction. Existing tools are either outdated and difficult to configure, or fail to provide accurate analysis. However, Integrated Development Environments (IDEs) are designed to address the above issues. This study introduces RefExpo2, a reusable DG extraction tool that supports multiple languages, such as Java, Python, and JavaScript. RefExpo is a plugin based on IntelliJ which is a wellmaintained and reputed IDE. In addition, we compile an initial version of our dataset consisting of 20 Java and Python projects. We evaluated RefExpo’s validity at two levels: specific language features and comparisons against other existing tools, which we refer to as the micro and macro levels. Our evaluation shows RefExpo achieving 92% and 100% recall on micro test suites Judge and PyCG for Python and Java, respectively. In macrolevel experiments, RefExpo outperformed existing tools by at least 31 % and 7 % in finding unique and shared results (nonoverlapping and overlapping with other tools). The installable version of RefExpo is available on the IntelliJ marketplace3. Additionally, a short video describing its functionality is available on YouTube 1.1https://youtu.be/eCnPUlj6YgA","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025643","Software Analytics;Dependency Graph;Call Graph;Code Referencing;Software Structure;Software Architecture","Java;Codes;Video on demand;Software architecture;Software;Data mining;Web sites;Reliability;Python;Software development management","","","","37","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"HyperAST: Incrementally Mining Large Source Code Repositories","Q. Le Dilavrec; A. Zaidman","Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","461","464","Modern software systems are large, with a project like Chromium reaching more than 30 million lines of code. Analyzing these large-scale projects over multiple versions rapidly becomes very expensive, and creating tools that can work at this scale is a challenge. This paper presents the HyperAST approach, that exploits the locality and redundancy of source code, to maintain thousands of Syntax Tree (AST) versions in memory. In particular, we contribute a programmatic interface to HyperAST that helps define the incremental computation of code metrics and efficient explorations of the fine-grained abstract syntax representation of source code.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025775","software repository mining;software maintenance","Measurement;Software maintenance;Codes;Source coding;Redundancy;Syntactics;Chromium;Software systems;Computational efficiency;Data mining","","","","7","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks Before and After Fine-tuning","F. Salerno; A. Al-Kaswan; M. Izadi","Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","465","477","Code language models, while widely popular, are often trained on unsanitized source code gathered from across the Internet. Previous work revealed that pre-trained models can remember the content of their training data and regurgitate them through data extraction attacks. Due to the large size of current models, only a few entities have the resources for pre-training such models. However, fine-tuning requires fewer resources and is increasingly used by both small and large entities for its effectiveness on specialized data. Such small curated data for finetuning might contain sensitive information or proprietary assets. In this study, we attack both pre-trained and fine-tuned code language models to investigate the extent of data extractability. We first develop a custom benchmark to assess the vulnerability of both pre-training and fine-tuning samples to extraction attacks. Our findings reveal that $54.9 \%$ of extractable pre-training data could be retrieved from StarCoder2-15B, whereas this number decreased to $\mathbf{2 3. 5 \%}$ after fine-tuning. This indicates that finetuning reduces the extractability of pre-training data. However, compared to larger models, fine-tuning smaller models increases their vulnerability to data extraction attacks on fine-tuning data. Given the potential sensitivity of fine-tuning data, this can lead to more severe consequences. Lastly, we also manually analyzed 2000 extractable samples before and after fine-tuning. We also found that data carriers and licensing information are the most likely data categories to be memorized from pre-trained and finetuned models, while the latter is the most likely to be forgotten after fine-tuning.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025762","Security and privacy;Software and its engineering;LLMs for code;Memorization;Fine-Tuning","Codes;Sensitivity;Source coding;Training data;Benchmark testing;Data models;Software;Data mining;Security;Research and development","","","","48","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Can LLMs Generate Higher Quality Code Than Humans? An Empirical Study","M. T. Jamil; S. Abid; S. Shamail","Department of Computer Science, Lahore University of Management Sciences DHA, Lahore, Pakistan; Department of Software Engineering, National University of Computer and Emerging Sciences Chiniot-Faisalabad Campus, Pakistan; Department of Computer Science, Lahore University of Management Sciences DHA, Lahore, Pakistan",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","478","489","Large Language Models are being extensively used for AI-assisted programming and code generation. The challenge is to ensure that the generated code is not only functionally correct but also safe, reliable and trustworthy. In this direction, we conduct a comprehensive empirical analysis of AI-generated code to assess whether large language models (LLMs) can produce correct and higher-quality code than humans. We evaluate the code quality of 984 code samples generated by GPT-3.5-Turbo and GPT-4 using various prompt types (simple, instructional, and enhanced) against input queries from the HumanEval dataset. We also enhance the HumanEval benchmark by calculating code quality metrics for the human-written code it contains. Code quality metrics are calculated using established tools like Radon, Bandit, Pylint, and Complexipy, with human-written code serving as a baseline for comparison. To quantify performance, we employ the TOPSIS method to rank the models and human code by their proximity to ideal and anti-ideal code quality metrics. Our results demonstrate that GPT-4, when used with advanced prompts, produces code closest to the ideal solution, outperforming human-written code in several key metrics. Our work provides evidence that LLMs, when properly guided, can surpass human developers in generating high-quality code. Our code and datasets are available online.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025576","Large Language Models (LLMs);AI-assisted programming;code generation;code quality assessment;code quality metrics;trustworthy AI;GPT;HumanEval","Measurement;Codes;Large language models;Radon;Programming;Benchmark testing;Software;Quality assessment;Reliability;Data mining","","","","41","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Prompt Engineering or Fine-Tuning: An Empirical Assessment of LLMs for Code","J. Shin; C. Tang; T. Mohati; M. Nayebi; S. Wang; H. Hemmati","Lassonde School of Engineering, York University, Toronto, Canada; NA; Schulich School of Engineering, University of Calgary, Calgary, Canada; Lassonde School of Engineering, York University, Toronto, Canada; Lassonde School of Engineering, York University, Toronto, Canada; Lassonde School of Engineering, York University, Toronto, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","490","502","The rapid advancements in large language models (LLMs) have greatly expanded the potential for automated code-related tasks. Two primary methodologies are used in this domain: prompt engineering and fine-tuning. Prompt engineering involves applying different strategies to query LLMs, like Chat-GPT, while fine-tuning further adapts pre-trained models, such as CodeBERT, by training them on task-specific data. Despite the growth in the area, there remains a lack of comprehensive comparative analysis between the approaches for code models. In this paper, we evaluate GPT-4 using three prompt engineering strategies-basic prompting, in-context learning, and taskspecific prompting-and compare it against 17 fine-tuned models across three code-related tasks: code summarization, generation, and translation. Our results indicate that GPT-4 with prompt engineering does not consistently outperform fine-tuned models. For instance, in code generation, GPT-4 is outperformed by finetuned models by 28.3% points on the MBPP dataset. It also shows mixed results for code translation tasks. Additionally, a user study was conducted involving 27 graduate students and 10 industry practitioners. The study revealed that GPT-4 with conversational prompts, incorporating human feedback during interaction, significantly improved performance compared to automated prompting. Participants often provided explicit instructions or added context during these interactions. These findings suggest that GPT-4 with conversational prompting holds significant promise for automated code-related tasks, whereas fully automated prompt engineering without human involvement still requires further investigation.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025620","Prompt engineering;Fine-tuning;LLM4SE;Empirical study;Survey","Industries;Training;Surveys;Adaptation models;Codes;Translation;Large language models;Software;Data models;Prompt engineering","","","","90","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code","T. Galimzyanov; S. Titov; Y. Golubev; E. Bogomolov",JetBrains Research; JetBrains Research; JetBrains Research; JetBrains Research,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","503","507","This paper introduces the human-curated Pandas-PlotBench dataset, designed to evaluate language models’ effectiveness as assistants in visual data exploration. Our benchmark focuses on generating code for visualizing tabular data—such as a Pandas DataFrame—based on natural language instructions, complementing current evaluation tools and expanding their scope. The dataset includes 175 unique tasks. Our experiments assess several leading Large Language Models (LLMs) across three visualization libraries: Matplotlib, Seaborn, and Plotly. We show that the shortening of tasks has a minimal effect on plotting capabilities, allowing for the user interface that accommodates concise user input without sacrificing functionality or accuracy. Another of our findings reveals that while LLMs perform well with popular libraries like Matplotlib and Seaborn, challenges persist with Plotly, highlighting areas for improvement. We hope that the modular design of our benchmark will broaden the current studies on generating visualizations. Our dataset and benchmark code is available online: https://huggingface. co/datasets/JetBrains-Research/PandasPlotBench; https://github.com/JetBrains-Research/PandasPlotBench.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025695","","Visualization;Codes;Large language models;Natural languages;Data visualization;Benchmark testing;Libraries;Data models;User experience;Software","","","","24","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"SnipGen: A Mining Repository Framework for Evaluating LLMs for Code","D. Rodriguez-Cardenas; A. Velasco; D. Poshyvanyk","Department of Computer Science, William & Mary, Williamsburg, VA; Department of Computer Science, William & Mary, Williamsburg, VA; Department of Computer Science, William & Mary, Williamsburg, VA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","508","512","Large Language Models (LLMs), such as transformer-based neural networks trained on billions of parameters, have become increasingly prevalent in software engineering (SE). These models, trained on extensive datasets that include code repositories, exhibit remarkable capabilities for SE tasks. However, evaluating their effectiveness poses significant challenges, primarily due to the potential overlap between the datasets used for training and those employed for evaluation. To address this issue, we introduce SnipGen, a comprehensive repository mining framework designed to leverage prompt engineering across various downstream tasks for code generation. SnipGen aims to mitigate data contamination by generating robust testbeds and crafting tailored data points to assist researchers and practitioners in evaluating LLMs for code-related tasks. In our exploratory study, SnipGen mined approximately 227K data points from 338K recent code changes in GitHub commits, focusing on method-level granularity. SnipGen features a collection of prompt templates that can be combined to create a Chain-of-Thought-like sequence of prompts, enabling a nuanced assessment of LLMs’ code generation quality. By providing the mining tool, the methodology, and the dataset, SnipGen empowers researchers and practitioners to rigorously evaluate and interpret LLMs’ performance in software engineering contexts.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025700","Deep learning;code generation;datasets;large language models;evaluation","Training;Codes;Large language models;Neural networks;Transformers;Software;Data mining;Prompt engineering;Software engineering;Software development management","","","","48","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"The Ecosystem of Open-Source Music Production Software – A Mining Study on the Development Practices of VST Plugins on GitHub","B. Andrei; M. V. Merino; I. Malavolta","Informatics Institute University Of Amsterdam, Amsterdam, the Netherlands; Computer Science Department, Vrije Universiteit Amsterdam, Amsterdam, the Netherlands; Computer Science Department, Vrije Universiteit Amsterdam, Amsterdam, the Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","513","525","In this study we shed light on a unique and interdisciplinary domain, where music, technology, and human creativity intersect: music production software. Today software technologies are the predominant means of music production, with a vibrant ecosystem for commercial and open-source products. In this work we target VST plugins, the de-facto standard for developing and prototyping music production software. We analyze 15,847 data points over 299 GitHub repositories containing VST plugins. Our results include a systematic quantification of the (i) characteristics of open-source VST projects in terms of, e.g., duration, size, contributors, stars/watchers, licensing, (ii) most used technologies for developing VST plugins, and (iii) code quality and testing practices in VST projects. Our findings provide a comprehensive understanding of the current state of the practice in VST plugins development, highlighting successful projects, opportunities for improvement, and future research directions for software engineering researchers.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025591","mining software repositories;music production software;empirical software engineering;vst","Systematics;Ecosystems;Production;Software;Data mining;Standards;Creativity;Software development management;Testing;Software engineering","","","","99","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Can LLMs Replace Manual Annotation of Software Engineering Artifacts?","T. Ahmed; P. Devanbu; C. Treude; M. Pradel","University of California, Davis, USA; University of California, Davis, USA; Singapore Management University, Singapore; University of Stuttgart, Germany",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","526","538","Experimental evaluations of software engineering innovations, e.g., tools and processes, often include human-subject studies as a component of a multi-pronged strategy to obtain greater generalizability of the findings. However, human-subject studies in our field are challenging, due to the cost and difficulty of finding and employing suitable subjects, ideally, professional programmers with varying degrees of experience. Meanwhile, large language models (LLMs) have recently started to demonstrate human-level performance in several areas. This paper explores the possibility of substituting costly human subjects with much cheaper LLM queries in evaluations of code and coderelated artifacts. We study this idea by applying six state-of-theart LLMs to ten annotation tasks from five datasets created by prior work, such as judging the accuracy of a natural language summary of a method or deciding whether a code change fixes a static analysis warning. Our results show that replacing some human annotation effort with LLMs can produce inter-rater agreements equal or close to human-rater agreement. To help decide when and how to use LLMs in human-subject studies, we propose model-model agreement as a predictor of whether a given task is suitable for LLMs at all, and model confidence as a means to select specific samples where LLMs can safely replace human annotators. Overall, our work is the first step toward mixed human-LLM evaluations in software engineering.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025652","LLMs;human subjects;evaluation","Technological innovation;Codes;Annotations;Large language models;Natural languages;Static analysis;Manuals;Predictive models;Software;Software engineering","","4","","67","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Investigating the Understandability of Review Comments on Code Change Requests","M. S. Rahman; Z. Codabux; C. K. Roy","Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","539","551","Code review is a widely adopted quality assurance practice in software engineering, where expert reviewers assess developers’ code changes before merging. While prior studies have explored review comment quality and usefulness, they often overlook the clarity and understandability of Code Change Request (CCR) comments. Unclear CCR comments can pose significant challenges for developers to address. Therefore, this study investigates the prevalence and impact of confusing or unclear CCR comments and proposes two approaches to enhance CCR communication during code review. Using a dataset of 182 open-source GitHub projects with over 55 K pull requests and 466 K CCR comments, we analyzed how often unclear comments occur and their effects on the review process. Our classifier, built from manually annotated developers’ replies in response to CCR comments, revealed that $24 \%$ of comments led to author confusion. Statistical analysis shows that unclear CCR comments significantly increase resolution time and discussion length, and that pull requests with clear CCR comments are more likely to be addressed and merged. A manual analysis of 400 confusing CCR comments identified six key characteristics, with lack of clarity and unclear rationale being the most common. Our first approach, the confusion classifier, flags authors’ confusion to enable reviewers to clarify ambiguities promptly (recall of 0.96), while the second classifier enables reviewers to evaluate the clarity and understandability of their CCR comments (recall of 0.93). This pioneering study further provides recommendations for enhancing CCR comments and offering a foundation for future research to streamline the review process.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00087","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025749","Code Review Comments;Code Change Requests;Collaboration;Software Maintenance;Confusion","Software maintenance;Codes;Quality assurance;Reviews;Statistical analysis;Merging;Manuals;Delays;Software engineering;Software development management","","","","82","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Mining a Decade of Event Impacts on Contributor Dynamics in Ethereum: A Longitudinal Study","M. Vaccargiu; S. Aufiero; C. Ba; S. Bartolucci; R. Clegg; D. Graziotin; R. Neykova; R. Tonelli; G. Destefanis","University of Cagliari, Italy; University College London, UK; Queen Mary University of London, UK; University College London, UK; Queen Mary University of London, UK; University of Hohenheim, Germany; Brunel University of London, UK; University of Cagliari, Italy; Brunel University of London, UK",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","552","563","We analyze developer activity across 10 major Ethereum repositories (totaling 129884 commits, 40550 issues) spanning 10 years to examine how events such as technical upgrades, market events, and community decisions impact development. Through statistical, survival, and network analyses, we find that technical events prompt increased activity before the event, followed by reduced commit rates afterwards, whereas market events lead to more reactive development. Core infrastructure repositories like Go-Ethereum exhibit faster issue resolution compared to developer tools, and technical events enhance core team collaboration. Our findings show how different types of events shape development dynamics, offering insights for project managers and developers in maintaining development momentum through major transitions. This work contributes to understanding the resilience of development communities and their adaptation to ecosystem changes.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025661","mining software repositories;events analysis;time series;open source software","Shape;Ecosystems;Dynamics;Collaboration;Network analyzers;Blockchains;Data mining;Open source software;Software development management;Resilience","","","","44","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Is it Really Fun? Detecting Low Engagement Events in Video Games","E. Guglielmi; G. Bavota; N. Novielli; R. Oliveto; S. Scalabrino","DEVISER @ University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; COLLAB @ Universiy of Bari; DEVISER @ University of Molise, Italy; DEVISER @ University of Molise, Italy",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","564","575","The gaming industry has witnessed remarkable growth in recent years, attracting millions of people who engage in its products both as a hobby and for professional purposes (e.g., e-sports). Video games are software products that have a unique and fundamental requirement: They must be engaging. Previous research introduced approaches aimed at measuring engagement, some of which specifically designed for video games. Such approaches could be useful for practitioners since they can be adopted on the large collection of gameplay videos daily published on platforms such as Twitch and YouTube to allow developers to monitor players’ engagement and detect areas in which it is low. Such specialized approaches have been evaluated on datasets in which the engagement was manually assessed by external evaluators based on the face of the player (we call it perceived engagement). We still do not know whether such approaches can capture the real engagement of players. Also, it is unclear to what extent practitioners would be willing to adopt such approaches in practice. In this paper, we provide two contributions. First, we ran an experiment with human 40 players aimed at defining a dataset of gameplay sessions in which participants self-reported their real engagement after every minute. We captured both their face and the gameplay. Based on this data, we compared state-of-the-art machine learning-based approaches to detect lowly engaging sessions. Our results show that the best model correctly classifies engagement in 74.7% of the cases and ranks video games in terms of their real engagement very similarly to how players would rank them (Spearman ρ = 0.833). Second, to assess the practicality of adopting such approaches in an industrial setting, we conducted two semi-structured interviews with senior game developers, who provided generally positive feedback and interesting insights for future developments.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025681","Gameplay videos;Video Games Quality;Mining software repositories","Industries;Video games;Video on demand;Games;Software;Data mining;Web sites;Interviews;Faces;Monitoring","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"A Dataset of Software Bill of Materials for Evaluating SBOM Consumption Tools","R. Kishimoto; T. Kanda; Y. Manabe; K. Inoue; S. Qiu; Y. Higo","The University of Osaka, Japan; Notre Dame Seishin University, Japan; The University of Fukuchiyama, Japan; Nanzan University, Japan; Toshiba Corporation, Japan; The University of Osaka, Japan",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","576","580","A Software Bill of Materials (SBOM) is becoming an essential tool for effective software dependency management. An SBOM is a list of components used in software, including details such as component names, versions, and licenses. Using SBOMs, developers can quickly identify software components and assess whether their software depends on vulnerable libraries. Numerous tools support software dependency management through SBOMs, which can be broadly categorized into two types: tools that generate SBOMs and tools that utilize SBOMs. A substantial collection of accurate SBOMs is required to evaluate tools that utilize SBOMs. However, there is no publicly available dataset specifically designed for this purpose, and research on SBOM consumption tools remains limited. In this paper, we present a dataset of SBOMs to address this gap. The dataset we constructed comprises 46 SBOMs generated from real-world Java projects, with plans to expand it to include a broader range of projects across various programming languages. Accurate and well-structured SBOMs enable researchers to evaluate the functionality of SBOM consumption tools and identify potential issues. We collected 3,271 Java projects from GitHub and generated SBOMs for 798 of them using Maven with an open-source SBOM generation tool. These SBOMs were refined through both automatic and manual corrections to ensure accuracy, currently resulting in 46 SBOMs that comply with the SPDX Lite profile, which defines minimal requirements tailored to practical workflows in industries. This process also revealed issues with the SBOM generation tools themselves. The dataset is publicly available on Zenodo (DOI: 10.5281/zenodo.14233414).","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00090","Nanzan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025701","SBOM;SPDX","Java;Computer languages;Accuracy;Sensitivity;Bills of materials;Manuals;Licenses;Software;Libraries;Software development management","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Jupyter Notebook Activity Dataset","T. Nakamaru; T. Matsunaga; T. Yamazaki","Grad. School of Arts and Sciences, The University of Tokyo, Tokyo, Japan; Grad. School of Info. Sci. and Tech., The University of Tokyo, Tokyo, Japan; Grad. School of Info. Sci. and Tech., The University of Tokyo, Tokyo, Japan",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","581","585","Fine-grained logs of programmers’ activities serve as research material in various fields of computer science. For activities in a traditional environment, there is a publicly available dataset. However, to our knowledge, no comparable dataset exists for activities in a cell-based computational notebook environment. This paper presents an open dataset of activities in the Jupyter Notebook. The dataset comprises the activity logs of 21 programmers who worked on a one-hour data science task in our log collection experiment. The dataset would contribute to understanding programmers’ workflows in cell-based notebook environments and evaluating proposals for those environments.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025633","computational notebook;programmer’s activity;publicly available dataset","Computer science;Data science;Software;Proposals;Data mining","","","","16","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"CoPhi - Mining C/C++ Packages for Conan Ecosystem Analysis","V. Sarkar; A. Kampkötter; B. Hermann","University of Washington, Seattle, USA; Department of Computer Science, Technische Universität Dortmund, Dortmund, Germany; Department of Computer Science, Technische Universität Dortmund, Dortmund, Germany",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","586","590","Large-scale analyses of software ecosystems allow researchers to identify widespread vulnerabilities, validate dependencies for safe usage, and gain an understanding of the conditions of software package landscapes. In the C/C++ ecosystem however, there are many challenges facing large-scale analyses, due to the lack of a standard package manager or build system. With this work, we aim to explore the Conan ecosystem by statically analyzing it as a whole and on a large scale. We provide a static analysis tool set named CoPhi that crawls Conan packages and analyzes them for specific features to capture C/C++ ecosystem metrics of interest, and also create corpora with user-defined properties. In a case study, we demonstrate the effectiveness of CoPhi by analyzing 620 Conan packages for four different metrics.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025564","Mining Software Repositories;C/C++;Static Analysis;Conan Package Manager","Measurement;Software packages;Ecosystems;Static analysis;Data mining;Standards","","","","11","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"MARIN: A Research-Centric Interface for Querying Software Artifacts on Maven Repositories","J. Düsing; J. Chiaramonte; B. Hermann","TU Dortmund, Dortmund, Germany; Arizona State University, Tempe, USA; TU Dortmund, Dortmund, Germany",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","591","595","Maven Central is the largest open repository for JVM libraries, hosting just under 15 million artifacts as of November 2024. Its popularity has made it a prime target for malicious actors to upload malware or exploit vulnerabilities – one in eight open source downloads have been vulnerable in 2023. Consequently, analyzing the artifacts is essential to understanding and improving software security and safety, both for individual projects and on a large-scale.However, current implementations of concrete analyses do not separate the infrastructural task of iterating and accessing artifacts from their domain-specific analysis task. Consequently, features are implemented many times in different variations, increasing the potential for bugs as well as the overhead in development and maintenance.With this work we propose MARIN, a framework for conducting analyses targeting software hosted on Maven Central. MARIN handles common infrastructural tasks in such scenarios, including iterating artifacts, retrieving metadata, parsing binaries, and resolving dependencies. It is designed to have minimal performance overhead, using both internal caches and the local Maven repository to reduce the number of HTTP calls and computations. This way, researchers can solely focus on implementing their domain-specific analysis task – MARIN provides configurable facilities to execute it for all artifacts on Maven Central.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025722","Static Analysis;Repository Mining;Maven Central;Large-Scale Analysis","Runtime;Multithreading;Static analysis;Metadata;Malware;Libraries;Safety;Maintenance;Data mining;Security","","","","30","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"GitProjectHealth: an Extensible Framework for Git Social Platform Mining","N. Hlad; B. Verhaeghe; K. Bauvent","Berger-Levrault, Toulouse, France; Berger-Levrault, Lyon, France; Berger-Levrault, Lyon, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","596","600","Git social platforms (such as Gitlab, Github, or Bitbucket) provide insight into a team’s workflow. Mining Software Repositories (MSR) provides methods and tools to extract data from these platforms. However, most tools lack connectivity and extensibility across multiple platforms. Moreover, they rarely connect to other project management platforms such as Jira. In this paper, we introduce GitProjectHealth (GPH), a framework to extract data from any Git repositories and social platforms. GPH is implemented inside a model-driven engineering framework in Pharo smalltalk, facilitating its extension to other social platforms. We demonstrate GPH features over 3 open-source organizations: Eclipse, MooseTechnology and Microsoft; as well as Berger-Levrault, a closed-source company. We extracted their activity to build distributions of commits by user and to determine which types of ticket were associated with each merge request.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025626","Mining Software Repositories;Model Driven Engineering;Pharo;Moose","Navigation;Project management;Data visualization;Companies;Feature extraction;Software;Model driven engineering;Extensibility;Data mining;Software development management","","","","15","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"MYRIAD PEOPLE Open Source Software for New Media Arts","B. Baudry; E. N. Gustafsson; R. Kaufman; M. Kling","Université de Montréal, QC, Canada; Independent artists, Stockholm, Sweden; Independent artists, Stockholm, Sweden; Independent artists, Stockholm, Sweden",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","601","605","New media art builds on top of rich software stacks. Blending multiple media such as code, light or sound, new media artists integrate various types of software to draw, animate, control or synchronize different parts of an artwork. Yet, the artworks rarely credit software and all the developers involved.In this work, we present MYRIAD PEOPLE, an original dataset of open source projects and their contributors, which span various software layers used in new media art installations. To collect this dataset, we released an open call for artists and eventually curated 9 artworks, which use a variety of software and media. In October 2024, we organized a collective exhibition in Stockholm, entitled MYRIAD, which showcased the 9 artworks. The MYRIAD PEOPLE dataset includes the 124 open source projects used in one or more of the MYRIAD’s artworks, as well as all the contributors to these projects. In this paper, we present the dataset, as well as the possible usages of this dataset for software and art research.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025669","art;open source;software;rug;credits;sound;light","Art;Codes;Full stack;Media;Synchronization;Data mining;Open source software","","","","31","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"OpenMent: A Dataset of Mentor-Mentee Interactions in Google Summer of Code","E. Raoofian; F. H. Fard; I. Adaji; G. Rodríguez-Pérez","University of British Columbia, Kelowna, Canada; University of British Columbia, Kelowna, Canada; University of British Columbia, Kelowna, Canada; University of British Columbia, Kelowna, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","606","610","Mentorship in Open Source Software (OSS) projects is crucial for reducing barriers to entry for newcomers and for fostering the technical and social integration of new contributors. While mentorship in OSS has been recognized as essential for sustainable project growth, quantitative research supporting qualitative findings is not common. To address this gap, we present OpenMent, a comprehensive dataset comprising over 500,000 issue comments, pull request comments, and commit messages from GitHub projects participating in the Google Summer of Code (GSoC) program. OpenMent is curated to capture role-specific interactions and communication patterns between mentors and mentees, providing information on the challenges and dynamics of OSS mentoring. This dataset is designed to be a reusable resource for the Software Engineering community, enabling researchers and practitioners to explore mentorship dynamics and investigate the impact of mentoring on contributor retention. By making OpenMent openly available, we aim to facilitate future research in OSS mentorship, fostering a deeper understanding of mentorship challenges, strategies, and contributions to the growth and inclusivity of OSS ecosystems.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00096","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025566","mentor-mentee dataset;google summer of code;mining software repositories","Codes;Ecosystems;Metadata;Dynamic scheduling;Encoding;Internet;Mentoring;Open source software;Software development management;Software engineering","","","","15","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Under the Blueprints: Parsing Unreal Engine’s Visual Scripting at Scale","K. Eng; A. Hindle","Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","611","615","In Unreal Engine, a popular game engine for AAA (high budget, high profile) title video games, Blueprint Visual Scripting is a widely used tool for developing gameplay elements using visual node and edge-based source code. Despite its widespread adoption, there is limited research on the intersection of software engineering and Blueprint-based visual programming. This dataset aims to address this gap by providing parsed Blueprint graphs extracted from Unreal Engine’s binary UAsset files. We developed extractors and a custom parser to mine Blueprint graphs from 335,753 Blueprint UAsset files across $\mathbf{2 4, 0 0 9}$ GitHub projects. By providing this dataset, we hope to encourage future research on the structure and usage of Unreal Engine Blueprints, and promote the development of tools—such as code smell detectors and language models for code completion-that can optimize visual programming practices within Unreal Engine.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025618","Unreal Engine;Blueprints;Visual Code","Visualization;Video games;Codes;Source coding;Programming;Software;Pins;Engines;Software development management;Software engineering","","1","","20","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Build Code Needs Maintenance Too: A Study on Refactoring and Technical Debt in Build Systems","A. Ghammam; D. E. Rzig; M. Almukhtar; R. Khalsi; F. Hassan; M. Kessentini","Oakland University Rochester Hills, USA; University of Michigan- Dearborn, Dearborn, USA; University of Michigan- Flint, Flint, USA; University of Michigan- Flint, Flint, USA; University of Michigan- Dearborn, Dearborn, USA; Grand Valley State University Grand Valley, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","616","628","In modern software engineering, build systems play the crucial role of facilitating the conversion of source code into software artifacts. Recent research has explored high-level causes of build failures, but has largely overlooked the structural properties of build files. Akin to source code, build systems face technical debt challenges that hinder maintenance and optimization. While refactoring is often seen as a key tool for addressing technical debt in source code, there is a significant research gap regarding the specific refactoring changes developers apply to build code and whether these refactorings effectively address technical debt.In this paper, we address this gap by examining refactorings applied to build scripts in open-source projects, covering the widely used build systems of Gradle, Ant, and Maven. Additionally, we investigate whether these refactorings are used to tackle technical debts in build systems. Our analysis was conducted on 725 examined build-file-related commits. We identified 24 build-related refactorings, which we divided into 6 main categories. These refactorings are organized into the first empirically derived taxonomy of build system refactorings. Furthermore, we investigate how developers employ these refactoring types to address technical debts via a manual commitanalysis and a developer survey. In this context, we identified 5 technical debts addressed by these refactorings and discussed their correlation with the different refactorings. Finally, we introduce BuildRefMiner, an LLM-powered tool leveraging GPT40 to automate the detection of refactorings within build systems. We evaluated its performance and found that it achieves an F1 score of 0.76 across all build systems.This study will serve as a foundational building block for guiding future research and practice in the maintenance and optimization of build systems. BuildRefMiner and the replication package for this study are available at [1]","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025590","build systems;refactoring;technical debt;llms","Surveys;Codes;Source coding;Taxonomy;Manuals;Software;Maintenance;Optimization;Faces;Software engineering","","","","73","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations","Z. Ye; T. H. M. Le; M. A. Babar","CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","629","641","Security misconfigurations in Container Orchestrators (COs) can pose serious threats to software systems. While Static Analysis Tools (SATs) can effectively detect these security vulnerabilities, the industry currently lacks automated solutions capable of fixing these misconfigurations. The emergence of Large Language Models (LLMs), with their proven capabilities in code understanding and generation, presents an opportunity to address this limitation. This study introduces LLMSecConfig, an innovative framework that bridges this gap by combining SATs with LLMs. Our approach leverages advanced prompting techniques and Retrieval-Augmented Generation (RAG) to automatically repair security misconfigurations while preserving operational functionality. Evaluation of 1,000 real-world Kubernetes configurations achieved a 94% success rate while maintaining a low rate of introducing new misconfigurations.Our work makes a promising step towards automated container security management, reducing the manual effort required for configuration maintenance.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025712","Container;Container Orchestrator;Configuration;Security;Large Language Models;Prompt Template;Retrieval-Augmented Generation","Industries;Large language models;Security management;Retrieval augmented generation;Static analysis;Manuals;Containers;Maintenance engineering;Software systems;Maintenance","","","","59","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"How Do Infrastructure-as-Code Practitioners Update Their Dependencies? An Empirical Study on Terraform Module Updates","M. Begoug; A. Ouni; M. Chouchen","ETS Montreal, University of Quebec, Montreal, QC, Canada; ETS Montreal, University of Quebec, Montreal, QC, Canada; Concordia University, Montreal, QC, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","642","653","Infrastructure-as-Code (IaC) enables practitioners to configure and manage software infrastructure through machine-readable code files. Various IaC tools facilitate code reuse and modularity via IaC modules that act as dependencies. These modules are maintained by IaC providers to introduce new features, resolve bugs, or address security vulnerabilities. However, there is a limited understanding of how practitioners update their IaC module dependencies in their software projects, including updates frequency, delays, as well as motivations behind such updates. To fill this gap, this paper aims to understand current update practices in IaC module dependencies, focusing on Terraform (TF), being currently one of the most popular IaC tools. In particular, we investigate (i) the frequency in which IaC practitioners update their module dependencies, (ii) the technical lag phenomena, which represents the time that the infrastructure configurations remain outdated relative to their upstream modules, and (iii) the motivations that drive these updates. To achieve these, we conduct an empirical study on 13,490 TF-related commits from 131 open-source projects. Our results reveal that only 1.2% of the analyzed commits involve updating module dependencies. Furthermore, we observe an increasing technical lag from 2021 until 2024, reaching ten months on average by 2024. Then, we conduct a qualitative study using thematic analysis on code changes involving TF module dependencies updates to investigate practitioners’ motivations behind such updates. We identify that TF practitioners revolve around six main motivations, with IaC Ecosystem Compatibility, Security Vulnerabilities Fixes, and IaC Code Quality Improvement being the three most prevalent motivations. Our findings advocate that TF practitioners need customized IaC tool support for safe module dependency updates while addressing compatibility concerns.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00100","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025691","Infrastructure-as-Code;Terraform Modules;Infrastructure Dependencies","Time-frequency analysis;Codes;Pandemics;Ecosystems;Organizations;Market research;Software;Stability analysis;Security;Software development management","","","","89","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"TerraDS: A Dataset for Terraform HCL Programs","C. Bühler; D. Spielmann; R. Meier; G. Salvaneschi","University of St. Gallen, St. Gallen, Switzerland; University of St. Gallen, St. Gallen, Switzerland; armasuisse, Thun, Switzerland; University of St. Gallen, St. Gallen, Switzerland",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","654","658","Infrastructure as Code (IaC) aims to automate infrastructure management by enabling the definition of infrastructure configurations in programs, rather than manually configuring hardware or cloud resources. Terraform is one of the most widely used IaC tools, gaining significant traction in recent years, as highlighted by its large and active user community and widespread adoption in both open-source and enterprise environments. Terraform’s code is written in the HashiCorp Configuration Language (HCL), which defines the infrastructure in a declarative manner. Despite the widespread adoption of Terraform, there is no large-scale dataset available for researchers to study IaC Terraform programs systematically. To address this gap, we present TerraDS, the first dataset of publicly available Terraform programs written in HCL. TerraDS contains the HCL code and the metadata of 67,360 open source repositories with permissive open-source licenses. The dataset includes 279,344 Terraform modules with 1,773,991 registered resources, all compiled into a reusable archive ($\sim 335 \mathrm{MB}$).","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00101","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025653","Cloud Computing;Configuration Management;Open Source Software;Static Analysis","Codes;Source coding;Stars;Static analysis;Metadata;Licenses;Open source software;Testing;Software development management;Indexing","","","","23","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"OSPtrack: A Labeled Dataset Targeting Simulated Execution of Open-Source Software","Z. Tan; C. Anagnostopoulos; J. Singer","University of Glasgow, UK; University of Glasgow, UK; University of Glasgow, UK",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","659","663","Open-source software serves as a foundation for the internet and the cyber supply chain, but its exploitation is becoming increasingly prevalent. While advances in vulnerability detection for OSS have been significant, prior research has largely focused on static code analysis, often neglecting runtime indicators. To address this shortfall, we created a comprehensive dataset spanning five ecosystems, capturing features generated during the execution of packages and libraries in isolated environments. The dataset includes 9,461 package reports, of which 1,962 are identified as malicious, and encompasses both static and dynamic features such as files, sockets, commands, and DNS records. Each report is labeled with verified information and detailed sub-labels for attack types, facilitating the identification of malicious indicators when source code is unavailable. This dataset supports runtime detection, enhances detection model training, and enables efficient comparative analysis across ecosystems, contributing to the strengthening of supply chain security.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025755","Open-source Software;Runtime Indicators;Supply Chain Security","Training;Runtime;Source coding;Sockets;Supply chains;Ecosystems;Feature extraction;Malware;Security;Open source software","","","","25","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"CARDS: A collection of package, revision, and miscellaneous dependency graphs","E. Tran-Girard; L. Bulteau; P. -Y. David","LIGM, CNRS, Univ. Gustave Eiffel, Marne-la-Vallée, France; LIGM, CNRS, Univ. Gustave Eiffel, Marne-la-Vallée, France; Octobus S.c.o.p., Montreuil, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","664","668","CARDS (Corpus of Acyclic Repositories and Dependency Systems) is a collection of directed graphs which express dependency relations, extracted from diverse real-world sources such as package managers, version control systems, and event graphs. Each graph contains anywhere from thousands to hundreds of millions of nodes and edges, which are normalized into a simple, unified format. Both cyclic and acyclic variants are included (as some graphs, such as citation networks, are not entirely acyclic). The dataset is suitable for studying the structure of different kinds of dependencies, enabling the characterization and distinction of various dependency graph types. It has been utilized for developing and testing efficient algorithms which leverage the specificities of source version control graphs. The collection is publicly available at doi.org/10.5281/zenodo.14245890.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025644","dependency;directed graphs;dataset;software;package;source;versioning","Software packages;Software algorithms;Directed graphs;Control systems;Data mining;Testing","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"GHALogs: Large-Scale Dataset of GitHub Actions Runs","F. Moriconi; T. Durieux; J. -R. Falleri; R. Troncy; A. Francillon","EURECOM AMADEUS; TU Delft; LaBRI, UMR 5800, University of Bordeaux; EURECOM; EURECOM",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","669","673","In recent years, continuous integration and deployment (CI/CD) has become increasingly popular in both the opensource community and industry. Evaluating CI/CD performance is a critical aspect of software development, as it not only helps minimize execution costs but also ensures faster feedback for developers. Despite its importance, there is limited fine-grained knowledge about the performance of CI/CD processes, while this knowledge is essential for identifying bottlenecks and optimization opportunities. Moreover, the availability of large-scale, publicly accessible datasets of CI/CD logs remains scarce. The few datasets that do exist are often outdated and lack comprehensive coverage. To address this gap, we introduce GHALogs, a new dataset comprising 116k CI/CD workflows executed using GitHub Actions (GHA) across 25k public code projects spanning 20 different programming languages. This dataset includes 513k workflow runs encompassing 2.3 million individual steps. For each workflow run, we provide detailed metadata along with complete run logs. To the best of our knowledge, this is the largest dataset of CI/CD runs that includes full log data. The inclusion of these logs enables more in-depth analysis of CI/CD pipelines, offering insights that cannot be gleaned solely from code repositories. We postulate that this dataset will facilitate future CI/CD pipeline behavior research through log-based analysis. Potential applications include performance evaluation (e.g., measuring task execution times) and root cause analysis (e.g., identifying reasons for pipeline failures).","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025655","github actions;continuous integration;ci/cd;cicd;github;logs;dataset","Performance evaluation;Industries;Computer languages;Root cause analysis;Codes;Pipelines;Metadata;Software;Data mining;Optimization","","","","20","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Automatic High-Level Test Case Generation using Large Language Models","N. B. Hasan; M. A. Islam; J. Y. Khan; S. Senjik; A. Iqbal",Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","674","685","We explored the challenges practitioners face in software testing and proposed automated solutions to address these obstacles. We began with a survey of local software companies and 26 practitioners, revealing that the primary challenge is not writing test scripts but aligning testing efforts with business requirements. Based on these insights, we constructed a usecase $\rightarrow$ (high-level) test-cases dataset to train/fine-tune models for generating high-level test cases. High-level test cases specify what aspects of the software’s functionality need to be tested, along with the expected outcomes. We evaluated large language models, such as GPT-4o, Gemini, LLaMA 3.1 8B, and Mistral 7B, where fine-tuning (the latter two) yields improved performance. A final (human evaluation) survey confirmed the effectiveness of these generated test cases. Our proactive approach strengthens requirement-testing alignment and facilitates early test case generation to streamline development.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025799","Test Case;Use Case;Test Case Generation;Dataset;Large Language Model","Surveys;Software testing;Large language models;Companies;Writing;Software;Data mining;Faces;Business","","","","50","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Prompting in the Wild: An Empirical Study of Prompt Evolution in Software Repositories","M. Tafreshipour; A. Imani; E. Huang; E. S. d. Almeida; T. Zimmermann; I. Ahmed","University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA; Federal University of Bahia (UFBA), Brazil; University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","686","698","The adoption of Large Language Models (LLMs) is reshaping software development as developers integrate these LLMs into their applications. In such applications, prompts serve as the primary means of interacting with LLMs. Despite the widespread use of LLM-integrated applications, there is limited understanding of how developers manage and evolve prompts. This study presents the first empirical analysis of prompt evolution in LLM-integrated software development. We analyzed 1,262 prompt changes across 243 GitHub repositories to investigate the patterns and frequencies of prompt changes, their relationship with code changes, documentation practices, and their impact on system behavior. Our findings show that developers primarily evolve prompts through additions and modifications, with most changes occurring during feature development. We identified key challenges in prompt engineering: only $21.9 \%$ of prompt changes are documented in commit messages, changes can introduce logical inconsistencies, and misalignment often occurs between prompt changes and LLM responses. These insights emphasize the need for specialized testing frameworks, automated validation tools, and improved documentation practices to enhance the reliability of LLM-integrated applications.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025760","Large Language Models;Prompt Engineering;Empirical Software Engineering","Systematics;Large language models;Documentation;Software;Software reliability;Prompt engineering;Data mining;Software development management;Testing;Software engineering","","","","58","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Towards Detecting Prompt Knowledge Gaps for Improved LLM-guided Issue Resolution","R. Ehsani; S. Pathak; P. Chatterjee","Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","699","711","Large language models (LLMs) have become essential in software development, especially for issue resolution. However, despite their widespread use, significant challenges persist in the quality of LLM responses to issue resolution queries. LLM interactions often yield incorrect, incomplete, or ambiguous information, largely due to knowledge gaps in prompt design, which can lead to unproductive exchanges and reduced developer productivity.In this paper, we analyze 433 developer-ChatGPT conversations within GitHub issue threads to examine the impact of prompt knowledge gaps and conversation styles on issue resolution. We identify four main knowledge gaps in developer prompts: Missing Context, Missing Specifications, Multiple Context, and Unclear Instructions. Assuming that conversations within closed issues contributed to successful resolutions while those in open issues did not, we find that ineffective conversations contain knowledge gaps in $44.6 \%$ of prompts, compared to only $12.6 \%$ in effective ones. Additionally, we observe seven distinct conversational styles, with Directive Prompting, Chain of Thought, and Responsive Feedback being the most prevalent. We find that knowledge gaps are present in all styles of conversations, with Missing Context being the most repeated challenge developers face in issue-resolution conversations.Based on our analysis, we identify key textual and code-related heuristics—Specificity, Contextual Richness, and Clarity—that are associated with successful issue closure and help assess prompt quality. These heuristics lay the foundation for an automated tool that can dynamically flag unclear prompts and suggest structured improvements. To test feasibility, we developed a lightweight browser extension prototype for detecting prompt gaps, that can be easily adapted to other tools within developer workflows.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025628","issue resolution;large language models;prompt quality","Context;Large language models;Prototypes;Oral communication;Software;Browsers;Data mining;Faces;Software development management;Message systems","","","","60","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Intelligent Semantic Matching (ISM) for Video Tutorial Search using Transformer Models","A. J. Tayeb; S. Haiduc","King Abdulaziz University, Saudi Arabia; Florida State University, United States",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","712","724","The rise in the number and diversity of available software development video tutorials has enhanced digital learning for developers but also introduced challenges in locating relevant content efficiently. Existing video search methods, including keyword-based approaches and tools like CodeTube and TechTube, rely primarily on retrieval algorithms such as BM25, which fail to capture the semantic nuances and user intentions behind search queries. To address these limitations, we introduce ISM, an approach that uses SBERT to generate semantically rich vectors from video tutorial transcripts to improve the search for programming video tutorials. By segmenting transcripts and implementing a re-ranking process, ISM effectively preserves context and enhances the relevance of search results. Additionally, ISM generates informative video summaries using GPT-4, allowing developers to quickly assess the relevance of video content. To evaluate our approach, we first performed a quantitative study comparing ISM with the baseline TechTube. The results revealed that ISM performs better in both video retrieval and fragment identification, achieving a Hit@ 5 score of 0.95 and an average F1 score of 0.70 compared to the baseline’s 0.58 and 0.52, respectively. We also performed a user study, which revealed that users strongly preferred the semantic matching capabilities and AI-generated summaries of our approach. This work advances the state-of-the-art in programming video tutorial search and summarization by offering more nuanced and useraligned retrieval and summarization mechanisms.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00108","National Science Foundation; Saudi Arabian Cultural Mission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025803","","Video description;Search methods;Semantics;Software algorithms;Tutorials;Programming;Transformers;Vectors;Software;Software development management","","","","45","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Language Models in Software Development Tasks: An Experimental Analysis of Energy and Accuracy","N. Alizadeh; B. Belchev; N. Saurabh; P. Kelbert; F. Castor","Utrecht University, Utrecht, The Netherlands; University of Twente, Enschede, The Netherlands; Utrecht University, Utrecht, The Netherlands; Fraunhofer IESE, Kaiserslautern, Germany; University of Twente, Enschede, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","725","736","The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development. Many of these tools are provided as remote APIs. Using third-party APIs raises data privacy and security concerns for client companies, which motivates the use of locallydeployed language models. In this study, we explore the tradeoff between model accuracy and energy consumption, aiming to provide valuable insights to help developers make informed decisions when selecting a language model. We investigate the performance of 18 families of LLMs in typical software development tasks on two real-world infrastructures, a commodity GPU and a powerful AI-specific GPU. Given that deploying LLMs locally requires powerful infrastructure which might not be affordable for everyone, we consider both full-precision and quantized models. Our findings reveal that employing a big LLM with a higher energy budget does not always translate to significantly improved accuracy. Additionally, quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized ones. Apart from that, not a single model is suitable for all types of software development tasks.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025589","LLMs;Energy Efficiency;Trade-Offs;Software Development;Coding Assistant;Model Quantization","Energy consumption;Analytical models;Accuracy;Translation;Graphics processing units;Predictive models;Energy efficiency;Encoding;Software reliability;Software development management","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"TriGraph: A Probabilistic Subgraph-Based Model for Visual Code Completion in Pure Data","A. Islam; A. Hindle","Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","737","749","Pure Data (PD) is a visual programming language for computer music that allows users to create applications through a graph-based, drag-and-drop interface, using objects and connections to manage program flow. There is a lack of tool support for computer musicians using PD, particularly for code completion. In this paper, we introduce TriGraph, a graph-based probabilistic model specifically designed for code completion in PD. TriGraph uses statistical analysis of 2-node and 3-node subgraph frequencies to predict nodes and connections in PD graphs. Using a dataset of parsed PD files, we train and evaluate 5 TriGraph models, assessing their performance in predicting nodes and edges in PD graphs. Our evaluations indicate that the models achieve an average Mean Reciprocal Rank (MRR) score of 0.39 for node prediction, placing the correct answer within the top 3 suggestions, and outperforming the n-grambased KenLM model on similar tasks. For edge prediction, the models achieve an average MRR score of 0.57, with results showing that incorporating both 2 -node and 3-node subgraphs yields better results than using only 3 -node subgraphs. These findings suggest that TriGraph could enhance the productivity of PD programmers by providing code completion support that may speed up development, reduce errors, and assist in discovering available options. These potential benefits highlight its promise as a valuable support tool for end-user programmers in graphical environments.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00110","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025562","Visual Programming Language;Pure Data;Probabilistic Models;Graph Analysis;Code Completion","Training;Visualization;Computer languages;Analytical models;Codes;Statistical analysis;Computational modeling;Predictive models;Probabilistic logic;Data models","","","","70","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Inferring Questions from Programming Screenshots","F. Ahmed; X. Tan; F. Adewole; S. Datta; M. Nayebi","York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","750","755","The integration of generative AI into developer forums like Stack Overflow presents an opportunity to enhance problem-solving by allowing users to post screenshots of code or Integrated Development Environments (IDEs) instead of traditional text-based queries. This study evaluates the effectiveness of various large language models (LLMs)—specifically LLAMA, GEMINI, and GPT-4o in interpreting such visual inputs. We employ prompt engineering techniques, including in-context learning, chain-of-thought prompting, and few-shot learning, to assess each model’s responsiveness and accuracy. Our findings show that while GPT-4o shows promising capabilities, achieving over $60 \%$ similarity to baseline questions for $51.75 \%$ of the tested images, challenges remain in obtaining consistent and accurate interpretations for more complex images. This research advances our understanding of the feasibility of using generative AI for image-centric problem-solving in developer communities, highlighting both the potential benefits and current limitations of this approach while envisioning a future where visual-based debugging copilot tools become a reality.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025629","Large language model;stack overflow","Visualization;Accuracy;Large language models;Debugging;Programming;Software;Problem-solving;Prompt engineering;Data mining;Few shot learning","","","","47","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Human-In-The-Loop Software Development Agents: Challenges and Future Directions","J. Pasuksmit; W. Takerngsaksiri; P. Thongtanunam; C. Tantithamthavorn; R. Zhang; S. Wang; F. Jiang; J. Li; E. Cook; K. Chen; M. Wu","Atlassian, Australia; Monash University, Australia; The University of Melbourne, Australia; Monash University, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","756","757","Multi-agent LLM-driven systems for software development are rapidly gaining traction, offering new opportunities to enhance productivity. At Atlassian, we deployed Human-in-the-Loop Software Development Agents to resolve Jira work items and evaluated the generated code quality using functional correctness testing and GPT-based similarity scoring. This paper highlights two major challenges: the high computational costs of unit testing and the variability in LLM-based evaluations. We also propose future research directions to improve evaluation frameworks for Human-In-The-Loop software development tools.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025667","hula;atlassian;llm;human-in-the-loop;jira;code-generation","Productivity;Codes;Human in the loop;Software;Computational efficiency;Data mining;Software development management;Testing","","","","6","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"FormalSpecCpp: A Dataset of C++ Formal Specifications created using LLMs","M. Chakraborty; P. Pirkelbauer; Q. Yi","University of California, Riverside, CA, USA; Lawrence Livermore National Laboratory (LLNL), CA, USA; Lawrence Livermore National Laboratory (LLNL), CA, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","758","762","FormalSpecCpp is a dataset designed to fill the gap in standardized benchmarks for verifying formal specifications in C++ programs. To the best of our knowledge, this is the first comprehensive collection of C++ programs with well-defined preconditions and postconditions. It provides a structured benchmark for evaluating specification inference tools and testing the accuracy of generated specifications. Researchers and developers can use this dataset to benchmark specification inference tools, fine-tune Large Language Models (LLMs) for automated specification generation, and analyze the role of formal specifications in improving program verification and automated testing. By making this dataset publicly available, we aim to advance research in program verification, specification inference, and AIassisted software development. The dataset and the code are available at https://github.com/MadhuNimmo/FormalSpecCpp.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00113","Lawrence Livermore National Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025772","formal specifications;large language models;specification inference;program verification","Codes;Accuracy;Large language models;C++ languages;Benchmark testing;Software;Formal specifications;Data mining;Software development management","","","","15","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"PyExamine: A Comprehensive, Un-Opinionated Smell Detection Tool for Python","K. Shivashankar; A. Martini","Department of Informatics, University of Oslo, Norway; Department of Informatics, University of Oslo, Norway",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","763","774","The growth of Python adoption across diverse domains has led to increasingly complex codebases, presenting challenges in maintaining code quality. While numerous tools attempt to address these challenges, they often fall short in providing comprehensive analysis capabilities or fail to consider Pythonspecific contexts. PyExamine addresses these critical limitations through an approach to code smell detection that operates across multiple levels of analysis. PyExamine architecture enables detailed examination of code quality through three distinct but interconnected layers: architectural patterns, structural relationships, and code-level implementations. This approach allows for the detection and analysis of 49 distinct metrics, providing developers with an understanding of their codebase’s health. The metrics span across all levels of code organization, from high-level architectural concerns to granular implementation details. Through evaluation on 7 diverse projects, PyExamine achieved detection accuracy rates: $91.4 \%$ for code-level smells, $89.3 \%$ for structural smells, and $80.6 \%$ for architectural smells. These results were further validated through extensive user feedback and expert evaluations, confirming PyExamine’s capability to identify potential issues across all levels of code organization with high recall accuracy. In additional to this, we have also used PyExamine to analysis the prevalence of different type of smells, across 183 diverse Python projects ranging from small utilities to large-scale enterprise applications. PyExamine’s distinctive combination of comprehensive analysis, Python-specific detection, and high customizability makes it a valuable asset for both individual developers and large teams seeking to enhance their code quality practices.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025624","Python;Code Smells;Anti-patterns","Codes;Accuracy;Software design;Organizations;Software;Distance measurement;Quality assessment;Data mining;Best practices;Python","","","","42","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Does Functional Package Management Enable Reproducible Builds at Scale? Yes.","J. Malka; S. Zacchiroli; T. Zimmermann","LTCI, Télécom Paris Institut Polytechnique de Paris, Palaiseau, France; LTCI, Télécom Paris Institut Polytechnique de Paris, Palaiseau, France; LTCI, Télécom Paris Institut Polytechnique de Paris, Palaiseau, France",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","775","787","Reproducible Builds (R-B) guarantee that rebuilding a software package from source leads to bitwise identical artifacts. R-B is a promising approach to increase the integrity of the software supply chain, when installing open source software built by third parties. Unfortunately, despite success stories like high build reproducibility levels in Debian packages, uncertainty remains among field experts on the scalability of R-B to very large package repositories. In this work, we perform the first large-scale study of bitwise reproducibility, in the context of the Nix functional package manager, rebuilding 709816 packages from historical snapshots of the nixpkgs repository, the largest cross-ecosystem open source software distribution, sampled in the period 2017-2023. We obtain very high bitwise reproducibility rates, between 69 and $91 \%$ with an upward trend, and even higher rebuildability rates, over $99 \%$. We investigate unreproducibility causes, showing that about $15 \%$ of failures are due to embedded build dates. We release a novel dataset with all build statuses, logs, as well as full “diffoscopes”: recursive diffs of where unreproducible build artifacts differ.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025777","reproducible builds;functional package management;software supply chain;reproducibility;security","Uncertainty;Software packages;Scalability;Supply chains;Ecosystems;Market research;Reproducibility of results;Security;Open source software;Monitoring","","","","34","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Refactoring for Dockerfile Quality: A Dive into Developer Practices and Automation Potential","E. Ksontini; M. Mastouri; R. Khalsi; W. Kessentini","University of Michigan - Flint, USA; University of Michigan - Flint, USA; University of Michigan - Flint, USA; University of Michigan - Flint, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","788","800","Docker, the industry standard for packaging and deploying applications, leverages Infrastructure as Code (IaC) principles to facilitate the creation of images through Dockerfiles. However, maintaining Dockerfiles presents significant challenges. Refactoring, in particular, is often a manual and complex process. This paper explores the utility and practicality of automating Dockerfile refactoring using 600 Dockerfiles from 358 opensource projects. Our study reveals that Dockerfile image size and build duration tend to increase as projects evolve, with developers often postponing refactoring efforts until later stages in the development cycle. This trend motivates the automation of refactoring. To achieve this, we leverage In Context Learning (ICL) along with a score-based demonstration selection strategy. Our approach leads to an average reduction of 32% in image size and a 6% decrease in build duration, with improvements in understandability and maintainability observed in 77% and 91% of cases, respectively. Additionally, our analysis shows that automated refactoring reduces Dockerfile image size by 2x compared to manual refactoring and 10x compared to smellfixing tools like PARFUM. This work establishes a foundation for automating Dockerfile refactoring, indicating that such automation could become a standard practice within CI/CD pipelines to enhance Dockerfile quality throughout every step of the software development lifecycle.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025789","Refactoring;In-Context Learning;Software Engineering;LLM;Docker Refactoring;IaC","Automation;Pipelines;Manuals;Streaming media;Packaging;Software;Standards;Optimization;Software engineering;Software development management","","1","","53","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Smells-sus: Sustainability Smells in IaC","S. Kosbar; M. Hamdaqa","Software and Emerging Technologies Lab (SAET) Polytechnique Montréal, Montréal, Canada; Software and Emerging Technologies Lab (SAET) Polytechnique Montréal, Montréal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","801","812","Practitioners use Infrastructure as Code (IaC) scripts to efficiently configure IT infrastructures through machine-readable definition files. However, during the development of these scripts, some code patterns or deployment choices may lead to sustainability issues, like inefficient resource utilization or redundant provisioning. We call this type of patterns sustainability smells. These inefficiencies pose significant environmental and financial challenges, given the growing scale of cloud computing. This research focuses on Terraform, a widely adopted IaC tool. Our study involves defining seven sustainability smells and validating them through a survey with 19 IaC practitioners. We utilized a dataset of 28,327 Terraform scripts from 395 open-source repositories. We performed a detailed qualitative analysis of a randomly sampled $\mathbf{1, 8 6 0}$ Terraform scripts from the original dataset to identify code patterns that correspond to the sustainability smells and used the other 26,467 Terraform scripts to study the prevalence of the defined sustainability smells. Our results indicate varying prevalence rates of these smells across the dataset. The most prevalent smell is NonModular Configurations, which appears in $9.67 \%$ of the scripts. Additionally, our findings highlight the complexity of conducting root cause analysis for sustainability issues, as these smells often arise from a confluence of script structures, configuration choices, and deployment contexts.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025603","Cloud Computing;Sustainability;Infrastructure as Code;Energy Efficiency","Surveys;Cloud computing;Root cause analysis;Codes;Statistical analysis;Energy efficiency;Software;Complexity theory;Resource management;Sustainable development","","","","50","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Evidence is All We Need: Do Self-Admitted Technical Debts Impact Method-Level Maintenance?","S. Chowdhury; H. Kidwai; M. Asaduzzaman","SQM Research Lab, Computer Science University of Manitoba, Winnipeg, Canada; SQM Research Lab, Computer Science University of Manitoba, Winnipeg, Canada; School of Computer Science, University of Windsor, Windsor, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","813","825","Self-Admitted Technical Debt (SATD) refers to the phenomenon where developers explicitly acknowledge technical debt through comments in the source code. While considerable research has focused on detecting and addressing SATD, its true impact on software maintenance remains underexplored. The few studies that have examined this critical aspect have not provided concrete evidence linking SATD to negative effects on software maintenance. These studies, however, focused only on file- or class-level code granularity. This paper aims to empirically investigate the influence of SATD on various facets of software maintenance at the method level. We assess SATD’s effects on code quality, bug susceptibility, change frequency, and the time practitioners typically take to resolve SATD.By analyzing a dataset of 774,051 methods from 49 opensource projects, we discovered that methods containing SATD are not only larger and more complex but also exhibit lower readability and a higher tendency for bugs and changes. We also found that SATD often remains unresolved for extended periods, adversely affecting code quality and maintainability. Our results provide empirical evidence highlighting the necessity of early identification, resource allocation, and proactive management of SATD to mitigate its long-term impacts on software quality and maintenance costs.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025748","SATD;bug-proneness;change-proneness;code metrics;software maintenance","Software maintenance;Time-frequency analysis;Codes;Costs;Source coding;Computer bugs;Software quality;Solids;Maintenance;Resource management","","","","89","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"DPy: Code Smells Detection Tool for Python","A. Boloori; T. Sharma","Dalhousie University, Canada; Dalhousie University, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","826","830","Code smells violate best practices in software development that make code difficult to understand and maintain. Code smell detection tools help practitioners detect maintainability issues and enable researchers to conduct repository mining and empirical research involving code smells. Though significant efforts have been made to effectively detect smells in code, majority of the available tools target programming languages such as Java. Despite the most popular language, a code smell detection tool that can identify not only implementation-level code smells but also support detection of smells at the design granularity is lacking. This paper presents DPy, a code smell detection tool for Python. The tool currently supports eight design smells, eleven implementation smells, and various code quality metrics for Python code. Our replication package includes the tool, instructions to use it, all the validation data and scripts [1]","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025788","Code smells;Python;Repository mining","Measurement;Java;Codes;Pipelines;Symbols;Computer architecture;Continuous integration;Software;Data mining;Python","","","","59","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"CoMRAT: Commit Message Rationale Analysis Tool","M. Dhaouadi; B. J. Oakes; M. Famelis","DIRO, Université de Montréal, Montréal, Canada; GIGL, Polytechnique Montréal, Montréal, Canada; DIRO, Université de Montréal, Montréal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","831","835","In collaborative open-source development, the rationale for code changes is often captured in commit messages, making them a rich source of valuable information. However, research on rationale in commit messages remains limited. In this paper, we present CoMRAT, a tool for analyzing decision and rationale sentences rationale in commit messages. CoMRAT enables a) researchers to produce metrics and analyses on rationale information in any Github module, and b) developers to check the amount of rationale in their commit messages. A preliminary evaluation suggests the tool’s usefulness and usability in both these research and development contexts.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025609","rationale analysis;code commit messages;Github repository mining;Linux kernel analysis","Measurement;Codes;Linux;Writing;Software;Data mining;Usability;Kernel;Research and development;Software development management","","","","12","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"E2EGit: A Dataset of End-to-End Web Tests in Open Source Projects","S. D. Meglio; L. L. L. Starace; V. Pontillo; R. Opdebeeck; C. D. Roover; S. D. Martino","Department of Electrical Engineering and Information Technology, University of Naples Federico II, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Italy; Software Languages (SOFT) Lab, Vrije Universiteit Brussel, Belgium; Software Languages (SOFT) Lab, Vrije Universiteit Brussel, Belgium; Software Languages (SOFT) Lab, Vrije Universiteit Brussel, Belgium; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Italy",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","836","840","End-to-end (E2E) testing is a software validation approach that simulates realistic user scenarios throughout the entire workflow of an application. In the context of web applications, E2E testing involves two activities: Graphic User Interface (GUI) testing, which simulates user interactions with the web app’s GUI through web browsers, and performance testing, which evaluates system workload handling. Despite its recognized importance in delivering high-quality web applications, the availability of large-scale datasets featuring real-world E2E web tests remains limited, hindering research in the field.To address this gap, we present E2EGit, a comprehensive dataset of non-trivial open-source web projects collected on GitHub that adopt E2E testing. By analyzing over 5,000 web repositories across popular programming languages (Java, JavaScript, TypeScript and Python), we identified 472 repositories implementing 43,670 automated Web GUI tests with popular browser automation frameworks (Selenium, Playwright, Cypress, Puppeteer), and 84 repositories that featured 271 automated performance tests implemented leveraging the most popular open-source tools (JMeter, LoCust). Among these, 13 repositories implemented both types of testing for a total of 786 Web GUI tests and 61 performance tests. The dataset is available on Zenodo (DOI: 10.5281/zenodo.14234731).","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025750","End-to-End Testing;Web GUI Testing;Performance Testing;GitHub-Minining;Web Applications","Training;Automation;Software quality;Browsers;Selenium;Test pattern generators;Testing;Graphical user interfaces;Software development management;Python","","","","31","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"TestMigrationsInPy: A Dataset of Test Migrations from Unittest to Pytest","A. Alves; A. Hora","Department of Computer Science, UFMG, Belo Horizonte, Brazil; Department of Computer Science, UFMG, Belo Horizonte, Brazil",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","841","845","Unittest and pytest are the most popular testing frameworks in Python. Overall, pytest provides some advantages, including simpler assertion, reuse of fixtures, and interoperability. Due to such benefits, multiple projects in the Python ecosystem have migrated from unittest to pytest. To facilitate the migration, pytest can also run unittest tests, thus, the migration can happen gradually over time. However, the migration can be time-consuming and take a long time to conclude. In this context, projects would benefit from automated solutions to support the migration process. In this paper, we propose TestMigrationsInPy, a dataset of test migrations from unittest to pytest. TestMigrationsInPy contains 923 real-world migrations performed by developers. Future research proposing novel solutions to migrate frameworks in Python can rely on TestMigrationsInPy as a ground truth. Moreover, as TestMigrationsInPy includes information about the migration type (e.g., changes in assertions or fixtures), our dataset enables novel solutions to be verified effectively, for instance, from simpler assertion migrations to more complex fixture migrations. TestMigrationsInPy is publicly available at: https://github.com/altinoalvesjunior/TestMigrationsInPy.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00122","EMI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025664","Software Testing;Framework Migration;LLMs;Software Repository Mining;unittest;pytest","Software testing;Codes;Fixtures;Ecosystems;Software;Data mining;Interoperability;Python","","","","41","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"pyMethods2Test: A Dataset of Python Tests Mapped to Focal Methods","I. Abdelmadjid; R. Dyer","University of Nebraska–Lincoln, Lincoln, NE, USA; University of Nebraska–Lincoln, Lincoln, NE, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","846","850","Python is one of the fastest-growing programming languages and currently ranks as the top language in many lists, even recently overtaking JavaScript as the top language on GitHub. Given its importance in data science and machine learning, it is imperative to be able to effectively train LLMs to generate good unit test cases for Python code. This motivates the need for a large dataset to provide training and testing data. To date, while other large datasets exist for languages like Java, none publicly exist for Python. Python poses difficult challenges in generating such a dataset, due to its less rigid naming requirements. In this work, we consider two commonly used Python unit testing frameworks: Pytest and unittest. We analyze a large corpus of over 88K open-source GitHub projects utilizing these testing frameworks. Using a carefully designed set of heuristics, we are able to locate over 22 million test methods. We then analyze the test and non-test code and map individual unit tests to the focal method being tested. This provides an explicit traceability link from the test to the tested method. Our pyMethods2Test dataset contains over 2 million of these focal method mappings, as well as the ability to generate useful context for input to LLMs. The pyMethods2Test dataset is publicly available on Zenodo at: https://doi.org/10.5281/zenodo.14264518","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00123","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025770","dataset;Python;software tests","Training;Software testing;Java;Codes;Machine learning;Data science;Software;Data mining;Python;Software development management","","","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"DataTD: A Dataset of Java Projects Including Test Doubles","M. Li; M. Fazzini","University of Minnesota, MN, USA; University of Minnesota, MN, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","851","855","Test doubles enable developers to isolate software components, simulate complex scenarios, and validate interactions during testing. Despite their critical role, there is a lack of systematically created and structured datasets for studying, devising, and evaluating techniques that aim to automate various aspects of the creation, usage, and maintenance of test doubles. To address this limitation, this paper introduces a novel dataset of 1,070 projects including test doubles. The dataset also includes carefully extracted metadata describing the use of the test doubles in the projects. Finally, the paper discusses the potential applications of the dataset in future research and directions for extending the dataset.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025757","","Java;Metadata;Software;Maintenance;Data mining;Testing","","","","40","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"JPerfEvo: A Tool for Tracking Method-Level Performance Changes in Java Projects","K. Shahedi; M. Lamothe; F. Khomh; H. Li","Polytechnique Montreal, Montreal, Canada; Polytechnique Montreal, Montreal, Canada; Polytechnique Montreal, Montreal, Canada; Polytechnique Montreal, Montreal, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","856","860","Performance regressions and improvements are common phenomena in software development, occurring periodically as software evolves and matures. When developers introduce new changes to a program’s codebase, unforeseen performance variations may arise. Identifying these changes at the method level, however, can be challenging due to the complexity and scale of modern codebases. In this work, we present JPerfEvo, a tool designed to automate the evaluation of the method-level performance impact of each code commit (i.e., the performance variations between the two versions before and after a commit). Leveraging the Java Microbenchmark Harness (JMH) module for benchmarking the modified methods, JPerfEvo instruments their execution and applies robust statistical evaluations to detect performance changes. The tool can classify these changes as performance improvements, regressions, or neutral (i.e., no change), with the change magnitude. We evaluated JPerfEvo on three popular and mature open-source Java projects, demonstrating its effectiveness in identifying performance changes throughout their development histories.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025671","performance;microbenchmarking;performance instrumentation","Java;Codes;Instruments;Benchmark testing;Software;Complexity theory;History;Data mining;Software development management","","","","34","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Author Index","",,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","861","865","","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025798","","","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
