"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"[Front cover]","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","1","1","Presents the front cover/splash page of the proceedings record.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796328","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Title Page iii","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","3","3","Presents the title page of this proceedings volume.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796286","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Table of Contents","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","v","xvii","Presents the table of contents/splash page of the proceedings record.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796375","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 General and Program Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xviii","xxii","Provides a listing of current committee members and society officers.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796203","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Data and Tool Showcase Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxiii","xxiii","On behalf of the entire Program Committee, it is our pleasure to welcome you to the Data and Tool Showcase Track of MSR 2022! The goal of this track is to provide a forum for actively promoting and recognizing the creation of reusable datasets and tools that are designed and built not only for a specific research project, but for the MSR community as a whole","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796233","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Hackathon Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxiv","xxiv","Today, software is developed thanks to many supporting systems, which provide help for source code management, code review, issue tracking, synchronous or asynchronous interpersonal communication, continuous integration, and many other tasks. Many of these systems store a wealth of data about how software is being developed, allowing for detailed studies and exploration tools that could be used to better understand software development","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796348","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Industry Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxv","xxv","The MSR 2022 Industry Track is the venue to present and learn about the opportunities, challenges, and cutting-edge technology related to using data from software repositories in practice. For a long time, academic researchers in software engineering have been looking to learn and collaborate with practitioners. Our goal for the new Industry Track is to be the space for a productive dialogue between software engineering researchers and practitioners, particularly those building tools for other software professionals. ","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796177","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Mining Challenge Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxvi","xxvii","The Mining Software Repositories (MSR) challenge is a long-standing tradition, dating back to 2006. It is open to all researchers in the field, and frequently participated in by young researchers and motivated students. MSR 2022 has been no exception, with the MSR conference holding the 17th edition of the challenge, which we have been honored to chair. ","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796282","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Registered Reports Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxviii","xxix","Empirical Software Engineering Journal (EMSE), in conjunction with the conference on Mining Software Repositories (MSR), is continuing the Registered Reports (RR) track. The RR track of MSR 2022 has two goals: (1) to prevent HARKing (hypothesizing after the results are known) for empirical studies; (2) to provide early feedback to authors in their initial study design. For papers submitted to the RR track, methods and proposed analyses are reviewed prior to execution. Pre-registered studies follow a two-step process: ","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796294","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Shadow PC Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxx","xxx","The Shadow PC track was introduced in MSR 2021. It is a unique opportunity for PhD students and early career researchers to understand the peer review process first hand. MSR 2022 continued with the Shadow PC track while learning from the lessons of the previous year, mainly scaling the load of shadow PC members and mentors.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796189","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the MSR 2022 Tutorials Track Co-Chairs","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxxi","xxxi","","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796342","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Organizing Committee","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxxii","xxxiv","Provides a listing of current committee members.","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796259","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Program Committee","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","xxxv","xliv","","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796367","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"An Empirical Evaluation of GitHub Copilot's Code Suggestions","N. Nguyen; S. Nadi","University of Alberta, Edmonton, AB, Canada; University of Alberta, Edmonton, AB, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","1","5","GitHub and OpenAI recently launched Copilot, an “AI pair programmer” that utilizes the power of Natural Language Processing, Static Analysis, Code Synthesis, and Artificial Intelligence. Given a natural language description of the target functionality, Copilot can generate corresponding code in several programming languages. In this paper, we perform an empirical study to evaluate the correctness and understandability of Copilot's suggested code. We use 33 LeetCode questions to create queries for Copilot in four different programming languages. We evaluate the correctness of the corresponding 132 Copilot solutions by running LeetCode's provided tests, and evaluate understandability using SonarQube's cyclomatic complexity and cognitive complexity metrics. We find that Copilot's Java suggestions have the highest correctness score (57%) while JavaScript is the lowest (27%). Overall, Copilot's suggestions have low complexity with no notable differences between the programming languages. We also find some potential Copilot shortcomings, such as generating code that can be further simplified and code that relies on undefined helper methods.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796235","Program Synthesis;Codex;GitHub Copilot;Empirical Evaluation","Measurement;Java;Codes;Static analysis;Software;Natural language processing;Complexity theory","","81","","32","","21 Jun 2022","","","IEEE","IEEE Conferences"
"BotHunter: An Approach to Detect Software Bots in GitHub","A. Abdellatif; M. Wessel; I. Steinmacher; M. A. Gerosa; E. Shihab","Concordia University, Montreal, Canada; Delft University of Technology, Delft, Netherlands; Universidade Tecnológica Federal do Paraná, Campo Mourão, Brazil; Northern Arizona University, Flagstaff, USA; Concordia University, Montreal, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","6","17","Bots have become popular in software projects as they play critical roles, from running tests to fixing bugs/vulnerabilities. However, the large number of software bots adds extra effort to practitioners and researchers to distinguish human accounts from bot accounts to avoid bias in data-driven studies. Researchers developed several approaches to identify bots at specific activity levels (issue/pull request or commit), considering a single repository and disregarding features that showed to be effective in other domains. To address this gap, we propose using a machine learning-based approach to identify the bot accounts regardless of their activity level. We selected and extracted 19 features related to the account's profile information, activities, and comment similarity. Then, we evaluated the performance of five machine learning classifiers using a dataset that has more than 5,000 GitHub accounts. Our results show that the Random Forest classifier performs the best, with an F1-score of 92.4% and AUC of 98.7%. Furthermore, the account profile information (e.g., account login) contains the most relevant features to identify the account type. Finally, we compare the performance of our Random Forest classifier to the state-of-the-art approaches, and our results show that our model outperforms the state-of-the-art techniques in identifying the account type regardless of their activity level.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527959","National Science Foundation(grant numbers:1815503,1900903); CNPq(grant numbers:313067/2020-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796262","Software Bots;Empirical Software Engineering","Bot (Internet);Feature extraction;Transformers;Software;Encoding;Data mining;Time factors","","10","","53","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Comments on Comments: Where Code Review and Documentation Meet","N. Rao; J. Tsay; M. Hirzel; V. J. Hellendoorn",Carnegie Mellon University United States; IBM Research United States; IBM Research United States; Carnegie Mellon University United States,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","18","22","A central function of code review is to increase understanding; helping reviewers understand a code change aids in knowledge transfer and finding bugs. Comments in code largely serve a similar purpose, helping future readers understand the program. It is thus natural to study what happens when these two forms of understanding collide. We ask: what documentation-related comments do reviewers make and how do they affect understanding of the contribution? We analyze ca. 700K review comments on 2,000 (Java and Python) GitHub projects, and propose several filters to identify which comments are likely to be either in response to a change in documentation and/or call for such a change. We identify 65K such cases. We next develop a taxonomy of the reviewer intents behind such “comments on comments”. We find that achieving a shared under-standing of the code is key: reviewer comments most often focused on clarification, followed by pointing out issues to fix, such as typos and outdated comments. Curiously, clarifying comments were frequently suggested (often verbatim) by the reviewer, indicating a desire to persist their understanding acquired during code review. We conclude with a discussion of implications of our comments-on-comments dataset for research on improving code review, including the potential benefits for automating code review.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796192","","Java;Codes;Taxonomy;Computer bugs;Documentation;Software;Data mining","","","","11","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"Does This Apply to Me? An Empirical Study of Technical Context in Stack Overflow","A. Galappaththi; S. Nadi; C. Treude","University of Alberta, Edmonton, Alberta, Canada; University of Alberta, Edmonton, Alberta, Canada; University of Melbourne, Victoria, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","23","34","Stack Overflow has become an essential technical resource for developers. However, given the vast amount of knowledge available on Stack Overflow, finding the right information that is relevant for a given task is still challenging, especially when a developer is looking for a solution that applies to their specific requirements or technology stack. Clearly marking answers with their technical context, i.e., the information that characterizes the technologies and assumptions needed for this answer, is potentially one way to improve navigation. However, there is no information about how often such context is mentioned, and what kind of information it might offer. In this paper, we conduct an empirical study to understand the occurrence of technical context in Stack Overflow answers and comments, using tags as a proxy for technical context. We specifically focus on additional context, where answers/comments mention information that is not already discussed in the question. Our results show that nearly half of our studied threads contain at least one additional context. We find that almost 50% of the additional context are either a library/framework, a programming language, a tool/application, an API, or a database. Overall, our findings show the promise of using additional context as navigational cues.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796260","Stack Overflow;contextual information;navigating information","Context;Computer languages;Navigation;Databases;Instruction sets;Software;Data mining","","1","","24","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Towards Reliable Agile Iterative Planning via Predicting Documentation Changes of Work Items","J. Pasuksmit; P. Thongtanunam; S. Karunasekera","The University of Melbourne, Australia; The University of Melbourne, Australia; The University of Melbourne, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","35","47","In agile iterative development, an agile team needs to analyze documented information for effort estimation and sprint planning. While documentation can be changed, the documentation changes after sprint planning may invalidate the estimated effort and sprint plan. Hence, to help the team be aware of the potential documentation changes, we developed DocWarn to estimate the probability that a work item will have documentation changes. We developed three variations of DocWarn, which are based on the characteristics extracted from the work items (DocWarn-C), the natural language text (DocWarn-T), and both inputs (DocWarn-H). Based on nine open-source projects that work in sprints and actively maintain documentation, DocWarn can predict the documentation changes with an average AUC of 0.75 and an average F1-Score of 0.36, which are significantly higher than the baselines. We also found that the most influential characteristics of a work item for determining the future documentation changes are the past tendency of the developers and the length of description text. Based on the qualitative assessment, we found that 40%-68% of the correctly predicted documentation changes were related to scope modification. With the prediction of DocWarn, the team will be better aware of the potential documentation changes during sprint planning, allowing the team to manage the uncertainty and reduce the risk of unreliable effort estimation and sprint planning.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796335","agile;documentation;iteration planning;sprint planning;effort estimation;document;change","Uncertainty;Natural languages;Estimation;Documentation;Planning;Iterative methods;Reliability","","2","","62","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems","C. M. Lüders; A. Bouraffa; W. Maalej","University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","48","60","Software projects use Issue Tracking Systems (ITS) like JIRA to track issues and organize the workflows around them. Issues are often inter-connected via different links such as the default JIRA link types Duplicate, Relate, Block, or Subtask. While previous research has mostly focused on analyzing and predicting duplication links, this work aims at understanding the various other link types, their prevalence, and characteristics towards a more reliable link type prediction. For this, we studied 607,208 links connecting 698,790 issues in 15 public JIRA repositories. Besides the default types, the custom types Depend, Incorporate, Split, and Cause were also common. We manually grouped all 75 link types used in the repositories into five general categories: General Relation, Duplication, Composition, Temporal/Causal, and Workflow. Comparing the structures of the corresponding graphs, we observed several trends. For instance, Duplication links tend to represent simpler issue graphs often with two components and Composition links present the highest amount of hierarchical tree structures (97.7%). Surprisingly, General Relation links have a significantly higher transitivity score than Duplication and Temporal/ Causal links. Motivated by the differences between the link types and by their popularity, we evaluated the robustness of two state-of-the-art duplicate detection approaches from the literature on the JIRA dataset. We found that current deep-learning approaches confuse between Duplication and other links in almost all repositories. On average, the classification accuracy dropped by 6% for one approach and 12% for the other. Extending the training sets with other link types seems to partly solve this issue. We discuss our findings and their implications for research and practice.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528457","European Union(grant numbers:732463); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796252","Issue Management;Issue Tracking System;Duplicate Detection;Link Type Detection;Dependency Management","Training;Analytical models;Uncertainty;Semantics;Training data;Organizations;Predictive models","","2","","42","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Smelly Variables in Ansible Infrastructure Code: Detection, Prevalence, and Lifetime","R. Opdebeeck; A. Zerouali; C. De Roover","Vrije Universiteit Brussel, Brussels, Belgium; Vrije Universiteit Brussel, Brussels, Belgium; Vrije Universiteit Brussel, Brussels, Belgium",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","61","72","Infrastructure as Code is the practice of automating the provisioning, configuration, and orchestration of network nodes using code in which variable values such as configuration parameters, node hostnames, etc. play a central role. Mistakes in these values are an important cause of infrastructure defects and corresponding outages. Ansible, a popular IaC language, nonetheless features semantics which can cause confusion about the value of variables. In this paper, we identify six novel code smells related to Ansible's intricate variable precedence rules and lazy-evaluated template expressions. Their detection requires an accurate representation of control and data flow, for which we transpose the program dependence graph to Ansible. We use the resulting detector to empirically investigate the prevalence of these variable smells in 21,931 open-source Ansible roles, uncovering 31,334 unique smell instances across 4,260 roles. We observe an upward trend in the number of variable smells over time, that it may take a long time before they are fixed, and that code changes more often introduce new smells than fix existing ones. Our results are a call to arms for more in-depth quality checkers for IaC code, and highlight the importance of transcending syntax in IaC research.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527964","Research Foundation Flanders(grant numbers:No); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796178","Infrastructure as Code;Ansible;code smells;program dependence graphs;empirical study;software quality","Codes;Semantics;Detectors;Syntactics;Maintenance engineering;Market research;Software reliability","","13","","43","","21 Jun 2022","","","IEEE","IEEE Conferences"
"An Alternative Issue Tracking Dataset of Public Jira Repositories","L. Montgomery; C. Lüders; W. Maalej","University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","73","77","Organisations use issue tracking systems (ITSs) to track and document their projects' work in units called issues. This style of documentation encourages evolutionary refinement, as each issue can be independently improved, commented on, linked to other issues, and progressed through the organisational workflow. Commonly studied ITSs so far include GitHub, GitLab, and Bugzilla, while Jira, one of the most popular ITS in practice with a wealth of additional information, has yet to receive similar attention. Unfortunately, diverse public Jira datasets are rare, likely due to the difficulty in finding and accessing these repositories. With this paper, we release a dataset of 16 public Jiras with 1822 projects, spanning 2.7 million issues with a combined total of 32 million changes, 9 million comments, and 1 million issue links. We believe this Jira dataset will lead to many fruitful research projects investigating issue evolution, issue linking, cross-project analysis, as well as cross-tool analysis when combined with existing well-studied ITS datasets.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528486","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:PGSD3-518105-2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796369","datasets;issue trackers;jira;thematic analysis","Documentation;Software;Data mining;Software development management","","6","","22","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Real-World Clone-Detection in Go","Q. Wu; H. Song; P. Yang","ByteDance Ltd., Beijing, China; ByteDance Ltd., Beijing, China; ByteDance Ltd., Beijing, China",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","78","79","In the early stage of development, developers copied internal code snippets to enhance developing efficiency. With the rapid growth of Bytedance, similar or equivalent code snip-pets across different repositories or different product lines' codebases would potentially increase the cost of maintenance and distribute vulnerable code snippets. With the application of Clone-Detection, there are multiple well-established tools or techniques used for detecting similar code snippets in Java, JavaScript, Objective C and etc [1], [3]. We could hardly find similar tools available for Go, a widely-used programming language in the field of server development, especially at Bytedance. For the lack of public and labeled datasets, we utilized a great number of code snippets in Bytedance's codebase and trained an unsupervised model to propose Go-CopyCatch (GoCC), a tool and technique for Clone-Detection in Go.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796255","","Java;Computer languages;Codes;Costs;Maintenance engineering;Software;Servers","","1","","3","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Geographic Diversity in Public Code Contributions: An Exploratory Large-Scale Study Over 50 Years","D. Rossi; S. Zacchiroli","University of Bologna, Bologna, Italy; LTCI, Télécom Paris, Institut Polytechnique de Paris, Paris, France",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","80","85","We conduct an exploratory, large-scale, longitudinal study of 50 years of commits to publicly available version control system repositories, in order to characterize the geographic diversity of contributors to public code and its evolution over time. We analyze in total 2.2 billion commits collected by Software Heritage from 160 million projects and authored by 43 million authors during the 1971–2021 time period. We geolocate developers to 12 world regions derived from the United Nation geoscheme, using as signals email top-level domains, author names compared with names distributions around the world, and UTC offsets mined from commit metadata. We find evidence of the early dominance of North America in open source software, later joined by Europe. After that period, the geographic diversity in public code has been constantly increasing. We also identify relevant historical shifts related to the UNIX wars, the increase of coding literacy in Central and South Asia, and broader phenomena like colonialism and people movement across countries (immigration/emigration).","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796333","geography;diversity;open source;commit;version control systems;social coding;software heritage","Codes;Geology;Asia;Europe;Control systems;Encoding;Data mining","","1","","33","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Operationalizing Threats to MSR Studies by Simulation-Based Testing","J. Härtel; R. Lämmel","University of Koblenz, Germany; University of Koblenz, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","86","97","Quantitative studies on the border between Mining Software Repository (MSR) and Empirical Software Engineering (ESE) apply data analysis methods, like regression modeling, statistic tests or correlation analysis, to commits or pulls to better understand the software development process. Such studies assure the validity of the reported results by following a sound methodology. However, with increasing complexity, parts of the methodology can still go wrong. This may result in MSR/ESE studies with undetected threats to validity. In this paper, we propose to systematically protect against threats by operationalizing their treatment using simulations. A simulation substitutes observed and unobserved data, related to an MSR/ESE scenario, with synthetic data, carefully defined according to plausible assumptions on the scenario. Within a simulation, unobserved data becomes transparent, which is the key difference to a real study, necessary to detect threats to an analysis methodology. Running an analysis methodology on synthetic data may detect basic technical bugs and misinterpretations, but it also improves the trust in the methodology. The contribution of a simulation is to operationalize testing the impact of important assumptions. Assumptions still need to be rated for plausibility. We evaluate simulation-based testing by operationalizing undetected threats in the context of four published MSR/ESE studies. We recommend that future research uses such more systematic treatment of threats, as a contribution against the reproducibility crisis.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796185","Simulation;empirical studies;threats;synthetic data;testing","Analytical models;Systematics;Data analysis;Correlation;Data models;Software;Reproducibility of results","","1","","54","","21 Jun 2022","","","IEEE","IEEE Conferences"
"The General Index of Software Engineering Papers","Z. A. Khalil; S. Zacchiroli","Inria, Paris, France; LTCI, Télécom Paris, Institut Polytechnique de Paris, Paris, France",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","98","102","We introduce the General Index of Software Engineering Papers, a dataset of fulltext-indexed papers from the most prominent scientific venues in the field of Software Engineering. The dataset includes both complete bibliographic information and indexed n-grams (sequence of contiguous words after removal of stopwords and non-words, for a total of 577 276 382 unique n-grams in this release) with length 1 to 5 for 44 581 papers retrieved from 34 venues over the 1971–2020 period. The dataset serves use cases in the field of meta-research, allowing to introspect the output of software engineering research even when access to papers or scholarly search engines is not possible (e.g., due to contractual reasons). The dataset also contributes to making such analyses reproducible and independently verifiable, as opposed to what happens when they are conducted using 3rd-party and non-open scholarly indexing services. The dataset is available as a portable Postgres database dump and released as open data.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796170","dataset;academic publishing;software engineering;ngrams;meta-analysis;natural language processing;fulltext index","Codes;Databases;Semantics;Search engines;Software;Data mining;Open data","","","","24","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Challenges and Future Research Direction for Microtask Programming in Industry","M. Kondo; S. Saito; Y. Iimura; E. Choi; O. Mizuno; Y. Kamei; N. Ubayashi","Kyushu University, Japan; NTT Computer and Data Science Laboratories, Japan; NTT Computer and Data Science Laboratories, Japan; Kyoto Institute of Technology, Japan; NTT Computer and Data Science Laboratories, Japan; Kyushu University, Japan; Kyushu University, Japan",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","103","104","Microtask programming [4] is a solution to promote distributed development in industry. The key idea of microtask programming is to reduce face-to-face communication across developers by splitting the development task of software into independent microtasks. Such microtasks can be completed by crowd workers who work remotely and at their preferable time such as early morning. Dedicated developers who have the responsibility for the progress of development split the task into microtasks, and distribute them to crowd workers. Hence, microtask programming has these two actors. Our research team reported that microtask programming has potential benefits such as the fluidity of project assignments in industrial companies [4]. However, we suppose it still has challenges. In addition, it is still unclear what are future research direction to support both actors in microtask programming, though our research team has conducted three studies for microtask programming so far [2]–[4].","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796270","Microtask programming;Interview;Software development","Industries;Companies;Programming;Software;Data mining;Task analysis","","1","","4","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Starting the InnerSource Journey: Key Goals and Metrics to Measure Collaboration","D. Izquierdo-Cortázar; J. Alonso-Gutiérrez; A. Pérez García-Plaza; G. Robles; J. M. González-Barahona","Bitergia, Spain; Santander Group, Spain; Bitergia, Spain; Universidad Rey Juan Carlos, Spain; Universidad Rey Juan Carlos, Spain",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","105","106","InnerSource is the application of best open source practices within the walls of the organization. Large corporations are required to be more and more efficient in the development of software and even more in the banking industry. There are three main areas of expenditure: infrastructure and facilities, people, and technology. The latter is of importance nowadays as key for the business and core to this paper. Reusability and collaboration are some of the ways a large corporation can be more efficient in technology. By being able to discover existing software and collaborating across business units, departments, or even geographical regions, corporations can share effort across them, and avoid starting once and again a similar piece of software.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796353","innersource;gqm;development metrics;software repositories","Industries;Collaboration;Organizations;Banking;Software;Software measurement;Data mining","","","","0","","21 Jun 2022","","","IEEE","IEEE Conferences"
"An Exploratory Study on Refactoring Documentation in Issues Handling","E. A. AlOmar; A. Peruma; M. W. Mkaouer; C. D. Newman; A. Ouni","Stevens Institute of Technology, Hoboken, New Jersey, USA; Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA; ETS Montreal, University of Quebec, Montreal, Quebec, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","107","111","Understanding the practice of refactoring documentation is of para-mount importance in academia and industry. Issue tracking systems are used by most software projects enabling developers, quality assurance, managers, and users to submit feature requests and other tasks such as bug fixing and code review. Although recent studies explored how to document refactoring in commit messages, little is known about how developers describe their refactoring needs in issues. In this study, we aim at exploring developer-reported refactoring changes in issues to better understand what developers consider to be problematic in their code and how they handle it. Our approach relies on text mining 45,477 refactoring-related issues and identifying refactoring patterns from a diverse corpus of 77 Java projects by investigating issues associated with 15,833 refactoring operations and developers' explicit refactoring intention. Our results show that (1) developers mostly use move refactoring related terms/phrases to target refactoring-related issues; and (2) developers tend to explicitly mention the improvement of specific quality attributes and focus on duplicate code removal. We envision our findings enabling tool builders to support developers with automated documentation of refactoring changes in issues.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796239","Refactoring documentation;issues;software quality;mining soft-ware repositories","Text mining;Industries;Java;Codes;Quality assurance;Computer bugs;Documentation","","2","","32","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Between JIRA and GitHub: ASFBot and its Influence on Human Comments in Issue Trackers","A. Moharil; D. Orlov; S. Jameel; T. Trouwen; N. Cassee; A. Serebrenik","Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","112","116","Open-Source Software (OSS) projects have adopted various automations for repetitive tasks in recent years. One common type of automation in OSS is bots. In this exploratory case study, we seek to understand how the adoption of one particular bot (ASFBot) by the Apache Software Foundation (ASF) impacts the discussions in the issue-trackers of these projects. We use the SmartShark dataset to investigate whether the ASFBot affects (i) human comments mentioning pull requests and fixes in issue comments and (ii) the general human comment rate on issues. We apply a regression discontinuity design (RDD) on nine ASF projects that have been active both before and after the ASFBot adoption. Our results indicate (i) an immediate decrease in the number of median comments mentioning pull requests and fixes after the bot adoption, but the trend of a monthly decrease in this comment count is reversed, and (ii) no effect in the number of human comments after the bot adoption. We make an effort to gather first insights in understanding the impact of adopting the ASFBot on the commenting behavior of developers who are working on ASF projects.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796306","bots;ASFBot;issue-trackers;Apache","Bot (Internet);Automation;Market research;Behavioral sciences;Data mining;Task analysis;Open source software","","1","","30","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"Is Refactoring Always a Good Egg? Exploring the Interconnection Between Bugs and Refactorings","A. Bagheri; P. Hegedűs","University of Szeged, Hungary; University of Szeged, Hungary",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","117","121","Bug fixing and code refactoring are two distinct maintenance actions with different goals. While bug fixing is a corrective change that eliminates a defect from the program, refactoring targets improving the internal quality (i.e., maintainability) of a software system without changing its functionality. Best practices and common intuition suggest that these code actions should not be mixed in a single code change. Furthermore, as refactoring aims for improving quality without functional changes, we would expect that refactoring code changes will not be sources of bugs. Nonetheless, empirical studies show that none of the above hypotheses are necessarily true in practice. In this paper, we empirically investigate the interconnection between bug-related and refactoring code changes using the SmartSHARK dataset. Our goal is to explore how often bug fixes and refactorings co-occur in a single commit (tangled changes) and whether refactoring changes themselves might induce bugs into the system. We found that it is not uncommon to have tangled commits of bug fixes and refactorings; 21% of bug-fixing commits include at least one type of refactoring on average. What is even more shocking is that 54% of bug-inducing commits also contain code refactoring changes. For instance, 10% (652 occurrences) of the Change Variable Type refactorings in the dataset appear in bug-inducing commits that make up 7.9% of the total inducing commits.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528034","Hungarian Academy of Sciences(grant numbers:NKP-21-5-SZTE-570); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796303","Bug inducing commits;refactoring;tangled code changes;empirical analysis","Codes;Computer bugs;Maintenance engineering;Software systems;Hazards;Behavioral sciences;Data mining","","1","","30","","21 Jun 2022","","","IEEE","IEEE Conferences"
"On the Co-Occurrence of Refactoring of Test and Source Code","N. A. Nagy; R. Abdalkareem","Concordia University, Montreal, Canada; Concordia University, Montreal, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","122","126","Refactoring is a widespread practice that aims to help improve the quality of a software system without altering its external behaviour. In practice, developers can perform refactoring operations on test and source code. However, while prior work showed that refactoring source code brings many benefits, few studies investigated test code refactoring and whether it co-occurred with source code. To examine the co-occurring refactorings, we conducted an empirical study of 60,465 commits spanning 77 open-source Java projects. First, we quantitatively analyzed the commits from those projects to identify co-occurring refactoring commits (i.e., commits contain refactorings performed on test and source code). Our results showed that on average 17.9% of refactoring commits are co-occurring refactoring commits, which is twice as much as test code-only refactoring commits. Also, we investigated the type of refactorings applied to test code in those co-occurring commits. We found Change Variable Type and Move Class are the most common applied refactorings. Second, we trained random forest classifiers to predict when refactoring test code should co-occur with refactoring source code using features extracted from the refactoring source code in ten selected projects. Our results showed that the classifier can accurately predict when test and source code refactoring co-occurs with AUC values between 0.67-0.92. Our analysis also showed that the most important features in our classifiers are related the refactoring size and developer refactoring experience.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796251","Source and Test Code Refactoring;Empirical Study","Java;Codes;Feature extraction;Software systems;Data mining;Random forests;Open source software","","2","","22","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Refactoring Debt: Myth or Reality? An Exploratory Study on the Relationship Between Technical Debt and Refactoring","A. Peruma; E. A. AlOmar; C. D. Newman; M. W. Mkaouer; A. Ouni","Rochester Institute of Technology, Rochester, NY, USA; Stevens Institute of Technology, Hoboken, NJ, USA; Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA; ETS Montreal, University of Quebec, Montreal, QC, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","127","131","To meet project timelines or budget constraints, developers intentionally deviate from writing optimal code to feasible code in what is known as incurring Technical Debt (TD). Furthermore, as part of planning their correction, developers document these deficiencies as comments in the code (i.e., self-admitted technical debt or SATD). As a means of improving source code quality, developers often apply a series of refactoring operations to their codebase. In this study, we explore developers repaying this debt through refactoring operations by examining occurrences of SATD removal in the code of 76 open-source Java systems. Our findings show that TD payment usually occurs with refactoring activities and developers refactor their code to remove TD for specific reasons. We envision our findings supporting vendors in providing tools to better support developers in the automatic repayment of technical debt.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796264","Mining Software Repositories;Technical Debt;Refactoring;Self Admitted Technical Debt","Java;Codes;Taxonomy;Writing;Market research;Planning;Appraisal","","","","31","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Studying the Impact of Continuous Delivery Adoption on Bug-Fixing Time in Apache's Open-Source Projects","C. D. A. de Almeida; D. N. Feijó; L. S. Rocha","Federal University of Ceará, Fortaleza, Ceará, Brazil; Federal University of Ceará, Fortaleza, Ceará, Brazil; Federal University of Ceará, Fortaleza, Ceará, Brazil",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","132","136","Buggy software impacts people's lives and businesses. Nowadays, a huge portion of a software project's cost is spent on debugging (finding and fixing bugs). Therefore, reducing the time needed to release new software versions free from bugs becomes crucial. Continuous delivery (CD) arises as an alternative to traditional software release engineering by providing the capability to faster and continuously release software to customers through automated pipelines. Previous studies claim that CD adoption leads to a reduction in the software release cycle time, including the time lag to fix reported bugs (bug-fixing time) and apply correction patches in the affected versions. However, there is a lack of empirical evidence supporting (or not) this claim. To fulfill this gap, we conducted an empirical study to evaluate the impact of CD adoption in the bug-fixing time. We study 25 open-source projects comparing the bug-fixing time before and after adopting CD. Our results show that bug-fixing time after CD adoption becomes shorter (with statistical significance) than the bug-fixing time before CD adoption.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796195","mining software repositories;bug-fixing time;continuous delivery","Release engineering;Costs;Computer bugs;Pipelines;Debugging;Data mining;Open source software","","4","","19","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Which bugs are missed in code reviews: An empirical study on SmartSHARK dataset","F. Khoshnoud; A. R. Nasab; Z. Toudeji; A. Sami","Department of CSE and IT, Shiraz University, Shiraz, Iran; Department of CSE and IT, Shiraz University, Shiraz, Iran; Department of CSE and IT, Shiraz University, Shiraz, Iran; Department of CSE and IT, Shiraz University, Shiraz, Iran",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","01","05","In pull-based development systems, code reviews and pull request comments play important roles in improving code quality. In such systems, reviewers attempt to carefully check a piece of code by different unit tests. Unfortunately, some-times they miss bugs in their review of pull requests, which lead to quality degradations of the systems. In other words, disastrous consequences occur when bugs are observed after merging the pull requests. The lack of a concrete understanding of these bugs led us to investigate and categorize them. In this research, we try to identify missed bugs in pull requests of SmartSHARK dataset projects. Our contribution is twofold. First, we hypothesized merged pull requests that have code reviews, code review comments, or pull request comments after merging, may have missed bugs after the code review. We considered these merged pull requests as candidate pull requests having missed bugs. Based on our assumption, we obtained 3,261 candidate pull requests from 77 open-source GitHub projects. After two rounds of restrictive manual analysis, we found 187 bugs missed in 173 pull requests. In the first step, we found 224 buggy pull requests containing missed bugs after merging the pull requests. Secondly, we defined and finalized a taxonomy that is appropriate for the bugs that we found and then found the distribution of bug categories after analysing those pull requests all over again. The categories of missed bugs in pull requests and their distributions are: semantic (51.34%), build (15.5%), analysis checks (9.09%), compatibility (7.49%), concurrency (4.28%), configuration (4.28%), GUI (2.14%), API (2.14%), security (2.14%), and memory (1.6%).","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796172","code review;pull request;missed bugs;SmartSHARK dataset","Codes;Computer bugs;Merging;Taxonomy;Semantics;Manuals;Security","","2","","15","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Empirical Standards for Repository Mining","P. Chatterjee; T. Sharma; P. Ralph","Drexel University, Philadelphia, PA, USA; Dalhousie University, Halifax, NS, Canada; Dalhousie University, Halifax, NS, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","142","143","The purpose of scholarly peer review is to evaluate the quality of scientific manuscripts. However, study after study demonstrates that peer review neither effectively nor reliably assesses research quality. Empirical standards attempt to address this problem by modelling a scientific community's expectations for each kind of empirical study conducted in that community. This should enhance not only the quality of research but also the reliability and pre-dictability of peer review, as scientists adopt the standards in both their researcher and reviewer roles. However, these improvements depend on the quality and adoption of the standards. This tutorial will therefore present the empirical standard for mining software repositories, both to communicate its contents and to get feedback from the attendees. The tutorial will be organized into three parts: (1) brief overview of the empirical standards project; (2) detailed presentation of the repository mining standard; (3) discussion and suggestions for improvement.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796211","Mining software repositories;Empirical standards;scholarly peer review","Tutorials;Software;Software reliability;Data mining;Standards","","1","","5","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Dazzle: Using Optimized Generative Adversarial Networks to Address Security Data Class Imbalance Issue","R. Shu; T. Xia; L. Williams; T. Menzies","North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","144","155","Background: Machine learning techniques have been widely used and demonstrate promising performance in many software security tasks such as software vulnerability prediction. However, the class ratio within software vulnerability datasets is often highly imbalanced (since the percentage of observed vulnerability is usually very low). Goal: To help security practitioners address software security data class imbalanced issues and further help build better prediction models with resampled datasets. Method: We introduce an approach called Dazzle which is an optimized version of conditional Wasserstein Generative Adversarial Networks with gradient penalty (cWGAN-GP). Dazzle explores the architecture hyperparameters of cWGAN-GP with a novel optimizer called Bayesian Optimization. We use Dazzle to generate minority class samples to resample the original imbalanced training dataset. Results: We evaluate Dazzle with three software security datasets, i.e., Moodle vulnerable files, Ambari bug reports, and JavaScript function code. We show that Dazzle is practical to use and demonstrates promising improvement over existing state-of-the-art oversampling techniques such as SMOTE (e.g., with an average of about 60% improvement rate over SMOTE in recall among all datasets). Conclusion: Based on this study, we would suggest the use of optimized GANs as an alternative method for security vulnerability data class imbalanced issues.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796337","Security Vulnerability Prediction;Class Imbalance;Hyperparameter Optimization;Generative Adversarial Networks","Training;Computer architecture;Predictive models;Generative adversarial networks;Software;Data models;Security","","3","","69","","21 Jun 2022","","","IEEE","IEEE Conferences"
"How to Improve Deep Learning for Software Analytics (a case study with code smell detection)","R. Yedida; T. Menzies","Dept. of Computer Science, NC State University, USA; Dept. of Computer Science, NC State University, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","156","166","To reduce technical debt and make code more maintainable, it is important to be able to warn programmers about code smells. State-of-the-art code small detectors use deep learners, usually without exploring alternatives. For example, one promising alternative is GHOST (from TSE'21) that relies on a combination of hyper-parameter optimization of feedforward neural networks and a novel oversampling technique. The prior study from TSE'21 proposing this novel “fuzzy sampling” was somewhat limited in that the method was tested on defect prediction, but nothing else. Like defect prediction, code smell detection datasets have a class imbalance (which motivated “fuzzy sampling”). Hence, in this work we test if fuzzy sampling is useful for code smell detection. The results of this paper show that we can achieve better than state-of-the-art results on code smell detection with fuzzy oversampling. For example, for “feature envy”, we were able to achieve 99+% AUC across all our datasets, and on 8/10 datasets for “misplaced class”. While our specific results refer to code smell detection, they do suggest other lessons for other kinds of analytics. For example: (a) try better preprocessing before trying complex learners (b) include simpler learners as a baseline in software analytics (c) try “fuzzy sampling” as one such baseline. In order to support others trying to reproduce/extend/refute this work, all our code and data is available online at https://github.com/yrahul3910/code-smell-detection.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528458","NSF(grant numbers:1908762); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796274","code smell detection;deep learning;autoencoders","Deep learning;Codes;Software algorithms;Detectors;Prediction algorithms;Software;Feedforward neural networks","","4","","59","","21 Jun 2022","","","IEEE","IEEE Conferences"
"To What Extent do Deep Learning-based Code Recommenders Generate Predictions by Cloning Code from the Training Set?","M. Ciniselli; L. Pascarella; G. Bavota","SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","167","178","Deep Learning (DL) models have been widely used to support code completion. These models, once properly trained, can take as input an incomplete code component (e.g., an incomplete function) and predict the missing tokens to finalize it. GitHub Copilot is an example of code recommender built by training a DL model on millions of open source repositories: The source code of these repositories acts as training data, allowing the model to learn “how to program”. The usage of such a code is usually regulated by Free and Open Source Software (FOSS) licenses, that establish under which conditions the licensed code can be redistributed or modified. As of Today, it is unclear whether the code generated by DL models trained on open source code should be considered as “new” or as “derivative” work, with possible implications on license infringements. In this work, we run a large-scale study investigating the extent to which DL models tend to clone code from their training set when recommending code completions. Such an exploratory study can help in assessing the magnitude of the potential licensing issues mentioned before: If these models tend to generate new code that is unseen in the training set, then licensing issues are unlikely to occur. Otherwise, a revision of these licenses urges to regulate how the code generated by these models should be treated when used, for example, in a commercial setting. Highlights from our results show that ∼10% to ∼0.1% of the predictions generated by a state-of-the-art DL-based code completion tool are Type-1 clones of instances in the training set, depending on the size of the predicted code. Long predictions are unlikely to be cloned.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528440","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796377","Deep Learning;Code Completion;Code Clones","Training;Deep learning;Codes;Cloning;Training data;Detectors","","8","","60","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Searching for High-Fidelity Builds Using Active Learning","H. Menon; K. Parasyris; T. Scogland; T. Gamblin","Lawrence Livermore National Laboratory, Livermore, CA, USA; Lawrence Livermore National Laboratory, Livermore, CA, USA; Lawrence Livermore National Laboratory, Livermore, CA, USA; Lawrence Livermore National Laboratory, Livermore, CA, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","179","190","Modern software is incredibly complex. A typical application may comprise hundreds or thousands of reusable components. Automated package managers can help to maintain a consistent set of dependency versions, but ultimately the solvers in these systems rely on constraints generated by humans. At scale, small errors add up, and it becomes increasingly difficult to find high-fidelity configurations. We cannot test all configurations, because the space is combinatorial, so exhaustive exploration is infeasible. In this paper, we present Reliabuild, an auto-tuning framework that efficiently explores the build configuration space and learns which package versions are likely to result in a successful configuration. We implement two models in Reliabuild to rank the different configurations and use adaptive sampling to select good configurations with fewer samples. We demonstrate Reliabuild's effectiveness by evaluating 31,186 build configurations of 61 packages from the Extreme-scale Scientific Software Stack (E4S). Reliabuild selects good configurations efficiently. For example, Reliabuild selects 3× the number of good configurations in comparison to random sampling for several packages including Abyss, Bolt, libnrm, OpenMPI. Our framework is also able to select all the high-fidelity builds in half the number of samples required by random sampling for packages such as Chai, OpenMPI, py-petsc4py, and slepc. We further use the model to learn statistics about the compatibility of different packages, which will enable package solvers to better select high-fidelity build configurations automatically.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528464","U.S. Department of Energy; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344,LLNL-CONF-831078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796317","","Adaptation models;Biological system modeling;Ecosystems;Fasteners;Reliability engineering;Software;Software reliability","","2","","56","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"ApacheJIT: A Large Dataset for Just-In-Time Defect Prediction","H. Keshavarz; M. Nagappan","David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","191","195","In this paper, we present ApacheJIT, a large dataset for Just-In-Time (JIT) defect prediction. ApacheJIT consists of clean and bug-inducing software changes in 14 popular Apache projects. ApacheJIT has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). Having a large number of commits makes ApacheJIT a suitable dataset for machine learning JIT models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796180","Defect Prediction;Software Engineering;Dataset","Training;Deep learning;Computer bugs;Predictive models;Data models;Software;Data mining","","7","","26","","21 Jun 2022","","","IEEE","IEEE Conferences"
"ReCover: a Curated Dataset for Regression Testing Research","F. Altiero; A. Corazza; S. Di Martino; A. Peron; L. L. L. Starace","Università degli Studi di Napoli Federico II, Naples, Italy; Università degli Studi di Napoli Federico II, Naples, Italy; Università degli Studi di Napoli Federico II, Naples, Italy; Università degli Studi di Napoli Federico II, Naples, Italy; Università degli Studi di Napoli Federico II, Naples, Italy",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","196","200","It is recognized in the literature that finding representative data to conduct regression testing research is non-trivial. In our experience within this field, existing datasets are often affected by issues that limit their applicability. Indeed, these datasets often lack fine-grained coverage information, reference software repositories that are not available anymore, or do not allow researchers to readily build and run the software projects, e.g., to obtain additional information. As a step towards better replicability and data-availability in regression testing research, we introduce ReCover, a dataset of 114 pairs of subsequent versions from 28 open source Java projects from GitHub. In particular, ReCover is intended as a consolidation and enrichment of recent dedicated regression testing datasets proposed in the literature, to overcome some of the above described issues, and to make them ready to use with a broader number of regression testing techniques. To this end, we developed a custom mining tool, that we make available as well, to automatically process two recent, massive regression testing datasets, retaining pairs of software versions for which we were able to (1) retrieve the full source code; (2) build the software in a general-purpose Java/Maven environment (which we provide as a Docker container for ease of replication); and (3) compute fine-grained test coverage metrics. ReCover can be readily employed in regression testing studies, as it bundles in a single package full, buildable source code and detailed coverage reports for all the projects. We envision that its use could foster regression testing research, improving replicability and long-term data availability.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796327","Regression Testing;Mined Dataset;Mining Software Repositories","Codes;XML;Containers;Software;Data mining;Proposals;Replicability","","2","","25","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Mining the Ethereum Blockchain Platform: Best Practices and Pitfalls (MSR 2022 Tutorial)","G. A. Oliva","SAIL Lab, Queen's University, Kingston, Ontario, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","201","202","Ethereum is the most popular blockchain platform that supports smart contracts. Smart contracts are computing programs that constitute the building blocks of decentralized applications (DApps). DApps are revolutionary and have led to the creation of entirely new businesses (e.g., marketplaces for digital collectibles). Nonetheless, developing and maintaining DApps lead to entirely new research challenges. Empirical research demands high-quality data, which can be obtained by carefully mining Ethereum. In this tutorial, I will discuss best practices and pitfalls associated with mining Ethereum. The tutorial will be organized into three main parts: (i) a brief introduction to Ethereum and its fundamental concepts, (ii) a hands-on mining session, and (iii) a final Q&A session.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796161","Ethereum;Decentralized Applications;DApps;mining software repositories;MSR;best practices;pitfalls","Smart contracts;Tutorials;Decentralized applications;Software;Blockchains;Data mining;Best practices","","","","8","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Mining the Usage of Reactive Programming APIs: A Study on GitHub and Stack Overflow","C. Zimmerle; K. Gama; F. Castor; J. M. M. Filho","Centro de Informática, Federal University of Pernambuco, Recife, Brazil; Centro de Informática, Federal University of Pernambuco, Recife, Brazil; Centro de Informática, Federal University of Pernambuco, Recife, Brazil; Centro de Informática, Federal University of Pernambuco, Recife, Brazil",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","203","214","Conventionally, callbacks and inversion of control have been the main tools to structure event-driven applications. Sadly, those patterns constitute a well-known source of design problems. The Reactive Programming (RP) paradigm has arisen as an approach to mitigate these problems. Yet, little evidence has been provided regarding the advantages of RP, and concerns have also arisen about the API usability of RP libraries given their disparate number of operators. In this work, we conduct a study on GitHub (GH) and Stack Overflow (SO) and explore three Reactive Extensions (Rx) libraries (RxJava, RxJS, and RxSwift) with the most GH projects to understand how much the vast Rx operators are being used. Also, we examine Rx SO posts to complement the results from the GH exploration by understanding the problems faced by RP developers and how they relate with the operators' frequencies found in open source projects. Results reveal that, in spite of its API size, the great majority of the Rx operators are actually being used (95.2%), with only a few, mostly related to RxJava, not being utilized. Also, we unveil 23 topics from SO with more posts concerning the Stream Abstraction (36.4%). Posts related to Dependency Management, Introductory Questions, and iOS Development figure as relevant topics to the community. The findings herein present can not only stimulate advancements in the field by understanding the usage of RP API and the main problems faced by developers, but also help newcomers in identifying the most important operators and the areas that are the most likely to be relevant for a RP application.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527966","INES; CNPq(grant numbers:465614/2014-0); FACEPE(grant numbers:APQ-0399-1.03/17,APQ/0388-1.03/14); CAPES(grant numbers:88887.136410/2017-00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796297","Reactive Programming;API Usability;Mining Software Repositories","Debugging;Programming;Libraries;Software;Data mining;Usability;Software development management","","1","","36","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Painting the Landscape of Automotive Software in GitHub","S. Kochanthara; Y. Dajsuren; L. Cleophas; M. van den Brand","Eindhoven University of Technology, The Netherlands; Eindhoven University of Technology, The Netherlands; Eindhoven University of Technology, The Netherlands; Eindhoven University of Technology, The Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","215","226","The automotive industry has transitioned from being an electro-mechanical to a software-intensive industry. A current high-end production vehicle contains 100 million+ lines of code surpassing modern airplanes, the Large Hadron Collider, the Android OS, and Facebook's front-end software, in code size by a huge margin. Today, software companies worldwide, including Apple, Google, Huawei, Baidu, and Sony are reportedly working to bring their vehicles to the road. This paper ventures into the automotive software landscape in open source, providing a first glimpse into this multi-disciplinary industry with a long history of closed source development. We paint the landscape of automotive software on GitHub by describing its characteristics and development styles. The landscape is defined by 15,000+ users contributing to ≈600 actively-developed automotive software projects created in a span of 12 years from 2010 until 2021. These projects range from vehicle dynamics-related software; firmware and drivers for sensors like LiDAR and camera; algorithms for perception and motion control; to complete operating systems integrating the above. Developments in the field are spearheaded by industry and academia alike, with one in three actively developed automotive software repositories owned by an organization. We observe shifts along multiple dimensions, including preferred language from MATLAB to Python and prevalence of perception and decision-related software over traditional automotive software. This study witnesses open source automotive software boom in its infancy with many implications for future research and practice.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796157","Automotive Software;Mining Software Repositories;Cyber-Physical Systems;Safety Critical;Software Engineering;Open Source;GitHub","Industries;Codes;Web and internet services;Companies;Software;History;Automotive engineering","","4","","46","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"DISCO: A Dataset of Discord Chat Conversations for Software Engineering Research","K. M. Subash; L. P. Kumar; S. L. Vadlamani; P. Chatterjee; O. Baysal","School of Computer Science, Carleton University, Ottawa, Canada; School of Computer Science, Carleton University, Ottawa, Canada; School of Computer Science, Carleton University, Ottawa, Canada; Department of Computer Science, Drexel University, Philadelphia, PA, United States; School of Computer Science, Carleton University, Ottawa, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","227","231","Today, software developers work on complex and fast-moving projects that often require instant assistance from other domain and subject matter experts. Chat servers such as Discord facilitate live communication and collaboration among developers all over the world. With numerous topics discussed in parallel, mining and analyzing the chat data of these platforms would offer researchers and tool makers opportunities to develop software tools and services such as automated virtual assistants, chat bots, chat summarization techniques, Q&A thesaurus, and more. In this paper, we propose a dataset called DISCO consisting of the one-year public DIScord chat COnversations of four software development communities. We have collected the chat data of the channels containing general programming Q&A discussions from the four Discord servers, applied a disentanglement technique [13] to extract conversations from the chat transcripts, and performed a manual validation of conversations on a random sample (500 conversations). Our dataset consists of 28, 712 conversations, 1,508,093 messages posted by 323, 562 users. As a case study on the dataset, we applied a topic modelling technique for extracting the top five general topics that are most discussed in each Discord channel.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528018","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2021-03809); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796319","Chat conversations;software developers;conversation disentanglement;online communities;Discord","Virtual assistants;Collaboration;Oral communication;Manuals;Programming;Thesauri;Data mining","","6","","42","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Inspect4py: A Knowledge Extraction Framework for Python Code Repositories","R. Filgueira; D. Garijo","University of St Andrews, St Andrews, UK; Universidad Politécnica de Madrid, Madrid, Spain",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","232","236","This work presents inspect4py, a static code analysis framework designed to automatically extract the main features, metadata and documentation of Python code repositories. Given an input folder with code, inspect4py uses abstract syntax trees and state of the art tools to find all functions, classes, tests, documentation, call graphs, module dependencies and control flows within all code files in that repository. Using these findings, inspect4py infers different ways of invoking a software component. We have evaluated our framework on 95 annotated repositories, obtaining promising results for software type classification (over 95% F1-score). With inspect4py, we aim to ease the understandability and adoption of software repositories by other researchers and developers. Code: https://github.com/SoftwareUnderstanding/inspect4py DOI:https://doi.org/10.5281/zenodo.5907936 License: Open (BSD3-Clause)","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796219","Code mining;software code;software classification;software documentation;code understanding","Codes;Documentation;Syntactics;Metadata;Feature extraction","","4","","17","","21 Jun 2022","","","IEEE","IEEE Conferences"
"SLNET: A Redistributable Corpus of 3rd-party Simulink Models","S. L. Shrestha; S. A. Chowdhury; C. Csallner","Computer Science & Eng. Dep, University of Texas at Arlington, Arlington, Texas, USA; Computer Science & Eng. Dep, University of Texas at Arlington, Arlington, Texas, USA; Computer Science & Eng. Dep, University of Texas at Arlington, Arlington, Texas, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","01","05","MATLAB/Simulink is widely used for model-based design. Engineers create Simulink models and compile them to embedded code, often to control safety-critical cyber-physical systems in automotive, aerospace, and healthcare applications. Despite Simulink's importance, there are few large-scale empirical Simulink studies, perhaps because there is no large readily available corpus of third-party open-source Simulink models. To enable empirical Simulink studies, this paper introduces SLNET, the largest corpus of freely available third-party Simulink models. SLNET has several advantages over earlier collections. Specifically, SLNET is 8 times larger than the largest previous corpus of Simulink models, includes fine-grained metadata, is constructed automatically, is self-contained, and allows redistribution. SLNET is available under permissive open-source licenses and contains its collection and analysis tools.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528001","National Science Foundation (NSF)(grant numbers:1911017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796193","Simulink;mining software repositories;open-source","Software packages;Medical services;Metadata;Cyber-physical systems;Control systems;Mathematical models","","5","","46","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"SoCCMiner: A Source Code-Comments and Comment-Context Miner","M. Sridharan; M. Mäntylä; M. Claes; L. Rantala","M3S, University of Oulu, Oulu, Finland; M3S, University of Oulu, Oulu, Finland; M3S, University of Oulu, Oulu, Finland; M3S, University of Oulu, Oulu, Finland",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","242","246","Numerous tools exist for mining source code and software development process metrics. However, very few publicly available tools focus on source code comments, a crucial software artifact. This paper presents SoCCMiner (Source Code-Comments and Comment-Context Miner), a tool that offers multiple mining pipelines. It is the first readily available (plug-and-play) and customizable open-source tool for mining source code contextual information of comments at different granularities (Class comments, Method comments, Interface comments, and other granular comments). Mining comments at different source code granularities can aid researchers and practitioners working in a host of applications that focus on source code comments, such as Self-Admitted Technical Debt, Program Comprehension, and other applications. Furthermore, SoCCMiner is highly adaptable and extendable to include additional attributes and support other programming languages. This prototype supports the Java programming language.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527998","Academy of Finland(grant numbers:328058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796266","Mining Software Repositories;Source Code Comments;Comment Context;Python","Measurement;Java;Codes;Limiting;Pipelines;Prototypes;Data mining","","3","","25","","21 Jun 2022","","","IEEE","IEEE Conferences"
"SOSum: A Dataset of Stack Overflow Post Summaries","B. Kou; Y. Di; M. Chen; T. Zhang","Purdue University, West Lafayette, Indiana, USA; Purdue University, West Lafayette, Indiana, USA; University of Southern California, Los Angeles, California, USA; Purdue University, West Lafayette, Indiana, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","247","251","Stack Overflow (SO) is becoming an indispensable part of modern software development workflow. However, given the limited time, attention, and memory capacity of programmers, navigating SO posts and comparing different solutions is time-consuming and cumbersome. Recent research has proposed to summarize SO posts to concise text to help programmers quickly assess the relevance and quality of SO posts. Yet there is no large dataset of high-quality SO post summaries, hindering the development and evaluation of post summarization techniques. We present SOSum, a dataset of 2,278 popular SO answer posts with manually labeled summative sentences. Questions in SOSum cover 669 tags with a median view count of 253K and a median post score of 17. This dataset will foster research on sentence-level summarization of SO posts and has the potential to facilitate text summarization research on other types of textual software artifacts such as programming tutorials.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796176","Stack Overflow;text summarization;data labeling","Systematics;Navigation;Tutorials;Programming;Software;Data models;Labeling","","7","","55","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"An Empirical Study on Maintainable Method Size in Java","S. A. Chowdhury; G. Uddin; R. Holmes","University of British Columbia, Vancouver, BC, Canada; University of Calgary, Calgary, AB, Canada; University of British Columbia, Vancouver, BC, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","252","264","Code metrics have been widely used to estimate software maintenance effort. Metrics have generally been used to guide developer effort to reduce or avoid future maintenance burdens. Size is the simplest and most widely deployed metric. The size metric is pervasive because size correlates with many other common metrics (e.g., McCabe complexity, readability, etc.). Given the ease of computing a method's size, and the ubiquity of these metrics in industrial settings, it is surprising that no systematic study has been performed to provide developers with meaningful method size guidelines with respect to future maintenance effort. In this paper we examine the evolution of ∼785K Java methods and show that developers should strive to keep their Java methods under 24 lines in length. Additionally, we show that decomposing larger methods to smaller methods also decreases overall maintenance efforts. Taken together, these findings provide empirical guidelines to help developers design their systems in a way that can reduce future maintenance.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527975","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:PDF-533056-2019,RGPIN-2021-02575); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796336","SLOC;code metrics;maintenance;McCabe;Readability","Measurement;Java;Software maintenance;Codes;Systematics;Buildings;Maintenance engineering","","3","","94","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Characterizing High-Quality Test Methods: A First Empirical Study","V. Veloso; A. Hora","Department of Computer Science, Universidade Federal de Minas Gerais (UFMG), Belo Horizonte, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais (UFMG), Belo Horizonte, Brazil",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","265","269","To assess the quality of a test suite, one can rely on mutation testing, which computes whether the overall test cases are adequately exercising the covered lines. However, this high level of granularity may overshadow the quality of individual test methods. In this paper, we propose an empirical study to assess the quality of test methods by relying on mutation testing at the method level. We find no major differences between high-quality and low-quality test methods in terms of size, number of asserts, and modifications. In contrast, high-quality test methods are less affected by critical test smells. Finally, we discuss practical implications for researchers and practitioners.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3529092","CAPES; CNPq; FAPEMIG; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796158","Mutation testing;Code quality;Software repository mining","Measurement;Runtime;Software;Data mining;Testing","","1","","35","","21 Jun 2022","","","IEEE","IEEE Conferences"
"CLIP meets GamePhysics: Towards bug identification in gameplay videos using zero-shot transfer learning","M. R. Taesiri; F. Macklon; C. -P. Bezemer","University of Alberta, Edmonton, AB, Canada; University of Alberta, Edmonton, AB, Canada; University of Alberta, Edmonton, AB, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","270","281","Gameplay videos contain rich information about how players interact with the game and how the game responds. Sharing gameplay videos on social media platforms, such as Reddit, has become a common practice for many players. Often, players will share game-play videos that showcase video game bugs. Such gameplay videos are software artifacts that can be utilized for game testing, as they provide insight for bug analysis. Although large repositories of gameplay videos exist, parsing and mining them in an effective and structured fashion has still remained a big challenge. In this paper, we propose a search method that accepts any English text query as input to retrieve relevant videos from large repositories of gameplay videos. Our approach does not rely on any external information (such as video metadata); it works solely based on the content of the video. By leveraging the zero-shot transfer capabilities of the Contrastive Language-Image Pre-Training (CLIP) model, our approach does not require any data labeling or training. To evaluate our approach, we present the GamePhysics dataset consisting of 26,954 videos from 1,873 games, that were collected from the GamePhysics section on the Reddit website. Our approach shows promising results in our extensive analysis of simple queries, compound queries, and bug queries, indicating that our approach is useful for object and event detection in gameplay videos. An example application of our approach is as a gameplay video search engine to aid in reproducing video game bugs. Please visit the following link for the code and the data: https://asgaardlab.github.io/CLIPxGamePhysics/","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796271","video mining;bug reports;software testing;video games","Training;Visualization;Social networking (online);Computer bugs;Transfer learning;Games;Software","","5","","58","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Complex Python Features in the Wild","Y. Yang; A. Milanova; M. Hirzel","Rensselaer Polytechnic Institute, USA; Rensselaer Polytechnic Institute, USA; IBM Research, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","282","293","While Python is increasingly popular, program analysis tooling for Python is lagging. This is due, in part, to complex features of the Python language-features with difficult to understand and model semantics. Besides the “usual suspects”, reflection and dynamic execution, complex Python features include context managers, decorators, and generators, among others. This paper explores how often and in what ways developers use certain complex features. We analyze over 3 million Python files mined from GitHub to address three research questions: (i) How often do developers use certain complex Python features? (ii) In what ways do developers use these features? (iii) Does use of complex features increase or decrease over time? Our findings show that usage of dynamic features that pose a threat to static analysis is infrequent. On the other hand, usage of context managers and decorators is surprisingly widespread. Our actionable result is a list of Python features that any “minimal syntax” ought to handle in order to capture developers' use of the Python language. We hope that understanding the usage of Python features will help tool-builders improve Python tools, which can in turn lead to more correct, secure, and performant Python code.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796194","Python;AST","Codes;Semantics;Static analysis;Syntactics;Software;Reflection;Generators","","4","","28","","21 Jun 2022","","","IEEE","IEEE Conferences"
"ManyTypes4TypeScript: A Comprehensive TypeScript Dataset for Sequence-Based Type Inference","K. Jesse; P. T. Devanbu","University of California, Davis, Davis, CA, USA; University of California, Davis, Davis, CA, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","294","298","In this paper, we present ManyTypes4TypeScript, a very large corpus for training and evaluating machine-learning models for sequence-based type inference in TypeScript. The dataset includes over 9 million type annotations, across 13,953 projects and 539,571 files. The dataset is approximately 10x larger than analogous type inference datasets for Python, and is the largest available for Type-Script. We also provide API access to the dataset, which can be integrated into any tokenizer and used with any state-of-the-art sequence-based model. Finally, we provide analysis and performance results for state-of-the-art code-specific models, for baselining. ManyTypes4TypeScript is available on Huggingface, Zenodo, and CodeXGLUE.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528507","NSF(grant numbers:1414172); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796285","Type Inference;Machine Learning;TypeScript;Code Properties","Training;Measurement;Analytical models;Annotations;Machine learning;Software;Data mining","","2","","34","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"METHODS2TEST: A dataset of focal methods mapped to test cases","M. Tufano; S. K. Deng; N. Sundaresan; A. Svyatkovskiy","Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","299","303","Unit testing is an essential part of the software development process, which helps to identify issues with source code in early stages of development and prevent regressions. Machine learning has emerged as viable approach to help software developers generate automated unit tests. However, generating reliable unit test cases that are semantically correct and capable of catching software bugs or unintended behavior via machine learning requires large, metadata-rich, datasets. In this paper we present Methods2Test: a large, supervised dataset of test cases mapped to corresponding methods under test (i.e., focal methods). This dataset contains 780,944 pairs of JUnit tests and focal methods, extracted from a total of 91,385 Java open source projects hosted on GitHub with licenses permitting re-distribution. The main challenge behind the creation of the Methods2Test was to establish a reliable mapping between a test case and the relevant focal method. To this aim, we designed a set of heuristics, based on developers' best practices in software testing, which identify the likely focal method for a given test case. To facilitate further analysis, we store a rich set of metadata for each method-test pair in JSON-formatted files. Additionally, we extract textual corpus from the dataset at different context levels, which we provide both in raw and tokenized forms, in order to enable researchers to train and evaluate machine learning models for Automated Test Generation. Methods2Test is publicly available at: https://github.com/microsoft/methods2test","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796371","datasets;software testing","Software testing;Java;Machine learning;Metadata;Software reliability","","17","","28","","21 Jun 2022","","","IEEE","IEEE Conferences"
"npm-filter: Automating the mining of dynamic information from npm packages","E. Arteca; A. Turcotte",NA; NA,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","304","308","The static properties of code repositories, e.g., lines of code, dependents, dependencies, etc. can be readily scraped from code hosting platforms such as GitHub, and from package management systems such as npm for JavaScript; Although no less important, information related to the dynamic properties of programs, e.g., number of tests in a test suite that pass or fail, is less readily available. The ability to easily collect this dynamic information could be immensely useful to researchers conducting corpus analyses, as they could differentiate projects based on properties that can only be observed by running them. In this paper, we present npm-filter, an automated tool that can download, install, build, test, and run custom user scripts over the source code of JavaScript projects available on npm, the most popular JavaScript package manager. We outline this tool, describe its implementation, and show that npm-filter has already been useful in developing evaluation suites for multiple JavaScript tools.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528501","National Science Foundation(grant numbers:CCF-1715153,CCF-1907727); Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796254","JavaScript;npm;corpus analysis;tool evaluation","Codes;Metadata;Software;Performance analysis;Data mining;Software development management;Testing","","2","","30","","21 Jun 2022","","","IEEE","IEEE Conferences"
"How heated is it? Understanding GitHub locked issues","I. Ferreira; B. Adams; J. Cheng","Polytechnique Montréal, Montréal, Canada; Queen's University, Kingston, Canada; Polytechnique Montréal, Montréal, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","309","320","Although issues of open source software are created to discuss and solve technical problems, conversations can become heated, with discussants getting angry and/or agitated for a variety of reasons, such as poor suggestions or violation of community conventions. To prevent and mitigate discussions from getting heated, tools like GitHub have introduced the ability to lock issue discussions that violate the code of conduct or other community guidelines. Despite some early research on locked issues, there is a lack of understanding of how communities use this feature and of potential threats to validity for researchers relying on a dataset of locked issues as an oracle for heated discussions. To address this gap, we (i) quantitatively analyzed 79 GitHub projects that have at least one issue locked as too heated, and (ii) qualitatively analyzed all issues locked as too heated of the 79 projects, a total of 205 issues comprising 5,511 comments. We found that projects have different behaviors when locking issues: while 54 locked less than 10% of their closed issues, 14 projects locked more than 90% of their closed issues. Additionally, locked issues tend to have a similar number of comments, participants, and emoji reactions to non-locked issues. For the 205 issues locked as too heated, we found that one-third do not contain any uncivil discourse, and only 8.82% of the analyzed comments are actually uncivil. Finally, we found that the locking justifications provided by maintainers do not always match the label used to lock the issue. Based on our results, we identified three pitfalls to avoid when using the GitHub locked issues data and we provide recommendations for researchers and practitioners.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527957","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796356","github locked issues;heated discussions;incivility;civility","Heating systems;Codes;Heat engines;Oral communication;Behavioral sciences;Data mining;Open source software","","5","","33","","21 Jun 2022","","","IEEE","IEEE Conferences"
"On the Violation of Honesty in Mobile Apps: Automated Detection and Categories","H. O. Obie; I. Ilekura; H. Du; M. Shahin; J. Grundy; L. Li; J. Whittle; B. Turhan","HumaniSE Lab, Monash University, Melbourne, Australia; Data Science Nigeria, Lagos, Nigeria; Applied Artificial Intelligence Inst., Deakin University, Melbourne, Australia; School of Computing Technologies, RMIT University, Melbourne, Australia; HumaniSE Lab, Monash University, Melbourne, Australia; Faculty of IT, Monash University, Melbourne, Australia; CSIRO's Data61, Melbourne, Australia; University of Oulu, Oulu, Finland",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","321","332","Human values such as integrity, privacy, curiosity, security, and honesty are guiding principles for what people consider important in life. Such human values may be violated by mobile software applications (apps), and the negative effects of such human value violations can be seen in various ways in society. In this work, we focus on the human value of honesty. We present a model to support the automatic identification of violations of the value of honesty from app reviews from an end-user perspective. Beyond the automatic detection of honesty violations by apps, we also aim to better understand different categories of honesty violations expressed by users in their app reviews. The result of our manual analysis of our honesty violations dataset shows that honesty violations can be characterised into ten categories: unfair cancellation and refund policies; false advertisements; delusive subscriptions; cheating systems; inaccurate information; unfair fees; no service; deletion of reviews; impersonation; and fraudulent-looking apps. Based on these results, we argue for a conscious effort in developing more honest software artefacts including mobile apps, and the promotion of honesty as a key value in software development practices. Furthermore, we discuss the role of app distribution platforms as enforcers of ethical systems supporting human values, and highlight some proposed next steps for human values in software engineering (SE) research.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796360","human values;mobile apps;app reviews;Android;Automatic detection;taxonomy;honesty","Support vector machines;Privacy;Ethics;Manuals;Software;Mobile applications;Classification algorithms","","5","","74","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Exploring Apache Incubator Project Trajectories with APEX","A. Ramchandran; L. Yin; V. Filkov","University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","333","337","Open Source Software (OSS) is a major component of our digital infrastructure, yet more than 80% of such projects fail. Seeking less uncertainty, many OSS projects join established software communities, e.g., the Apache Software Foundation (ASF), with established rules and community support to guide projects toward sustainability. In their nascent stage, ASF projects are incubated in the ASF incubator (ASFI), which provides systematic mentorship toward long-term sustainability. Projects in ASFI eventually conclude their incubation by either graduating, if successful, or retiring, if not. Time-stamped traces of developer activities are publicly available from ASF, and can be used for monitoring project trajectories toward sustainability. Here we present a web app dashboard tool, APEX, that allows internal and external stakeholders to monitor and explore ASFI project sustainability trajectories, including social and technical networks.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528506","National Science Foundation(grant numbers:2020751); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796292","OSS Sustainability;Apache Incubator;Tool","Uncertainty;Systematics;Maintenance engineering;Real-time systems;Trajectory;Stakeholders;Data mining","","","","4","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"The OCEAN mailing list data set: Network analysis spanning mailing lists and code repositories","M. Warrick; S. F. Rosenblatt; J. -G. Young; A. Casari; L. Hébert-Dufresne; J. Bagrow","Google, Inc., California, USA; University of Vermont, Burlington, Vermont, USA; University of Vermont, Burlington, Vermont, USA; Google, Inc., California, USA; University of Vermont, Burlington, Vermont, USA; University of Vermont, Burlington, Vermont, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","338","342","Communication surrounding the development of an open source project largely occurs outside the software repository itself. Historically, large communities often used a collection of mailing lists to discuss the different aspects of their projects. Multimodal tool use, with software development and communication happening on different channels, complicates the study of open source projects as a sociotechnical system. Here, we combine and standardize mailing lists of the Python community, resulting in 954,287 messages from 1995 to the present. We share all scraping and cleaning code to facilitate reproduction of this work, as well as smaller datasets for the Golang (122,721 messages), Angular (20,041 messages) and Node.js (12,514 messages) communities. To showcase the usefulness of these data, we focus on the CPython repository and merge the technical layer (which GitHub account works on what file and with whom) with the social layer (messages from unique email addresses) by identifying 33% of GitHub contributors in the mailing list data. We then explore correlations between the valence of social messaging and the structure of the collaboration network. We discuss how these data provide a laboratory to test theories from standard organizational science in large open source projects.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528479","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR00112190092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796358","datasets;sociotechnical systems;network analysis;text tagging","Sociotechnical systems;Codes;Oceans;Network analyzers;Tagging;Software;Electronic mail","","1","","35","","21 Jun 2022","","","IEEE","IEEE Conferences"
"The Unexplored Treasure Trove of Phabricator Code Reviews","G. Kudrjavets; N. Nagappan; A. Rastogi","University of Groningen, Groningen, Netherlands; Microsoft Research, Redmond, WA, USA; University of Groningen, Groningen, Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","343","347","Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there is no readily accessible public code review dataset for Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the data retrieval process and our solutions, resulting in a dataset with details regarding 317,476 Phabricator code reviews. Our dataset11https://doi.org/10.6084/m9.figshare.17139245 is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a more granular level than other platforms. In addition, given that the projects we mined are publicly accessible via the Conduit API [18], our dataset can be used as a foundation to fetch additional details and insights.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796228","Code review;dataset;mining;Phabricator","Codes;Databases;Collaboration;Software;Data mining;History;Software development management","","","","26","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"The Unsolvable Problem or the Unheard Answer? A Dataset of 24,669 Open-Source Software Conference Talks","K. Truong; C. Miller; B. Vasilescu; C. Kästner","Oregon State University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","348","352","Talks at practitioner-focused open-source software conferences are a valuable source of information for software engineering researchers. They provide a pulse of the community and are valuable source material for grey literature analysis. We curated a dataset of 24,669 talks from 87 open-source conferences between 2010 and 2021. We stored all relevant metadata from these conferences and provide scripts to collect the transcripts. We believe this data is useful for answering many kinds of questions, such as: What are the important/highly discussed topics within practitioner communities? How do practitioners interact? And how do they present themselves to the public? We demonstrate the usefulness of this data by reporting our findings from two small studies: a topic model analysis providing an overview of open-source community dynamics since 2011 and a qualitative analysis of a smaller community-oriented sample within our dataset to gain a better understanding of why contributors leave open-source software.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796182","open source;conference talks;dataset;practitioner focused","Bridges;Analytical models;Video on demand;Metadata;Data mining;Sustainable development;Open source software","","","","22","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"A Large-Scale Comparison of Python Code in Jupyter Notebooks and Scripts","K. Grotov; S. Titov; V. Sotnikov; Y. Golubev; T. Bryksin","JetBrains Research, ITMO University; JetBrains Research; JetBrains Research; JetBrains Research; JetBrains Research",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","353","364","In recent years, Jupyter notebooks have grown in popularity in several domains of software engineering, such as data science, machine learning, and computer science education. Their popularity has to do with their rich features for presenting and visualizing data, however, recent studies show that notebooks also share a lot of drawbacks: high number of code clones, low reproducibility, etc. In this work, we carry out a comparison between Python code written in Jupyter Notebooks and in traditional Python scripts. We compare the code from two perspectives: structural and stylistic. In the first part of the analysis, we report the difference in the number of lines, the usage of functions, as well as various complexity metrics. In the second part, we show the difference in the number of stylistic issues and provide an extensive overview of the 15 most frequent stylistic issues in the studied mediums. Overall, we demonstrate that notebooks are characterized by the lower code complexity, however, their code could be perceived as more entangled than in the scripts. As for the style, notebooks tend to have 1.4 times more stylistic issues, but at the same time, some of them are caused by specific coding practices in notebooks and should be considered as false positives. With this research, we want to pave the way to studying specific problems of notebooks that should be addressed by the development of notebook-specific tools, and provide various insights that can be useful in this regard.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796343","jupyter;jupyter notebooks;python;mining software repositories;static analysis;code style","Codes;Data visualization;Machine learning;Data science;Software;Reproducibility of results;Encoding","","17","","43","","21 Jun 2022","","","IEEE","IEEE Conferences"
"An Empirical Study on the Survival Rate of GitHub Projects","A. Ait; J. L. C. Izquierdo; J. Cabot","IN3 - UOC, Barcelona, Spain; IN3 - UOC, Barcelona, Spain; IN3 - UOC, ICREA, Barcelona, Spain",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","365","375","The number of Open Source projects hosted in social coding platforms such as GitHub is constantly growing. However, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. In this paper we analyze early project development dynamics in software projects hosted on GitHub, including their survival rate. To this aim, we collected all 1,127 GitHub repositories from four different ecosystems (i.e., NPM packages, R packages, WordPress plugins and Laravel packages) created in 2016. We stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. Our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. More importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. In fact, the probability of surviving longer than five years is less than 50% though some types of projects have better chances of survival.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796216","Open Source Analysis;Survival Analysis;Mining Software Repositories;Empirical Study","Ecosystems;Time series analysis;Organizations;Maintenance engineering;Software;Encoding;Security","","4","","27","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Do Customized Android Frameworks Keep Pace with Android?","P. Liu; M. Fazzini; J. Grundy; L. Li","Monash University, Melbourne, Victoria, Australia; University of Minnesota, Minneapolis, Minnesota, United States; Monash University, Melbourne, Victoria, Australia; Monash University, Melbourne, Victoria, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","376","387","To satisfy varying customer needs, device vendors and OS providers often rely on the open-source nature of the Android OS and offer customized versions of the Android OS. When a new version of the Android OS is released, device vendors and OS providers need to merge the changes from the Android OS into their customizations to account for its bug fixes, security patches, and new features. Because developers of customized OSs might have made changes to code locations that were also modified by the developers of the Android OS, the merge task can be characterized by conflicts, which can be time-consuming and error-prone to resolve. To provide more insight into this critical aspect of the Android ecosystem, we present an empirical study that investigates how eight open-source customizations of the Android OS merge the changes from the Android OS into their projects. The study analyzes how often the developers from the customized OSs merge changes from the Android OS, how often the developers experience textual merge conflicts, and the characteristics of these conflicts. Furthermore, to analyze the effect of the conflicts, the study also analyzes how the conflicts can affect a randomly selected sample of 1,000 apps. After analyzing 1,148 merge operations, we identified that developers perform these operations for 9.7% of the released versions of the Android OS, developers will encounter at least one conflict in 41.3% of the merge operations, 58.1% of the conflicts required developers to change the customized OSs, and 64.4% of the apps considered use at least one method affected by a conflict. In addition to detailing our results, the paper also discusses the implications of our findings and provides insights for researchers and practitioners working with Android and its customizations.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796218","Android Customization","Codes;Ecosystems;Computer bugs;Security;Data mining;Task analysis;Open source software","","3","","48","","21 Jun 2022","","","IEEE","IEEE Conferences"
"DaSEA - A Dataset for Software Ecosystem Analysis","P. Buchkova; J. H. Hinnerskov; K. Olsen; R. -H. Pfeiffer","IT University of Copenhagen, Copenhagen, Denmark; IT University of Copenhagen, Copenhagen, Denmark; IT University of Copenhagen, Copenhagen, Denmark; IT University of Copenhagen, Copenhagen, Denmark",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","388","392","Software package managers facilitate reuse and rapid construction of software systems. Since evermore software is distributed via package managers, researchers and practitioners require explicit data of software dependency networks that are opaquely formed by dependency relations between software packages. To reason about increasingly complex software products and ecosystems, researchers and practitioners rely either on publicly available datasets like the seemingly unattended libraries.io [14] or they mine problem-specific data from software ecosystems repeatedly and non-transparently. Therefore, we present the DaSEA dataset, which contains metadata of software packages, their versions, and dependencies from multiple ecosystems (currently six programming languages and five operating system package managers). Alongside the dataset, we provide an extensible open-source tool under the same name that is used to create updated versions of the DaSEA dataset allowing studies of evolution of software ecosystems.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796284","Software Engineering;Dataset;Package Managers;Dependency Networks","Computer languages;Software packages;Operating systems;Ecosystems;Distributed databases;Metadata;Software systems","","1","","27","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Dataset: Dependency Networks of Open Source Libraries Available Through CocoaPods, Carthage and Swift PM","K. Rahkema; D. Pfahl","University of Tartu, Tartu, Estonia; University of Tartu, Tartu, Estonia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","393","397","Third party libraries are used to integrate existing solutions for common problems and help speed up development. The use of third party libraries, however, can carry risks, for example through vulnerabilities in these libraries. Studying the dependency networks of package managers lets us better understand and mitigate these risks. So far, the dependency networks of the three most important package managers of the Apple ecosystem, CocoaPods, Carthage and Swift PM, have not been studied. We analysed the dependencies for all publicly available open source libraries up to December 2021 and compiled a dataset containing the dependency networks of all three package managers. The dependency networks can be used to analyse how vulnerabilities are propagated through transitive dependencies. In order to ease the tracing of vulnerable libraries we also queried the NVD database and included publicly reported vulnerabilities for these libraries in the dataset.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796276","datasets;iOS;dependency network;package manager;mobile apps","Databases;Ecosystems;Libraries;Software;Data mining","","4","","12","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Lupa: A Framework for Large Scale Analysis of the Programming Language Usage","A. Vlasova; M. Tigina; I. Vlasov; A. Birillo; Y. Golubev; T. Bryksin",JetBrains Research; JetBrains Research ITMO University; Saint Petersburg State University; JetBrains Research; JetBrains Research; JetBrains Research,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","398","402","In this paper, we present Lupa - a platform for large-scale analysis of the programming language usage. Lupa is a command line tool that uses the power of the IntelliJ Platform under the hood, which gives it access to powerful static analysis tools used in modern IDEs. The tool supports custom analyzers that process the rich concrete syntax tree of the code and can calculate its various features: the presence of entities, their dependencies, definition-usage chains, etc. Currently, Lupa supports analyzing Python and Kotlin, but can be extended to other languages supported by IntelliJ-based IDEs. We explain the internals of the tool, show how it can be extended and customized, and describe an example analysis that we carried out with its help: analyzing the syntax of ranges in Kotlin.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796207","language analysis;static analysis;kotlin;python;mining software repositories","Visualization;Codes;Semantics;Pipelines;Static analysis;Syntactics;Software","","2","","42","","21 Jun 2022","","","IEEE","IEEE Conferences"
"GitDelver Enterprise Dataset (GDED): An Industrial Closed-source Dataset for Socio-Technical Research","N. Riquet; X. Devroey; B. Vanderose","NADI, University of Namur, Namur, Belgium; NADI, University of Namur, Namur, Belgium; NADI, University of Namur, Namur, Belgium",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","403","407","Conducting socio-technical software engineering research on closed-source software is difficult as most organizations do not want to give access to their code repositories. Most experiments and publications therefore focus on open-source projects, which only provides a partial view of software development communities. Yet, closing the gap between open and closed source software industries is es-sential to increase the validity and applicability of results stemming from socio-technical software engineering research. We contribute to this effort by sharing our work in a large company counting 4,800 employees. We mined 101 repositories and produced the GDED dataset containing socio-technical information about 106,216 commits, 470,940 file modifications and 3,471,556 method modifications from 164 developers during the last 13 years, using various programming languages. For that, we used GitDelver, an open-source tool we developed on top of Pydriller, and anonymized and scrambled the data to comply with legal and corporate requirements. Our dataset can be used for various purposes and provides information about code complexity, self-admitted technical debt, bug fixes, as well as temporal information. We also share our experience regarding the processing of sensitive data to help other organizations making datasets publicly available to the research community.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796217","dataset showcase;socio-technical aspects;development teams","Industries;Computer languages;Codes;Law;Soft sensors;Companies;History","","1","","34","","21 Jun 2022","","","IEEE","IEEE Conferences"
"SniP: An Efficient Stack Tracing Framework for Multi-threaded Programs","A. KP; S. Kumar; D. Mishra; B. Panda","Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Bombay, India",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","408","412","Usage of the execution stack at run-time captures the dynamic state of programs and can be used to derive useful insights into the program behaviour. The stack usage information can be used to identify and debug performance and security aspects of applications. Binary run-time instrumentation techniques are well known to capture the memory access traces during program execution. Tracing the program in entirety and filtering out stack specific accesses is a commonly used technique for stack related analysis. However, applying vanilla tracing techniques (using tools like Intel Pin) for multi-threaded programs has challenges such as identifying the stack areas to perform efficient run-time tracing. In this paper, we introduce SniP, an open-source stack tracing framework for multi-threaded programs built around Intel's binary instrumentation tool Pin. SniP provides a framework for efficient run-time tracing of stack areas used by multi-threaded applications by identifying the stack areas dynamically. The targeted tracing capability of SniP is demonstrated using a range of multi-threaded applications to show its efficacy in terms of trace size and time to trace. Compared to full program tracing using Pin, SniP achieves up to 75x reduction in terms of trace file size and up to 24x reduction in time to trace. SniP complements existing trace based stack usage analysis tools and we demonstrate that SniP can be easily integrated with the analysis framework through different use-cases.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796268","Multi-threaded programs;Run-time instrumentation;Stack tracing","Filtering;Instruments;Linux;Debugging;Pins;Performance analysis;Security","","2","","25","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Tooling for Time- and Space-efficient git Repository Mining","F. Heseding; W. Scheibel; J. Döllner","Digital Engineering Faculty, Hasso Plattner Institute, University of Potsdam, Potsdam, Germany; Digital Engineering Faculty, Hasso Plattner Institute, University of Potsdam, Potsdam, Germany; Digital Engineering Faculty, Hasso Plattner Institute, University of Potsdam, Potsdam, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","413","417","Software projects under version control grow with each commit, accumulating up to hundreds of thousands of commits per repository. Especially for such large projects, the traversal of a repository and data extraction for static source code analysis poses a trade-off between granularity and speed. We showcase the command-line tool pyrepositoryminer that combines a set of optimization approaches for efficient traversal and data extraction from git repositories while being adaptable to third-party and custom software metrics and data extractions. The tool is written in Python and combines bare repository access, in-memory storage, parallelization, caching, change-based analysis, and optimized communication between the traversal and custom data extraction components. The tool allows for both metrics written in Python and external programs for data extraction. A single-thread performance evaluation based on a basic mining use case shows a mean speedup of 15.6x to other freely available tools across four mid-sized open source projects. A multi-threaded execution allows for load distribution among cores and, thus, a mean speedup up to 86.9x using 12 threads.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796175","Mining Software Repositories;Python;Git","Performance evaluation;Industries;Codes;Software metrics;Instruction sets;Software;Data mining","","","","15","","21 Jun 2022","","","IEEE","IEEE Conferences"
"TSSB-3M: Mining single statement bugs at massive scale","C. Richter; H. Wehrheim","University of Oldenburg, Oldenburg, Germany; University of Oldenburg, Oldenburg, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","418","422","Single statement bugs are one of the most important ingredients in the evaluation of modern bug detection and automatic program repair methods. By affecting only a single statement, single statement bugs represent a type of bug often overlooked by developers, while still being small enough to be detected and fixed by automatic methods. With the rise of data-driven automatic repair the availability of single statement bugs at the scale of millionth of examples is more important than ever; not only for testing these methods but also for providing sufficient real world examples for training. To provide access to bug fix datasets of this scale, we are releasing two datasets called SSB-9M and TSSB-3M. While SSB-9M provides access to a collection of over 9M general single statement bug fixes from over 500K open source Python projects , TSSB-3M focuses on over 3M single statement bugs which can be fixed solely by a single statement change. To facilitate future research and empirical investigations, we annotated each bug fix with one of 20 single statement bug (SStuB) patterns typical for Python together with a characterization of the code change as a sequence of AST modifications. Our initial investigation shows that at least 40% of all single statement bug fixes mined fit at least one SStuB pattern, and that the majority of 72% of all bugs can be fixed with the same syntactic modifications as needed for fixing SStuBs.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796214","Datasets;single statement bugs;Python;open software repositories","Training;Codes;Computer bugs;Maintenance engineering;Syntactics;Software;Data mining","","5","","23","","21 Jun 2022","","","IEEE","IEEE Conferences"
"LibDB: An Effective and Efficient Framework for Detecting Third-Party Libraries in Binaries","W. Tang; Y. Wang; H. Zhang; S. Han; P. Luo; D. Zhang","School of Software, Tsinghua University, Beijing, China; Microsoft Research, Beijing, China; The University of Newcastle, Newcastle, Australia; Microsoft Research, Beijing, China; School of Software, Tsinghua University, Beijing, China; Microsoft Research, Beijing, China",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","423","434","Third-party libraries (TPLs) are reused frequently in software applications for reducing development cost. However, they could introduce security risks as well. Many TPL detection methods have been proposed to detect TPL reuse in Android bytecode or in source code. This paper focuses on detecting TPL reuse in binary code, which is a more challenging task. For a detection target in binary form, libraries may be compiled and linked to separate dynamic-link files or built into a fused binary that contains multiple libraries and project-specific code. This could result in fewer available code features and lower the effectiveness of feature engineering. In this paper, we propose a binary TPL reuse detection framework, LibDB, which can effectively and efficiently detect imported TPLs even in stripped and fused binaries. In addition to the basic and coarse-grained features (string literals and exported function names), LibDB utilizes function contents as a new type of feature. It embeds all functions in a binary file to low-dimensional representations with a trained neural network. It further adopts a function call graph-based comparison method to improve the accuracy of the detection. LibDB is able to support version identification of TPLs contained in the detection target, which is not considered by existing detection methods. To evaluate the performance of LibDB, we construct three datasets for binary-based TPL reuse detection. Our experimental results show that LibDB is more accurate and efficient than state-of-the-art tools on the binary TPL detection task and the version identification task. Our datasets and source code used in this work are anonymously available at https://github.com/DeepSoftwareAnalytics/LibDB.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796347","Third-party libraries;Static binary analysis;Clone detection","Costs;Filtering;Neural networks;Binary codes;Libraries;Software;Security","","16","","39","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Noisy Label Learning for Security Defects","R. Croft; M. A. Babar; H. Chen","CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","435","447","Data-driven software engineering processes, such as vulnerability prediction heavily rely on the quality of the data used. In this paper, we observe that it is infeasible to obtain a noise-free security defect dataset in practice. Despite the vulnerable class, the non-vulnerable modules are difficult to be verified and determined as truly exploit free given the limited manual efforts available. It results in uncertainty, introduces labeling noise in the datasets and affects conclusion validity. To address this issue, we propose novel learning methods that are robust to label impurities and can leverage the most from limited label data; noisy label learning. We investigate various noisy label learning methods applied to soft-ware vulnerability prediction. Specifically, we propose a two-stage learning method based on noise cleaning to identify and remediate the noisy samples, which improves AUC and recall of baselines by up to 8.9% and 23.4%, respectively. Moreover, we discuss several hurdles in terms of achieving a performance upper bound with semi-omniscient knowledge of the label noise. Overall, the experimental results show that learning from noisy labels can be effective for data-driven software and security analytics.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796240","machine learning;noisy label learning;software vulnerabilities","Learning systems;Upper bound;Uncertainty;Manuals;Predictive models;Software;Noise measurement","","7","","76","","21 Jun 2022","","","IEEE","IEEE Conferences"
"WeakSATD: Detecting Weak Self-admitted Technical Debt","B. Russo; M. Camilli; M. Mock","Free University of Bozen-Bolzano, Italy; Free University of Bozen-Bolzano, Italy; Free University of Bozen-Bolzano, Italy",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","448","453","Speeding up development may produce technical debt, i.e., not-quite-right code for which the effort to make it right increases with time as a sort of interest. Developers may be aware of the debt as they admit it in their code comments. Literature reports that such a self-admitted technical debt survives for a long time in a program, but it is not yet clear its impact on the quality of the code in the long term. We argue that self-admitted technical debt contains a number of different weaknesses that may affect the security of a program. Therefore, the longer a debt is not paid back the higher is the risk that the weaknesses can be exploited. To discuss our claim and rise the developers' awareness of the vulnerability of the self-admitted technical debt that is not paid back, we explore the self-admitted technical debt in the Chromium C-code to detect any known weaknesses. In this preliminary study, we first mine the Common Weakness Enumeration repository to define heuristics for the automatic detection and fix of weak code. Then, we parse the C-code to find self-admitted technical debt and the code block it refers to. Finally, we use the heuristics to find weak code snippets associated to self-admitted technical debt and recommend their potential mitigation to developers. Such knowledge can be used to prioritize self-admitted technical debt for repair. A prototype has been developed and applied to the Chromium code. Initial findings report that 55% of self-admitted technical debt code contains weak code of 14 different types.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796253","Self-admitted technical debt;Weak code;Security;Vulnerability","Codes;Prototypes;Chromium;Maintenance engineering;Software;Security;Data mining","","7","","39","","21 Jun 2022","","","IEEE","IEEE Conferences"
"AndroOBFS: Time-tagged Obfuscated Android Malware Dataset with Family Information","S. Kumar; D. Mishra; B. Panda; S. K. Shukla","Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","454","458","With the large-scale adaptation of Android OS and ever-increasing contributions in the Android application space, Android has become the number one target of malware writers. In recent years, a large number of automatic malware detection and classification systems have evolved to tackle the dynamic nature of malware growth using either static or dynamic analysis techniques. Performance of static malware detection methods degrade due to the obfuscation attacks. Although many benchmark datasets are available to measure the performance of malware detection and classification systems, only a single obfuscated malware dataset (PRAGuard) is available to show-case the efficacy of the existing malware detection systems against the obfuscation attacks. PRAGuard contains outdated samples till March 2013 and does not represent the latest application categories. Moreover, PRAGuard does not provide the family information for malware because of which PRAGuard can not be used to evaluate the efficacy of the malware family classification systems. In this work, we create and release AndroOBFS, a time-tagged (at month granularity) obfuscated malware dataset with familial information spanning over three years from 2018 to 2020. We create this dataset by obfuscating 16279 unique real-world malware in six different obfuscation categories. Out of 16279 obfuscated malware samples, 14579 samples are distributed across 158 families with at least two unique malware samples in each family. We release this dataset to facilitate Android malware study towards designing robust and obfuscation resilient malware detection and classification systems.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528493","SERB; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796156","Android;malware;obfuscation;detection;classification","Benchmark testing;Malware;Data mining","","2","","29","","21 Jun 2022","","","IEEE","IEEE Conferences"
"TriggerZoo: A Dataset of Android Applications Automatically Infected with Logic Bombs","J. Samhi; T. F. Bissyandé; J. Klein","SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","459","463","Many Android apps analyzers rely, among other techniques, on dynamic analysis to monitor their runtime behavior and detect potential security threats. However, malicious developers use subtle, though efficient, techniques to bypass dynamic analyzers. Logic bombs are examples of popular techniques where the malicious code is triggered only under specific circumstances, challenging comprehensive dynamic analyses. The research community has proposed various approaches and tools to detect logic bombs. Unfortunately, rigorous assessment and fair comparison of state-of-the-art techniques are impossible due to the lack of ground truth. In this paper, we present Triggerzoo, a new dataset of 406 Android apps containing logic bombs and benign trigger-based behavior that we release only to the research community using authenticated API. These apps are real-world apps from Google Play that have been automatically infected by our tool ANDROBOMB. The injected pieces of code implementing the logic bombs cover a large pallet of realistic logic bomb types that we have manually characterized from a set of real logic bombs. Researchers can exploit this dataset as ground truth to assess their approaches and provide comparisons against other tools.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796237","","Data privacy;Runtime;Codes;Weapons;Malware;Behavioral sciences;Internet","","1","","35","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"Vul4J: A Dataset of Reproducible Java Vulnerabilities Geared Towards the Study of Program Repair Techniques","Q. -C. Bui; R. Scandariato; N. E. D. Ferreyra","Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","464","468","In this work we present Vul4j, a Java vulnerability dataset where each vulnerability is associated to a patch and, most importantly, to a Proof of Vulnerability (PoV) test case. We analyzed 1803 fix commits from 912 real-world vulnerabilities in the Project KB knowledge base to extract the reproducible vulnerabilities, i.e., vulnerabilities that can be triggered by one or more PoV test cases. To this aim, we ran the test suite of the application in both, the vulnerable and secure versions, to identify the corresponding PoVs. Furthermore, if no PoV test case was spotted, then we wrote it ourselves. As a result, Vul4j includes 79 reproducible vulnerabilities from 51 open-source projects, spanning 25 different Common Weakness Enumeration (CWE) types. To the extent of our knowledge, this is the first dataset of its kind created for Java. Particularly, it targets the study of Automated Program Repair (APR) tools, where PoVs are often necessary in order to identify plausible patches. We made our dataset and related tools publically available on GitHub.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796326","java;vulnerability;program repair","Java;Knowledge based systems;Computer bugs;Maintenance engineering;Security;Feeds;Data mining","","12","","20","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Challenges in Migrating Imperative Deep Learning Programs to Graph Execution: An Empirical Study","T. C. Vélez; R. Khatchadourian; M. Bagherzadeh; A. Raja","City University of New York (CUNY) Graduate Center, New York, NY, USA; City University of New York (CUNY) Hunter College, New York, NY, USA; Oakland University, Rochester, MI, USA; City University of New York (CUNY) Hunter College, New York, NY, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","469","481","Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code that supports symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce DL code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged at the expense of run-time performance. While hybrid approaches aim for the “best of both worlds,” the challenges in applying them in the real world are largely unknown. We conduct a data-driven analysis of challenges-and resultant bugs-involved in writing reliable yet performant imperative DL code by studying 250 open-source projects, consisting of 19.7 MLOC, along with 470 and 446 manually examined code patches and bug reports, respectively. The results indicate that hybridization: (i) is prone to API misuse, (ii) can result in performance degradation-the opposite of its intention, and (iii) has limited application due to execution mode incompatibility. We put forth several recommendations, best practices, and anti-patterns for effectively hybridizing imperative DL code, potentially benefiting DL practitioners, API designers, tool developers, and educators.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528455","City University of New York; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796227","empirical studies;deep learning;imperative programs;hybrid programming paradigms;graph-based execution;software evolution","Deep learning;Codes;Neural networks;Computer bugs;Writing;Reliability;Data mining","","3","","103","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes","J. Gong; T. Chen","Loughborough University, Loughborough, UK; Loughborough University, Loughborough, UK",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","482","494","Learning and predicting the performance of a configurable software system helps to provide better quality assurance. One important engineering decision therein is how to encode the configuration into the model built. Despite the presence of different encoding schemes, there is still little understanding of which is better and under what circumstances, as the community often relies on some general beliefs that inform the decision in an ad-hoc manner. To bridge this gap, in this paper, we empirically compared the widely used encoding schemes for software performance learning, namely label, scaled label, and one-hot encoding. The study covers five systems, seven models, and three encoding schemes, leading to 105 cases of investigation. Our key findings reveal that: (1) conducting trial-and-error to find the best encoding scheme in a case by case manner can be rather expensive, requiring up to 400+ hours on some models and systems; (2) the one-hot encoding often leads to the most accurate results while the scaled label encoding is generally weak on accuracy over different models; (3) conversely, the scaled label encoding tends to result in the fastest training time across the models/systems while the one-hot encoding is the slowest; (4) for all models studied, label and scaled label encoding often lead to relatively less biased outcomes between accuracy and training time, but the paired model varies according to the system. We discuss the actionable suggestions derived from our findings, hoping to provide a better understanding of this topic for the community. To promote open science, the data and code of this work can be publicly accessed at https://github.com/ideas-Iabo/MSR2022-encoding-study.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796199","Encoding Scheme;Machine Learning;Software Engineering;Per-formance Prediction;Performance Learning;Configurable Software","Training;Bridges;Systematics;Quality assurance;Neural networks;Software performance;Predictive models","","6","","56","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Multimodal Recommendation of Messenger Channels","E. Koshchenko; E. Klimov; V. Kovalenko","JetBrains Research, Amsterdam, The Netherlands; JetBrains Research, Saint Petersburg, Russia; JetBrains Research, Amsterdam, The Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","495","505","Collaboration platforms, such as GitHub and Slack, are a vital instrument in the day-to-day routine of software engineering teams. The data stored in these platforms has a significant value for datadriven methods that assist with decision-making and help improve software quality. However, the distribution of this data across different platforms leads to the fact that combining it is a very time-consuming process. Most existing algorithms for socio-technical assistance, such as recommendation systems, are based only on data directly related to the purpose of the algorithms, often originating from a single system. In this work, we explore the capabilities of a multimodal recommendation system in the context of software engineering. Using records of interaction between employees in a software company in messenger channels and repositories, as well as the organizational structure, we build several channel recommendation models for a software engineering collaboration platform, and compare them on historical data. In addition, we implement a channel recommendation bot and assess the quality of recommendations from the best models with a user study. We find that the multimodal recommender yields better recommendations than unimodal baselines, allows to mitigate the overfitting problem, and helps to deal with cold start. Our findings suggest that the multimodal approach is promising for other recommendation problems in software engineering.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796325","","Instruments;Software algorithms;Decision making;Collaboration;Software quality;Data models;Data mining","","","","45","","21 Jun 2022","","","IEEE","IEEE Conferences"
"On the Naturalness of Fuzzer-Generated Code","R. H. Kambhamettu; J. Billos; T. Oluwaseun-Apo; B. Gafford; R. Padhye; V. J. Hellendoorn","Carnegie Mellon University, Pennsylvania, USA; Wake Forest University, North Carolina, USA; Pennsylvania State University, Pennsylvania, USA; Carnegie Mellon University, Pennsylvania, USA; Carnegie Mellon University, Pennsylvania, USA; Carnegie Mellon University, Pennsylvania, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","506","510","Compiler fuzzing tools such as Csmith have uncovered many bugs in compilers by randomly sampling programs from a generative model. The success of these tools is often attributed to their ability to generate unexpected corner case inputs that developers tend to overlook during manual testing. At the same time, their chaotic nature makes fuzzer-generated test cases notoriously hard to interpret, which has lead to the creation of input simplification tools such as C-Reduce (for C compiler bugs). In until now unrelated work, researchers have also shown that human-written software tends to be rather repetitive and predictable to language models. Studies show that developers deliberately write more predictable code, whereas code with bugs is relatively unpredictable. In this study, we ask the natural questions of whether this high predictability property of code also, and perhaps counter-intuitively, applies to fuzzer-generated code. That is, we investigate whether fuzzer-generated compiler inputs are deemed unpredictable by a language model built on human-written code and surprisingly conclude that it is not. To the contrary, Csmith fuzzer-generated programs are more predictable on a per-token basis than human-written C programs. Furthermore, bug-triggering tended to be more predictable still than random inputs, and the C-Reduce minimization tool did not substantially increase this predictability. Rather, we find that bug-triggering inputs are unpredictable relative to Csmith's own generative model. This is encouraging; our results suggest promising research directions on incorporating predictability metrics in the fuzzing and reduction tools themselves.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527972","NSF(grant numbers:CCF-1852260,CCF-2120955); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796265","entropy;predictability;generation-based fuzzing;neural language modeling","Measurement;Codes;Program processors;Computer bugs;Manuals;Predictive models;Fuzzing","","","","20","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Senatus - A Fast and Accurate Code-to-Code Recommendation Engine","F. Silavong; S. Moran; A. Georgiadis; R. Saphal; R. Otter","CTO, JPMorgan Chase, London, United Kingdom; CTO, JPMorgan Chase, London, United Kingdom; CTO, JPMorgan Chase, London, United Kingdom; CTO, JPMorgan Chase, London, United Kingdom; CTO, JPMorgan Chase, London, United Kingdom",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","511","523","Machine learning on source code (MLOnCode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with Senatus, a new code-to-code recommendation engine. At the core of Senatus is De-Skew LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus and find the recommendations to be of higher quality than competing baselines, while achieving faster search. For example on the CodeSearchNet dataset Senatus improves performance by 31.21% F1 and 147.9x faster query time compared to Facebook Aroma. Senatus also outperforms standard MinHash LSH by 29.2% F1 and 51.02x faster query time.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796316","Locality sensitive hashing;MinHash LSH;machine learning on source code;Code-to-code recommendation","Codes;Social networking (online);Switches;Syntactics;Search engines;Software;Data mining","","5","","59","","21 Jun 2022","","","IEEE","IEEE Conferences"
"GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses","W. Ma; M. Zhao; E. Soremekun; Q. Hu; J. M. Zhang; M. Papadakis; M. Cordy; X. Xie; Y. Le Traon","University of Luxembourg, Luxembourg; LMU, Munich, Germany; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University College London, United Kingdom; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; Singapore Management University, Singapore; University of Luxembourg, Luxembourg",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","524","536","Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that is generic. To this end, we propose the first self-supervised pre-training approach (called Graphcode2vec) which produces task-agnostic embedding of lexical and program dependence features. Graphcode2vec achieves this via a synergistic combination of code analysis and Graph Neural Networks. Graphcode2vec is generic, it allows pre-training, and it is applicable to several SE downstream tasks. We evaluate the effectiveness of Graphcode2vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT, Graph-CodeBERT) and seven (7) task-specific, learning-based methods. In particular, Graphcode2vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that Graphcode2vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796339","code embedding;code representation;code analysis","Learning systems;Codes;Semantics;Machine learning;Syntactics;Maintenance engineering;Software","","13","","78","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"Do Small Code Changes Merge Faster? A Multi-Language Empirical Investigation","G. Kudrjavets; N. Nagappan; A. Rastogi","University of Groningen, Groningen, Netherlands; Meta Platforms, Inc., Menlo Park, CA, USA; University of Groningen, Groningen, Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","537","548","Code velocity, or the speed with which code changes are integrated into a production environment, plays a crucial role in Continuous Integration and Continuous Deployment. Many studies report factors influencing code velocity. However, solutions to increase code velocity are unclear. Meanwhile, the industry continues to issue guidelines on “ideal” code change size, believing it increases code velocity despite lacking evidence validating the practice. Surprisingly, this fundamental question has not been studied to date. This study investigates the practicality of improving code velocity by optimizing pull request size and composition (ratio of insertions, deletions, and modifications). We start with a hypothesis that a moderate correlation exists between pull request size and time-to-merge. We selected 100 most popular, actively developed projects from 10 programming languages on GitHub. We analyzed our dataset of 845,316 pull requests by size, composition, and context to explore its relationship to time-to-merge–a proxy to measure code velocity. Our study shows that pull request size and composition do not relate to time-to-merge. Regardless of the contextual factors that can influence pull request size or composition (e.g., programming language), the observation holds. Pull request data from two other platforms: Gerrit and Phabricator (401,790 code reviews) confirms the lack of relationship. This negative result as in “…eliminate useless hypotheses …” [75] challenges a widespread belief by showing that small code changes do not merge faster to increase code velocity.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796376","Pull request;code review velocity;pull request size;GitHub","Industries;Computer languages;Codes;Production;Size measurement;Software;Velocity measurement","","3","","83","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"FaST: A linear time stack trace alignment heuristic for crash report deduplication","I. M. Rodrigues; D. Aloise; E. R. Fernandes","Polytechnique Montreal, Montreal, Canada; Polytechnique Montreal, Montreal, Canada; Leuphana University of Lüneburg, Lüneburg, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","549","560","In software projects, applications are often monitored by systems that automatically identify crashes, collect their information into reports, and submit them to developers. Especially in popular applications, such systems tend to generate a large number of crash reports in which a significant portion of them are duplicate. Due to this high submission volume, in practice, the crash report deduplication is supported by devising automatic systems whose efficiency is a critical constraint. In this paper, we focus on improving deduplication system throughput by speeding up the stack trace comparison. In contrast to the state-of-the-art techniques, we propose FaST, a novel sequence alignment method that computes the similarity score between two stack traces in linear time. Our method independently aligns identical frames in two stack traces by means of a simple alignment heuristic. We evaluate FaST and five competing methods on four datasets from open-source projects using ranking and binary metrics. Despite its simplicity, FaST consistently achieves state-of-the-art performance regarding all metrics considered. Moreover, our experiments confirm that FaST is substantially more efficient than methods based on optimal sequence alignment.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527951","Natural Sciences and Engineering Research Council of Canada (NSERC); WestGrid; Compute Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796190","Duplicate Crash Report;Crash Report Deduplication;Duplicate Crash Report Detection;Automatic Crash Reporting;Stack Trace Similarity","Measurement;Throughput;Data structures;Computer crashes;Indexes;Data mining;Open source software","","5","","26","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Is Open Source Eating the World's Software? Measuring the Proportion of Open Source in Proprietary Software Using Java Binaries","J. Musseau; J. S. Meyers; G. P. Sieniawski; C. A. Thompson; D. German","Mergebase, Canada; Chainguard, USA; IQT Labs, USA; Ford Motor Company, USA; University of Victoria, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","561","565","That open source software comprises an increasingly large percentage of modern software applications has become conventional wisdom. The exact extent to which open source software constitutes today's applications is indeterminate, however, at least by the standards of the academic software engineering research community. This paper proposes a methodology and associated tool that can analyze Java binaries and determine the proportion of open source that comprises them. This paper also presents empirical measurements of 5 commercial Java software systems, reporting OSS proportions between 76.2% to 99.9% among these 5 systems, including a historical analysis covering 6 versions and 12 years for one of the subject systems.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796295","Open Source Software;Measurement;Methodology;Java;Binaries","Java;Software systems;Software;Distance measurement;Software measurement;Data mining;Task analysis","","","","14","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Methods for Stabilizing Models Across Large Samples of Projects (with case studies on Predicting Defect and Project Health)","S. Majumder; T. Xia; R. Krishna; T. Menzies","Computer Science, North Carolina State University, Raleigh, USA; Computer Science, North Carolina State University, Raleigh, USA; Computer Science, North Carolina State University, Raleigh, USA; Computer Science, North Carolina State University, Raleigh, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","566","578","Despite decades of research, Software Engineering (SE) lacks widely accepted models (that offer precise quantitative stable predictions) about what factors most influence software quality. This paper provides a promising result showing such stable models can be generated using a new transfer learning framework called “STABILIZER”. Given a tree of recursively clustered projects (using project meta-data), STABILIZER promotes a model upwards if it performs best in the lower clusters (stopping when the promoted model performs worse than the models seen at a lower level). The number of models found by STABILIZER is minimal: one for defect prediction (756 projects) and less than a dozen for project health (1628 projects). Hence, via STABILIZER, it is possible to find a few projects which can be used for transfer learning and make conclusions that hold across hundreds of projects at a time. Further, the models produced in this manner offer predictions that perform as well or better than the prior state-of-the-art. To the best of our knowledge, STABILIZER is order of magnitude faster than the prior state-of-the-art transfer learners which seek to find conclusion stability, and these case studies are the largest demonstration of the generalizability of quantitative predictions of project quality yet reported in the SE literature. In order to support open science, all our scripts and data are online at https://github.com/Anonymous633671/STABILIZER.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527934","National Science Foundation(grant numbers:1908762); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796244","Defect Prediction;Project Health;Bellwether;Hierarchical Clustering;Random Forest;Two Phase Transfer Learning;Transfer Learning","Transfer learning;Buildings;Estimation;Software quality;Forestry;Predictive models;Stability analysis","","1","","113","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Mining Code Review Data to Understand Waiting Times Between Acceptance and Merging: An Empirical Analysis","G. Kudrjavets; A. Kumar; N. Nagappan; A. Rastogi","University of Groningen, Groningen, Netherlands; Snap, Inc., Santa Monica, CA, USA; Meta Platforms, Inc., Menlo Park, CA, USA; University of Groningen, Groningen, Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","579","590","Increasing code velocity (or the speed with which code changes are reviewed and merged) is integral to speeding up development and contributes to the work satisfaction of engineers. While factors affecting code change acceptance have been investigated in the past, solutions to decrease the code review lifetime are less understood. This study investigates the code review process to quantify delays and investigate opportunities to potentially increase code velocity. We study the temporal characteristics of half a million code reviews hosted on Gerrit and Phabricator, starting from the first response, to a decision to accept or reject the changes, and until the changes are merged into a target branch. We identified two types of time delays: (a) the wait time from the proposal of code changes until first response, and (b) the wait time between acceptance and merging. Our study indicates that reducing the time between acceptance and merging has the potential to speed up Phabricator code reviews by 29-63%. Small code changes and changes made by authors with a large number of previously accepted code reviews have a higher chance of being immediately accepted, without code review iterations. Our analysis suggests that switching from manual to automatic merges can help increase code velocity.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796315","Code review;code velocity;developer productivity;non-productive time","Codes;Delay effects;Merging;Switches;Software;Delays;Data mining","","7","","69","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"TwinDroid: A Dataset of Android app System call traces and Trace Generation Pipeline","A. Razagallah; R. Khoury; J. -B. Poulet","Univeristé du Québec à Chicoutimi, Sagueny, Québec, Canada; Univeristé du Québec à Chicoutimi, Sagueny, Québec, Canada; Univeristé du Québec à Chicoutimi, Sagueny, Québec, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","591","595","System call traces are an invaluable source of information about a program's runtime behavior and be particularly useful for malware detection in Android apps. However, the paucity of publicly available high-quality datasets hinders the development of the field. In this paper, we introduce TwinDroid, a dataset of over 1000 system calls traces, from both benign and infected Android apps. A large part of the apps used to create the dataset is from benign-malicious app pairs, identical apart from the inclusion of malware in the latter. This makes TwinDroid an ideal basis for security research, and an earlier version of TwinDroid has already been used for this purpose. In addition to a dataset of traces, TwinDroid includes a fully automated traces generation pipeline, which allows users to generate new traces in a standardized manner seamlessly. This pipeline will enable the dataset to remain up-to-date and relevant despite the rapid pace of change that characterizes Android security.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796248","dataset;Android apps;security;System call traces","Runtime;Pipelines;Malware;Behavioral sciences;Security;Data mining","","","","19","","21 Jun 2022","","","IEEE","IEEE Conferences"
"LineVD: Statement-level Vulnerability Detection using Graph Neural Networks","D. Hin; A. Kan; H. Chen; M. A. Babar","CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; AWS AI Labs*, Adelaide, SA, Australia; CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","596","607","Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development work-flow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experi-ments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796269","Software Vulnerability Detection;Program Representation;Deep Learning","Deep learning;Training;Codes;Supervised learning;Predictive models;Transformers;Feature extraction","","53","","62","","21 Jun 2022","","","IEEE","IEEE Conferences"
"LineVul: A Transformer-based Line-Level Vulnerability Prediction","M. Fu; C. Tantithamthavorn","Monash University, Australia; Monash University, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","608","620","Software vulnerabilities are prevalent in software systems, causing a variety of problems including deadlock, information loss, or system failures. Thus, early predictions of software vulnerabilities are critically important in safety-critical software systems. Various ML/DL-based approaches have been proposed to predict vulnerabilities at the file/function/method level. Recently, IVDetect (a graph-based neural network) is proposed to predict vulnerabilities at the function level. Yet, the IVDetect approach is still inaccurate and coarse-grained. In this paper, we propose LINEVUL, a Transformer-based line-level vulnerability prediction approach in order to address several limitations of the state-of-the-art IVDetect approach. Through an empirical evaluation of a large-scale real-world dataset with 188k+ C/C++ functions, we show that LINEVUL achieves (1) 160%-379% higher F1-measure for function-level predictions; (2) 12%-25% higher Top-10 Accuracy for line-level predictions; and (3) 29%-53% less Effort@20%Recall than the baseline approaches, highlighting the significant advancement of LINEVUL towards more accurate and more cost-effective line-level vulnerability predictions. Our additional analysis also shows that our LINEVUL is also very accurate (75%-100%) for predicting vulnerable functions affected by the Top-25 most dangerous CWEs, highlighting the potential impact of our LINEVUL in real-world usage scenarios.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796256","Vulnerability Prediction;AI for Software Engineering;Software Security","Neural networks;System recovery;Transformers;Software systems;Security;Data mining","","93","","66","","21 Jun 2022","","","IEEE","IEEE Conferences"
"On the Use of Fine-grained Vulnerable Code Statements for Software Vulnerability Assessment Models","T. H. M. Le; M. A. Babar","CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","621","633","Many studies have developed Machine Learning (ML) approaches to detect Software Vulnerabilities (SVs) in functions and fine-grained code statements that cause such SVs. However, there is little work on leveraging such detection outputs for data-driven SV assessment to give information about exploitability, impact, and severity of SVs. The information is important to understand SVs and prioritize their fixing. Using large-scale data from 1,782 functions of 429 SVs in 200 real-world projects, we investigate ML models for automating function-level SV assessment tasks, i.e., predicting seven Common Vulnerability Scoring System (CVSS) metrics. We particularly study the value and use of vulnerable statements as inputs for developing the assessment models because SVs in functions are originated in these statements. We show that vulnerable statements are 5.8 times smaller in size, yet exhibit 7.5-114.5% stronger assessment performance (Matthews Correlation Coefficient (MCC)) than non-vulnerable statements. Incorporating context of vulnerable statements further increases the performance by up to 8.9% (0.64 MCC and 0.75 F1-Score). Overall, we provide the initial yet promising ML-based baselines for function-level SV assessment, paving the way for further research in this direction.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796209","Security Vulnerability;Vulnerability Assessment;Machine Learning;Mining Software Repositories","Measurement;Correlation coefficient;Codes;Machine learning;Predictive models;Software;Data models","","13","","93","","21 Jun 2022","","","IEEE","IEEE Conferences"
"ECench: An Energy Bug Benchmark of Ethereum Client Software","J. Kim; M. Kim; E. Lee","Department of Software, Sungkyunkwan University, Suwon, Republic of Korea; Institute of Software Convergence, Sungkyunkwan University, Suwon, Republic of Korea; College of Computing and Informatics, Sungkyunkwan University, Suwon, Republic of Korea",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","634","638","With the introduction of smart contacts, Ethereum has become one of the most popular blockchain networks. In the wake of its popularity, an increasing number of Ethereum-based software have been developed. However, the carbon emissions resulting from these software has been pointed out as a global issue. It is necessary to reduce the energy consumed by these software to reduce carbon emissions. Recently, most studies have focused on smart contracts and proposed energy-efficient methods for the development of carbon friendly Ethereum networks. However, in addition to smart contracts, the energy used by client software in Ethereum networks should also be reviewed. This is because the client software performs all functions occurring in the Ethereum network, including smart contracts. Therefore, energy bugs that waste energy in Ethereum client software should be investigated and solved. The first task to enable this is to build an energy bug benchmark of Ethereum client software. This study introduces ECench, an energy bug benchmark of Ethereum client software. ECench includes 507 energy buggy commits from 7 series of client software that are officially operated in the Ethereum network. We carefully collected and manually reviewed them for cleaner commits. A key strength of our benchmark is that it provides eight energy wastage categories, which can serve as a cornerstone for researchers to identify energy waste codes. ECench can provide a valuable starting point for studies on energy reduction and carbon reduction in Ethereum.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528028","National Research Foundation of Korea(NRF)(grant numbers:2019R1A2C2006411); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796293","benchmark;ethereum;software engineering;energy consumption","Codes;Computer bugs;Smart contracts;Carbon dioxide;Benchmark testing;Software;Energy efficiency","","1","","24","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Microsoft CloudMine: Data Mining for the Executive Order on Improving the Nation's Cybersecurity","K. Herzig; L. Ghostling; M. Grothusmann; S. Just; N. Huang; A. Klimowski; Y. Ramkumar; M. McLeroy; K. Muslu; H. Sajnani; V. Vadaga","Microsoft Corporation, USA; Microsoft Corporation, USA; Microsoft Corporation, Germany; Microsoft Corporation, Germany; Microsoft Corporation, Canada; Microsoft Corporation, USA; Microsoft Corporation, USA; Microsoft Corporation, USA; Microsoft Corporation, USA; Microsoft Corporation, USA; Microsoft Corporation, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","639","639","As any other US software maker, Microsoft is bound by the “Executive Order on Improving the Nation's Cybersecurity” [2] which dictates a clear mandate to “enhance the software supply chain security” and to generally improve the cyber security practices. However, this is much easier written down than enforced. The executive order imposes new rules and requirements that will impact engineering practices and evidence collection for most projects and engineering teams in a relatively short period of time. Part of the response is the requirement to build up comprehensive inventories of software artifacts contributing to US government systems, which is a massive task when done manually would be tedious and fragile as software eco-systems change rapidly. Required is a system that will constantly monitor and update the inventory of software artifacts and contributors so that at any given point of time, the scope and involved teams for any software security incident can be notified and response plans activated. The front line of this security battle includes data mining platforms providing the security and compliance teams with engineering artifacts and insights into artifact dependencies and engineering practices of the corresponding engineering teams. The data provided does not only allow Microsoft to build an accurate engineering artifact inventory, but also enables Microsoft�s teams to initiate so called “get-clean” initiatives to start issue remediation before proper policy tools and pipelines (“stay-clean”) can be developed, tested, and deployed. In this talk we will present CloudMine1, one of Microsoft's main data mining platforms serving data sets and dependency graphs of more than 270 different engineering artifacts (e.g., builds, releases, commits, pull requests, etc.) gathered on an hourly basis. During the talk we will provide some insights into CloudMine, its engineering team and operational costs-which is significant. We will then highlight the benefits and opportunities a data mining framework like CloudMine provides the company including insights into how inventory and automation bots use CloudMine data to impact thousands of Microsoft engineers daily, saving the company significant costs and response times to security incidents: the ability to scan more than 100,000 code repositories across the enterprise within hours; building up an artifact engineering inventory enabling us to flag any known security vulnerability in any of the software components within hours; or spotting non-compliant build and release pipelines across Microsoft's 500,000 pipelines. In addition, we will also present open challenges the CloudMine engineering team is facing during operating and growing CloudMine as a platform, which will hopefully provide motivation and inspiration for researcher and other companies to start a dialog with us and other companies about these challenges and latest research results that may help us solve these issues. From the talk it should become clear that running enterprise scale systems is not cheap but worth the effort as it enables Microsoft and its engineering teams to respond to current cyber security threads even before we can build and test best in class built-in defense systems.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796173","CloudMine;CyberSecurity","Software;Security;Companies;Data mining;Computer crime;Buildings;Tungsten","","1","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Evaluating the effectiveness of local explanation methods on source code-based defect prediction models","Y. Gao; Y. Zhu; Q. Yu","School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China; School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China; School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","640","645","Interpretation has been considered as one of key factors for applying defect prediction in practice. As one way for interpretation, local explanation methods has been widely used for certain predictions on datasets of traditional features. There are also attempts to use local explanation methods on source code-based defect prediction models, but unfortunately, it will get poor results. Since it is unclear how effective those local explanation methods are, we evaluate such methods with automatic metrics which focus on local faithfulness and explanation precision. Based on the results of experiments, we find that the effectiveness of local explanation methods depends on the adopted defect prediction models. They are effective on token frequency-based models, while they may not be effective enough to explain all predictions of deep learning-based models. Besides, we also find that the hyperparameter of local explanation methods should be carefully optimized to get more precise and meaningful explanation.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528472","National Natural Science Foundation of China(grant numbers:62077029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796250","Software Defect Prediction;Local Explanation;Explainable Machine Learning;LIME","Measurement;Codes;Predictive models;Software;Data mining","","3","","31","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Problems and Solutions in Applying Continuous Integration and Delivery to 20 Open-Source Cyber-Physical Systems","F. Zampetti; V. Nardone; M. Di Penta","University of Sannio, Benevento, Italy; University of Sannio, Benevento, Italy; University of Sannio, Benevento, Italy",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","646","657","Continuous integration and delivery (CI/CD) have been shown to be very useful to improve the quality of software products (e.g., increasing their reliability or maintainability), and their development processes, e.g., by shortening release cycles. Applying CI/CD in the context of Cyber-Physical Systems (CPSs) can be particularly important, given that many of those systems can have safety-critical properties, and given their interaction with hardware or simulators during the development phase. This paper empirically analyzes how CI/CD is enacted in CPSs when considering the context of open-source projects, that often (also) rely on hosted CI/CD so-lutions, and benefit of an open-source development community. We qualitatively analyze a statistically significant sample of 670 pull requests from 20 open-source CPSs hosted on GitHub, to identify and categorize-also keeping into account catalogs from previous literature-bad practices, challenges, mitigation, and restructuring actions. The study reports and discusses the relationships we found between bad practices/challenges and CI/CD restructuring/mitigation strategies, reporting concrete examples, especially those emerging from the intrinsic complexity of CPSs.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796215","Cyber- Physical Systems;Continuous Integration and Delivery;Pull Requests","Cyber-physical systems;Hardware;Software reliability;Complexity theory;Data mining;Open source software;Software development management","","2","","49","","21 Jun 2022","","","IEEE","IEEE Conferences"
"To Type or Not to Type? A Systematic Comparison of the Software Quality of JavaScript and TypeScript Applications on GitHub","J. Bogner; M. Merkel","University of Stuttgart, Institute of Software Engineering, Stuttgart, Germany; University of Stuttgart, Institute of Software Engineering, Stuttgart, Germany",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","658","669","JavaScript (JS) is one of the most popular programming languages, and widely used for web apps, mobile apps, desktop clients, and even backend development. Due to its dynamic and flexible nature, however, JS applications often have a reputation for poor software quality. While the type-safe superset TypeScript (TS) offers features to address these prejudices, there is currently insufficient empirical evidence to broadly support the claim that TS applications exhibit better software quality than JS applications. We therefore conducted a repository mining study based on 604 GitHub projects (299 for JS, 305 for TS) with over 16M LoC. Using SonarQube and the GitHub API, we collected and analyzed four facets of software quality: a) code quality (# of code smells per LoC), b) code understandability (cognitive complexity per LoC), c) bug proneness (bug fix commit ratio), and d) bug resolution time (mean time a bug issue is open). For TS, we also collected how frequently the type-safety ignoring any type was used per project via ESLint. The analysis indicates that TS applications exhibit significantly better code quality and understandability than JS applications. Contrary to expectations, however, bug proneness and bug resolution time of our TS sample were not significantly lower than for JS: the mean bug fix commit ratio of TS projects was more than 60% larger (0.126 vs. 0.206), and TS projects needed on average more than an additional day to fix bugs (31.86 vs. 33.04 days). Furthermore, reducing the usage of the any type in TS apps appears to be beneficial: its frequency was significantly correlated with all metrics except bug proneness, even though the correlations were of small strengths (Spearman's rho between 0.17 and 0.26). Our results indicate that the perceived positive influence of Type-Script for avoiding bugs in comparison to JavaScript may be more complicated than assumed. While using TS seems to have benefits, it does not automatically lead to less and easier to fix bugs. However, more research is needed in this area, especially concerning the potential influence of project complexity and developer experience.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796341","JavaScript;TypeScript;software quality;repository mining;GitHub","Codes;Correlation;Systematics;Statistical analysis;Computer bugs;Software quality;Complexity theory","","1","","39","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Using Bandit Algorithms for Selecting Feature Reduction Techniques in Software Defect Prediction","M. Tsunoda; A. Monden; K. Toda; A. Tahir; K. E. Bennin; K. Nakasai; M. Nagura; K. Matsumoto","Kindai University, Higashi-osaka, Japan; Okayama University, Okayama, Japan; Fukuoka Institute of Tech., Fukuoka, Japan; Massey University, Palmerston North, NZ; Wageningen UR, Wageningen, Netherlands; Kumamoto College, NIT, Kirishima, Japan; Nanzan University, Nagoya, Japan; NAIST, Ikoma, Japan",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","670","681","Background: Selecting a suitable feature reduction technique, when building a defect prediction model, can be challenging. Different techniques can result in the selection of different independent variables which have an impact on the overall performance of the prediction model. To help in the selection, previous studies have assessed the impact of each feature reduction technique using different datasets. However, there are many reduction techniques, and therefore some of the well-known techniques have not been assessed by those studies. Aim: The goal of the study is to select a high-accuracy reduction technique from several candidates without preliminary assessments. Method: We utilized bandit algorithm (BA) to help with the selection of best features reduction technique for a list of candidates. To select the best feature reduction technique, BA evaluates the prediction accuracy of the candidates, comparing testing results of different modules with their prediction results. By substituting the reduction technique for the prediction method, BA can then be used to select the best reduction technique. In the experiment, we evaluated the performance of BA to select suitable reduction technique. We performed cross version defect prediction using 14 datasets. As feature reduction techniques, we used two assessed and two non-assessed techniques. Results: Using BA, the prediction accuracy was higher or equivalent than existing approaches on average, compared with techniques selected based on an assessment. Conclusions: BA can have larger impact on improving prediction models by helping not only on selecting suitable models, but also in selecting suitable feature reduction techniques.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3529093","Japan Society for the Promotion of Science(grant numbers:20H05706); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796258","Software fault prediction;online optimization;variable selection;external validity","Degradation;Software testing;Heuristic algorithms;Software algorithms;Buildings;Predictive models;Prediction algorithms","","10","","37","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Constructing Dataset of Functionally Equivalent Java Methods Using Automated Test Generation Techniques","Y. Higo; S. Matsumoto; S. Kusumoto; K. Yasuda","Osaka University, Suita, Osaka, Japan; Osaka University, Suita, Osaka, Japan; Osaka University, Suita, Osaka, Japan; Hitachi, Ltd., Yokohama, Kanagawa, Japan",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","682","686","Since programming languages offer a wide variety of grammers, desired functions can be implemented in a variety of ways. We consider that there is a large amount of source code that has different implementations of the same functions, and that those can be compiled into a dataset useful for various research in software engineering. In this study, we construct a dataset of functionally equivalent Java methods from about 36 million lines of source code. The constructed dataset is available at https://zenodo.org/record/5912689.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796310","functionally equivalent Java methods;test generation techniques","Java;Visualization;Computer languages;Codes;Limiting;Cloning;Test pattern generators","","5","","11","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Extracting Corrective Actions from Code Repositories","Y. Bugayenko; K. Daniakin; M. Farina; F. Jolha; A. Kruglov; G. Succi; W. Pedrycz","Huawei, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; University of Alberta, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","687","688","Simple detection of bugs, defects or anomalies during software development is not enough - it is necessary to apply corrective actions to eliminate them. To find out whether an anomaly exists in any software, we can measure the quality attributes using software metrics. The main goal of this paper was to find out and explain how to meaningfully attribute metrics to useful corrective actions.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796279","software metrics;repository;information retrieval;anomaly;corrective action;project management","Codes;Software metrics;Computer bugs;Software;Data mining","","3","","5","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Code Review Practices for Refactoring Changes: An Empirical Study on OpenStack","E. A. AlOmar; M. Chouchen; M. W. Mkaouer; A. Ouni","Stevens Institute of Technology, Hoboken, New Jersey, USA; ETS Montreal, University of Quebec, Montreal, Quebec, Canada; Rochester Institute of Technology, Rochester, New York, USA; ETS Montreal, University of Quebec, Montreal, Quebec, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","689","701","Modern code review is a widely used technique employed in both industrial and open-source projects to improve software quality, share knowledge, and ensure adherence to coding standards and guidelines. During code review, developers may discuss refactoring activities before merging code changes in the code base. To date, code review has been extensively studied to explore its general challenges, best practices and outcomes, and socio-technical aspects. However, little is known about how refactoring is being reviewed and what developers care about when they review refactored code. Hence, in this work, we present a quantitative and qualitative study to understand what are the main criteria developers rely on to develop a decision about accepting or rejecting a submitted refactored code, and what makes this process challenging. Through a case study of 11,010 refactoring and non-refactoring reviews spread across OpenStack open-source projects, we find that refactoring-related code reviews take significantly longer to be resolved in terms of code review efforts. Moreover, upon performing a thematic analysis on a significant sample of the refactoring code review discussions, we built a comprehensive taxonomy consisting of 28 refactoring review criteria. We envision our findings reaffirming the necessity of developing accurate and efficient tools and techniques that can assist developers in the review process in the presence of refactorings.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3527932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796280","refactoring;code review;developer perception;software quality","Industries;Codes;Taxonomy;Merging;Software quality;Encoding;Open source software","","12","","93","","21 Jun 2022","","","IEEE","IEEE Conferences"
"A Time Series-Based Dataset of Open-Source Software Evolution","B. L. Sousa; M. A. S. Bigonha; K. A. M. Ferreira; G. C. Franco","Department of Computer Science, UFMG Belo Horizonte, Minas Gerais, Brazil; Department of Computer Science, UFMG Belo Horizonte, Minas Gerais, Brazil; Department of Computing, CEFET-MG Belo Horizonte, Minas Gerais, Brazil; Department of Statistics, UFMG Belo Horizonte, Minas Gerais, Brazil",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","702","706","Software evolution is the process of developing, maintaining, and updating software systems. It is known that the software systems tend to increase their complexity and size over their evolution to meet the demands required by the users. Due to this fact, researchers have increasingly carried out studies on software evolution to understand the systems' evolution pattern and propose techniques to overcome inherent problems in software evolution. Many of these works collect data but do not make them publicly available. Many datasets on software evolution are outdated, and/or are small, and some of them do not provide time series from software metrics. We propose an extensive software evolution dataset with temporal information about open-source Java systems. To build this dataset, we proposed a methodology of four steps: selecting the systems using a criterion, extracting and measuring their releases, and generating their time series. Our dataset contains time series of 46 software metrics extracted from 46 open-source Java systems, and we make it publicly available.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528492","CAPES; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796226","dataset;software evolution;software metrics;time series;open-source software","Java;Codes;Software metrics;Time series analysis;Software systems;Time measurement;Complexity theory","","","","38","","21 Jun 2022","","","IEEE","IEEE Conferences"
"A Versatile Dataset of Agile Open Source Software Projects","V. Tawosi; A. Al-Subaihin; R. Moussa; F. Sarro","University College London, London, UK; University College London, London, UK; University College London, London, UK; University College London, London, UK",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","707","711","Agile software development is nowadays a widely adopted practise in both open-source and industrial software projects. Agile teams typically heavily rely on issue management tools to document new issues and keep track of outstanding ones, in addition to storing their technical details, effort estimates, assignment to developers, and more. Previous work utilised the historical information stored in issue management systems for various purposes; however, when researchers make their empirical data public, it is usually relevant solely to the study's objective. In this paper, we present a more holistic and versatile dataset containing a wealth of information on more than half a million issues from 44 open-source Agile software, making it well-suited to several research avenues, and cross-analyses therein, including effort estimation, issue prioritization, issue assignment and many more. We make this data publicly available on GitHub to facilitate ease of use, maintenance, and extensibility.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528029","ERC(grant numbers:741278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796320","Agile Development;Open-Source Software;Data Mining","Estimation;Maintenance engineering;Data mining;Open source software","","8","","33","","21 Jun 2022","","","IEEE","IEEE Conferences"
"FixJS: A Dataset of Bug-fixing JavaScript Commits","V. Csuvik; L. Vidács","Department of Software Engineering, MTA-SZTE Research Group on Artificial Intelligence University of Szeged, Szeged, Hungary; Department of Software Engineering, MTA-SZTE Research Group on Artificial Intelligence University of Szeged, Szeged, Hungary",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","712","716","The field of Automated Program Repair (APR) has received increasing attention in recent years both from the academic world and from leading IT companies. Its main goal is to repair software bugs automatically, thus reducing the cost of development and mainte-nance significantly. Recent works use state-of-the-art deep learning models to predict correct patches, for these teaching on a large amount of data is inevitable almost in every scenarios. Despite this, readily accessible data on the field is very scarce. To contribute to related research, we present FixJS, a dataset containing bug-fixing information of ~2 million commits. The commits were gathered from GitHub and processed locally to have both the buggy (before bug fixing commit) and fixed (after fix) version of the same program. We focused on JavaScript functions, as it is one of the most popular programming language globally and functions are first class objects there. The data includes more than 300,000 samples of such functions, including commit information, before/after states and 3 source code representations.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796277","Automated Program Repair;Software engineering;Bug-fixing commits","Deep learning;Costs;Computer bugs;Education;Maintenance engineering;Predictive models;Software","","9","","27","","21 Jun 2022","","","IEEE","IEEE Conferences"
"LAGOON: An Analysis Tool for Open Source Communities","S. Dey; W. Woods","Galois, Inc., Portland, Oregon, USA; Galois, Inc., Portland, Oregon, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","717","721","This paper presents LAGOON - an open source platform for understanding the complex ecosystems of Open Source Software (OSS) communities. The platform currently utilizes spatiotemporal graphs to store and investigate the artifacts produced by these communities, and help analysts identify bad actors who might compromise an OSS project's security. LAGOON provides ingest of artifacts from several common sources, including source code repositories, issue trackers, mailing lists and scraping content from project websites. Ingestion utilizes a modular architecture, which supports incremental updates from data sources and provides a generic identity fusion process that can recognize the same community members across disparate accounts. A user interface is provided for visualization and exploration of an OSS project's complete sociotechnical graph. Scripts are provided for applying machine learning to identify pat-terns within the data. While current focus is on the identification of bad actors in the Python community, the platform's reusability makes it easily extensible with new data and analyses, paving the way for LAGOON to become a comprehensive means of assessing various OSS-based projects and their communities.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528504","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR00112190092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796249","graph data;machine learning;open source software;social database;spatiotemporal data analysis;user interface","Soft sensors;Ecosystems;Data visualization;Machine learning;Computer architecture;Spatiotemporal phenomena;Security","","1","","36","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Automatically Prioritizing and Assigning Tasks from Code Repositories in Puzzle Driven Development","Y. Bugayenko; A. Bakare; A. Cheverda; M. Farina; A. Kruglov; Y. Plaksin; G. Succi; W. Pedrycz","Huawei, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; Innopolis University, Russia; University of Alberta, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","722","723","Automatically prioritizing software development tasks extracted from codes could provide significant technical and organizational advantages. Tools exist for the automatic extraction of tasks, but they still lack the ability to capture their mutual dependencies; hence, the capability to prioritize them. Solving this important puzzle is the goal of the presented industrial challenge.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796201","task prioritization;text tagging;software development","Codes;Software;Data mining;Task analysis","","3","","5","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Software Bots in Software Engineering: Benefits and Challenges","M. Wessel; M. A. Gerosa; E. Shihab","Delft University of Technology, Delft, The Netherlands; Northern Arizona University, Flagstaff, USA; Concordia University, Montreal, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","724","725","Software bots are becoming increasingly popular in software engineering (SE). In this tutorial, we define what a bot is and present several examples. We also discuss the many benefits bots provide to the SE community, including helping in development tasks (such as pull request review and integration) and onboarding newcomers to a project. Finally, we discuss the challenges related to interacting with and developing software bots.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796186","Software Bots;GitHub Bots;Chatbots;Human-bot Interaction;Open Source Software;Automation;Collaborative Development","Bot (Internet);Tutorials;Software;Data mining;Task analysis;Software engineering","","2","","19","CCBY","21 Jun 2022","","","IEEE","IEEE Conferences"
"Bot Detection in GitHub Repositories","N. Chidambaram; P. R. Mazrae","Software Engineering Lab, University of Mons, Mons, Belgium; Software Engineering Lab, University of Mons, Mons, Belgium",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","726","728","Contemporary social coding platforms like GitHub promote collaborative development. Many open-source software repositories hosted in these platforms use machine accounts (bots) to automate and facilitate a wide range of effort-intensive and repetitive activities. Determining if an account corresponds to a bot or a human contributor is important for socio-technical development analytics, for example, to understand how humans collaborate and interact in the presence of bots, to assess the positive and negative impact of using bots, to identify the top project contributors, to identify potential bus factors, and so on. Our project aims to include the trained machine learning (ML) classifier from the BoDeGHa bot detection tool as a plugin to the GrimoireLab software development analytics platform. In this work, we present the procedure to form a pipeline for retrieving contribution and contributor data using Perceval, distinguishing bots from humans using BoDeGHa, and visualising the results using Kibana.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796354","","Bot (Internet);Pipelines;Data visualization;Machine learning;Organizations;Encoding;Data mining","","3","","7","","21 Jun 2022","","","IEEE","IEEE Conferences"
"GitRank: A Framework to Rank GitHub Repositories","N. Hasabnis","Intel Labs, Santa Clara, California, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","729","731","Open-source repositories provide wealth of information and are increasingly being used to build artificial intelligence (AI) based systems to solve problems in software engineering. Open-source repositories could be of varying quality levels, and bad-quality repositories could degrade performance of these systems. Evaluating quality of open-source repositories, which is not available directly on code hosting sites such as GitHub, is thus important. In this hackathon, we utilize known code quality measures and GrimoireLab toolkit to implement a framework, named Gi tRank, to rank open-source repositories on three different criteria. We discuss our findings and preliminary evaluation in this hackathon report.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796321","ai;open source software;oss;code quality;machine programming","Measurement;Codes;Data mining;Artificial intelligence;Open source software;Software development management;Software engineering","","1","","34","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Maintenance and Evolution: GrimoireLab Graal","W. Meijer; D. Visscher; E. De Haan; M. Schröder; L. Visscher; A. Capiluppi; I. Botez","Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","732","734","E-type open-source software inevitably grows in size and complexity over time, and without performing anti-regressive tasks this type of software has a limited lifespan. In this project, a case study of the effect of such anti-regressive tasks is conducted using GrimoireLab Graal as a subject. This process is guided by quality metrics and developer insights. The outcome of this work is a life-cycle of maintenance activities, ultimately resulting in a refactored version of GrimoireLab Graal. After applying anti-regressive actions, commonly used software quality metrics decreased (lower is better). Additionally, after performing an experiment to test the evolution readiness of the software, the complexity of the original software increased significantly, whilst no side effects were measured in the revised software.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796238","software maintenance;software evolution;quality metrics;refactoring","Software quality;Computer architecture;Switches;Maintenance engineering;Software;Complexity theory;Software measurement","","","","7","","21 Jun 2022","","","IEEE","IEEE Conferences"
"OpenSSL 3.0.0: An exploratory case study","J. Walden","Northern Kentucky University Highland Heights, Ohio, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","735","737","Context: The OpenSSL project released version 3.0.0 in Septem-ber 2021. This release was a departure from previous versions of OpenSSL in several ways, including a new versioning system and the first use of public software design documents. Objective: The goal is to compare code quality of version 3.0.0 with the previous major release using the GrimoireLab toolset. Method: We developed a new backend for Graal, a component of GrimoireLab, to use the cqmetrics C code metrics tool. We also modified Graal to add the capability to perform monthly samples of a project. We collected monthly snapshots of the two branches of OpenSSL and computed code metrics for each snapshot. Results: While the code base grew substantially in each version, code complexity and use of problematic language features both de-creased. The only negative indicator of code quality was an increase in style inconsistency.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796183","mining software repositories;software metrics","Measurement;Computer languages;Codes;Software design;Soft sensors;Documentation;Complexity theory","","3","","12","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Quid Pro Quo: An Exploration of Reciprocity in Code Review","C. Gavidia-Calderon; D. Han; A. Bennaceur","The Open University, United Kingdom; Singapore Management University, Singapore; The Open University, United Kingdom",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","738","740","We explore the role of reciprocity in code review processes. Reciprocity manifests itself in two ways: 1) reviewing code for others translates to accepted code contributions, and 2) having contributions accepted increases the reviews made for others. We use vector autoregressive (VAR) models to explore the causal relation between reviews performed and accepted contributions. After fitting VAR models for 24 active open-source developers, we found evidence of reciprocity in 6 of them. These results suggest reciprocity does play a role in code review, that can potentially be exploited to increase reviewer participation.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528522","Engineering and Physical Sciences Research Council(grant numbers:EP/V026747/1,EP/R013144/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796163","code review;collaboration;time series analysis","Reactive power;Codes;Fitting;Data mining;Open source software","","","","15","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Replicating Data Pipelines with GrimoireLab","K. Eng; H. Sahar","University of Alberta, Edmonton, Canada; University of Alberta, Edmonton, Canada",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","741","743","In this paper, we present our MSR Hackathon 2022 project that replicates an existing Gitter study [2] using GrimoireLab. We compare the previous study's pipeline with our GrimoireLab implementation in terms of speed, data consistency, organization, and the learning curve to get started. We believe our experience with GrimoireLab can help future researchers in making the right choice while implementing their data pipelines over Gitter and Github data.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796247","Gitter;developer discussions;GrimoireLab","Pipelines;Organizations;Software;Data mining;Software development management","","1","","2","","21 Jun 2022","","","IEEE","IEEE Conferences"
"A Deep Study of the Effects and Fixes of Server-Side Request Races in Web Applications","Z. Qiu; S. Shao; Q. Zhao; H. A. Khan; X. Hui; G. Jin","North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","744","756","Server-side web applications are vulnerable to request races. While some previous studies of real-world request races exist, they primarily focus on the root cause of these bugs. To better combat request races in server-side web applications, we need a deep understanding of their characteristics. In this paper, we provide a complementary focus on race effects and fixes with an enlarged set of request races from web applications developed with Object-Relational Mapping (ORM) frameworks. We revisit characterization questions used in previous studies on newly included request races, distinguish the external and internal effects of request races, and relate requestrace fixes with concurrency control mechanisms in languages and frameworks for developing server-side web applications. Our study reveals that: (1) request races from ORM-based web applications share the same characteristics as those from raw-SQL web applications; (2) request races violating application semantics without explicit crashes and error messages externally are common, and latent request races, which only corrupt some shared resource internally but require extra requests to expose the misbehavior, are also common; and (3) various fix strategies other than using synchronization mechanisms are used to fix request races. We expect that our results can help developers better understand request races and guide the design and development of tools for combating request races.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528463","National Science Foundation(grant numbers:CCF-2008056); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796296","web-application request races;characteristic study;Object-Relational Mapping;external and internal effects;fix strategies","Computer languages;Semantics;Computer bugs;Concurrency control;Software;Synchronization;Security","","1","","85","","21 Jun 2022","","","IEEE","IEEE Conferences"
"A Large-scale Dataset of (Open Source) License Text Variants","S. Zacchiroli","LTCI, Telecom Paris, Institut Polytechnique de Paris, Paris, France",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","757","761","We introduce a large-scale dataset of the complete texts of free/open source software (FOSS) license variants. To assemble it we have collected from the Software Heritage archive-the largest publicly available archive of FOSS source code with accompanying development history-all versions of files whose names are commonly used to convey licensing terms to software users and developers. The dataset consists of 6.5 million unique license files that can be used to conduct empirical studies on open source licensing, training of automated license classifiers, natural language processing (NLP) analyses of legal texts, as well as historical and phylogenetic studies on FOSS licensing. Additional metadata about shipped license files are also provided, making the dataset ready to use in various contexts; they include: file length measures, detected MIME type, detected SPDX license (using ScanCode), example origin (e.g., GitHub repository), oldest public commit in which the license appeared. The dataset is released as open data as an archive file containing all deduplicated license files, plus several portable CSV files for metadata, referencing files via cryptographic checksums.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796220","dataset;open source;software license;copyright;intellectual property;software engineering;natural language processing","Training;Codes;Soft sensors;Semantics;Open source software;Metadata;Natural language processing;Copyright protection;Software engineering","","4","","34","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Detecting Privacy-Sensitive Code Changes with Language Modeling","G. Demirci; V. Murali; I. Ahmad; R. Rao; G. A. Aye","Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","761","762","At Meta, we work to incorporate privacy-by-design into all of our products and keep user information secure. We have created an ML model that detects code changes (“diffs”) that have privacy-sensitive implications. At our scale of tens of thousands of engineers creating hundreds of thousands of diffs each month, we use automated tools for detecting such diffs. Inspired by recent studies on detecting defects [2], [3], [5] and security vulnerabilities [4], [6], [7], we use techniques from natural language processing to build a deep learning system for detecting privacy-sensitive code.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796200","privacy;software;repository;change;detection;machine learning;privacy sensitive;neural networks","Deep learning;Codes;Databases;Static analysis;Manuals;Feature extraction;Software","","","","7","","21 Jun 2022","","","IEEE","IEEE Conferences"
"SECOM: Towards a convention for security commit messages","S. Reis; R. Abreu; H. Erdogmus; C. Păsăreanu","INESC-ID & IST/Técnico, U. of Lisbon, Lisbon, Portugal; INESC-ID & FEUP, U. Porto, Porto, Portugal; Carnegie Mellon University, USA; Carnegie Mellon University, USA",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","764","765","One way to detect and assess software vulnerabilities is by extracting security-related information from commit messages. Automating the detection and assessment of vulnerabilities upon security commit messages is still challenging due to the lack of structured and clear messages. We created a convention, called SECOM, for security commit messages that structure and include bits of security-related information that are essential for detecting and assessing vulnerabilities for both humans and tools. The full convention and details are available here: https://tqrg.github.io/secom/.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796324","security commit messages;convention;standard;best practices","Software;Security;Data mining","","","","12","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Varangian: A Git Bot for Augmented Static Analysis","S. Pujar; Y. Zheng; L. Buratti; B. Lewis; A. Morari; J. Laredo; K. Postlethwait; C. Görn","IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; Red Hat, United States; Red Hat, United States",2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","766","767","The complexity and scale of modern software programs often lead to overlooked programming errors and security vulnerabilities. Developers often rely on automatic tools, like static analysis tools, to look for bugs and vulnerabilities. Static analysis tools are widely used because they can understand nontrivial program behaviors, scale to millions of lines of code, and detect subtle bugs. However, they are known to generate an excess of false alarms which hinder their utilization as it is counterproductive for developers to go through a long list of reported issues, only to find a few true positives. One of the ways proposed to suppress false positives is to use machine learning to identify them. However, training machine learning models requires good quality labeled datasets. For this purpose, we developed D2A [3], a differential analysis based approach that uses the commit history of a code repository to create a labeled dataset of Infer [2] static analysis output.","2574-3864","978-1-4503-9303-4","10.1145/3524842.3528516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796288","security;static analysis;git;bot;machine learning;bert","Training;Codes;Computer bugs;Static analysis;Machine learning;Programming;Software","","1","","3","","21 Jun 2022","","","IEEE","IEEE Conferences"
"Author Index","",,2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR),"21 Jun 2022","2022","","","769","773","","2574-3864","978-1-4503-9303-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796340","","","","","","","","21 Jun 2022","","","IEEE","IEEE Conferences"
